{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955a258-7843-41bd-8659-8043b35c65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import intake\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "xr.set_options(keep_attrs=True)\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a525725-21cb-4604-905a-cd78bdfa5f57",
   "metadata": {},
   "source": [
    "Load dask Area for faster computing.  Note, this will take awhile but in long run processing should be faster when compute is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d23d7-ef5e-4b8f-a634-6f719917a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import progress\n",
    "from dask.distributed import Client\n",
    "from climakitae.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "cluster.adapt(minimum=0, maximum=16)\n",
    "client = cluster.get_client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730f13c-d06d-4813-bb91-18bcca403be3",
   "metadata": {},
   "source": [
    "Get client link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2cccf-c225-4f18-a7de-b0c185effb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da6ff9-7c5b-43ce-b8f6-eda1df54a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "#Use these cordinates to clip around the watershed of interest.\n",
    "latitude = [34.775317,42.432494]\n",
    "longitude = [-123.097421,-117.980799]\n",
    "run_list_path = \"data/GCM_Run_List_Test.csv\"\n",
    "esm_datastore = \"https://cadcat.s3.amazonaws.com/cae-collection.json\"\n",
    "output_folder = \"outputs\"\n",
    "mask_path = \"mask/mask.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e0ccc-88e4-488c-94fa-8b62c0b7bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(run_list_path):\n",
    "    \"\"\"Read each set of model parameters into dictionary from csv file.\n",
    "    \n",
    "    Return list of dictionaries.\n",
    "    \"\"\"\n",
    "    model_params = []\n",
    "    with open(run_list_path, \"r\") as src:\n",
    "        d = csv.DictReader(src)\n",
    "        for row in d:\n",
    "            model_params.append(row)\n",
    "    return model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b349d-4c0d-408d-bd45-4b7a2f5d9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(esm_datastore, model_params):\n",
    "    \"\"\"Return xarray.DataSet from model parameters.\"\"\"\n",
    "    # Open catalog of available data sets using intake-esm package\n",
    "    cat = intake.open_esm_datastore(esm_datastore)\n",
    "    cat_item = cat.search(\n",
    "        activity_id=model_params[\"activity_id\"],\n",
    "        institution_id=model_params[\"institution_id\"],\n",
    "        table_id=model_params[\"table_id\"], \n",
    "        variable_id=['pr','tasmax','tasmin'],\n",
    "        experiment_id=model_params[\"experiment_id\"],\n",
    "        grid_label=model_params[\"grid_label\"],\n",
    "        member_id=model_params[\"member_id\"],\n",
    "        source_id=model_params[\"source_id\"],  \n",
    "    )\n",
    "    # Add catalog item to dataset dict\n",
    "    data_dict = cat_item.to_dataset_dict(\n",
    "        #xarray_open_kwargs={'consolidated': True},\n",
    "        storage_options={'anon': True}\n",
    "    )\n",
    "    # Construct dataset key to retrieve from the dictionary\n",
    "    key = \"{}.{}.{}.{}.{}.{}\".format(\n",
    "            model_params['activity_id'],\n",
    "            model_params['institution_id'],\n",
    "            model_params['source_id'],\n",
    "            model_params['experiment_id'],\n",
    "            model_params['table_id'],\n",
    "            model_params['grid_label'],)\n",
    "    \n",
    "    # Slice the dataset to the input time window.\n",
    "    \n",
    "    ds = slice_by_time_years_dataset(data_dict[key],model_params['start_year'],model_params['end_year'])\n",
    "    ds = convert_daily_to_monthly_dataset(ds)\n",
    "    # Trim trim down to cordinates.\n",
    "    #ds = trim_to_lat_lon_dataset(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d990d3-0d54-470d-be7a-aa828ef0da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask_to_dataset(ds):\n",
    "    # attach the mask\n",
    "    with open(mask_path, 'rb') as f:\n",
    "        mask = np.load(f, allow_pickle=True)\n",
    "\n",
    "    ds.coords['mask'] = (('lat', 'lon'), mask)\n",
    "    ds = trim_to_lat_lon_dataset(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8381dd-f218-4b17-a1fd-0d22e562b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_daily_to_monthly_dataset(ds):\n",
    "    #Convert our daily values to monthly.  Precip is the accumulated and temperature is the average.\n",
    "     #86400 x kg/m2/s = daily value (mm)  Check this!!!!\n",
    "    ds['pr'] = ds.pr * 86400\n",
    "    ds.pr.attrs[\"units\"] = 'mm/day' \n",
    "    ds_precip = ds['pr'].resample(time=\"M\").sum()\n",
    "    ds_precip.attrs[\"units\"] = 'mm/mon' \n",
    "    ds_temp = ds[['tasmin','tasmax']].resample(time=\"M\").mean()\n",
    "    \n",
    "    #Change the temp to C\n",
    "    ds_temp = ds_temp[['tasmin','tasmax']] - 273.15\n",
    "    ds_temp.tasmin.attrs[\"units\"]  = 'degC'\n",
    "    ds_temp.tasmax.attrs[\"units\"]  = 'degC'\n",
    "    \n",
    "    \n",
    "    #Merge the dataset back into on dataset.\n",
    "    ds= xr.merge([ds_precip,ds_temp])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91935c5-dff2-48ae-8858-111927c9cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_by_time_years_dataset(ds,startyear,endyear):\n",
    "    # Time slice\n",
    "    ds = ds.sel(\n",
    "        time=slice(str(startyear), str(endyear))\n",
    "        )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901ea78-2ae9-4335-b386-91c0124bbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_to_lat_lon_dataset(ds):\n",
    "    #This needs to be done for the cliping.\n",
    "    ds.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "    ds.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    \n",
    "    #Get the subset of data for watershed.\n",
    "    ds = ds.rio.clip_box(\n",
    "        minx=longitude[0],\n",
    "        miny=latitude[0],\n",
    "        maxx=longitude[1],\n",
    "        maxy=latitude[1],\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405fe5e9-361c-4b9f-8561-1a4d7478a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_file_name_monthly(model_params,end_part):\n",
    "    return '%s_%s_%s_%s.csv'%(model_params['source_id'],model_params['experiment_id'],model_params['member_id'],end_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf74e9e-2b0d-4344-af9f-c8bafc6859a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_dataset_with_mask(esm_datastore_in, model_params_in):\n",
    "#Loads current dataset\n",
    "    ds = get_dataset(esm_datastore_in, model_params_in)\n",
    "    ds = add_mask_to_dataset(ds)\n",
    "    ds = ds.compute()\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9243eaf7-dcb9-4af7-8247-70911ca11be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one(esm_datastore_in, model_params_in):\n",
    "    ds = get_load_dataset_with_mask(esm_datastore_in, model_params_in)\n",
    "    #for each subasin:\n",
    "        #Process outputs without wieghts and save to CSV.\n",
    "        #Process 30 year rolling average and save to CSV.\n",
    "    #Process with weights. This should be 1 value for all subasins.\n",
    "    #Process 30 year rolling average. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09434bfd-997f-456a-af2d-50353c169f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_params = get_model_params(run_list_path)\n",
    "model_params = all_model_params[0]\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7762ecb-8fa0-4dc3-8ec3-8eb6a14dede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(esm_datastore, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233db82-924b-4c05-849c-5336d4bc2d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f21f33-eabe-4984-b6df-1a07c89c1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs[\"units\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77a35e-3d3e-400d-9d19-825585448897",
   "metadata": {},
   "source": [
    "Add mask to data set.  Mask is applied here and resulting dataset is clipped to box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0a3f7-5651-4767-b0b1-6844566ca940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = add_mask_to_dataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5050316e-bc4e-40a5-aba8-75d9cb02f699",
   "metadata": {},
   "source": [
    "Load the dataset here.  This takes awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871bb4d-15bd-4b4a-b9e6-8b0118a5bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa74ca-6750-4a7b-b2e9-25f3280f27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf83af1-c116-460e-ad72-b31ba766b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb502f-4595-4e60-9e3d-1cac3d850660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_data = ds['pr'].where(ds.mask != -1) # 14 Tulare\n",
    "# map_data.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce43bb3-0378-47e7-a0a8-60767bfd1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.where(ds.mask != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2cb99-27f1-4480-aa63-123db5ba4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_data = ds['pr'].where(ds.mask == 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3b20d-8f21-4d9f-a954-f9674f9584d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_subbasin = -1\n",
    "\n",
    "map_data = ds.where(ds.mask != id_subbasin)\n",
    "#map_data = ds.where(ds.mask == id_subbasin)\n",
    "map_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc9421-cf9b-46d2-9162-debac9b12fad",
   "metadata": {},
   "source": [
    "Grant, Can we pull this from the shape file or do we need add seperate csv here?  We also need the weight for each subasin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bfb833-a0ed-4d94-ac16-a92df5614c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_dict = {\n",
    "    17: \"UpperYuba\",\n",
    "    18: \"Test\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46bc963-8f46-49bf-810d-d29cfef17b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "oids = basin_dict.keys()\n",
    "oids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e12fea-a10c-4c09-9b3c-d3143ec0e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for oid in oids:\n",
    "    # mask the data\n",
    "    # get our number\n",
    "#    result[oid] = precip_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c5ac0-ef0a-4836-8091-b855b62ffc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c76422-6d29-4aea-841f-c9fa802e85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data['pr'][0].plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc93979-1a72-4641-9d10-b600d5b668c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data['tasmax'][20].plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81530535-6583-4805-81e8-490c558cc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data['tasmin'][20].plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e688329-5638-470b-a25c-2b6ae95df72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_precip = mask_test.pr.mean(['lat','lon'])\n",
    "results_precip = map_data.pr.mean(['lat','lon'])\n",
    "results_precip.attrs[\"units\"]  = 'mm/mon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a9f7c-f0bf-4fd6-94fb-5d87e96f9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tasmin = map_data.tasmin.mean(['lat','lon'])\n",
    "results_tasmin.attrs[\"units\"]  = 'degC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57800e81-ae89-44aa-ba0b-d697bf60ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tasmax = map_data.tasmax.mean(['lat','lon'])\n",
    "results_tasmax.attrs[\"units\"]  = 'degC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99415439-db0a-4ce9-8e05-a5cccb9600c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all= xr.merge([results_precip,results_tasmax,results_tasmin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906064d-15a2-46f3-a41b-ac5175a01964",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5500c-ce56-4336-8e5c-6b5e49d1f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Format the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35ad7a-a8b7-4dc3-86e1-cdd713b657d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = ds_all.to_pandas()\n",
    "\n",
    "df.drop('spatial_ref',axis=1, inplace=True)\n",
    "df.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049397f6-493b-4577-ac4b-39c161fbbbb6",
   "metadata": {},
   "source": [
    "Format output to what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac544c-4549-4599-91f0-ce1ee801b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df.index.strftime('%Y')\n",
    "df['Month'] = df.index.strftime('%b')\n",
    "df['Tave (degC)'] = df[['tasmax','tasmin']].mean(axis=1)\n",
    "df.rename({'pr': 'Pr (mm)','tasmax':'Tasmin (degC)','tasmin' : 'Tasmin (degC)'}, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9fe09-5afd-4a47-9c59-db45ef92737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df.iloc[:,[3,4,0,1,2,5]]\n",
    "df_n = df_r.reset_index()\n",
    "df_n.drop('time' , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9c484-4031-49f9-b410-cb078f8565dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456d1d3-cba7-4ee6-8021-cbb9888ce6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_Path_Test = os.path.join(output_folder,get_output_file_name_monthly(model_params,id_subbasin)) #os.path.join(output_folder, \"test2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a74db5-b01c-43a0-a862-b09bd9b4e884",
   "metadata": {},
   "source": [
    "Grant: This was just a test.  Can you find a way to store in memory instead CSV file and write it the zip file?  Also, for some reason the index is being written out to the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b7787-40c0-471b-b24b-c7de00df51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.to_csv(csv_Path_Test,index=False)\n",
    "#lst = df_n.values.tolist()\n",
    "#lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce08df-ba5a-4041-9996-1db288bc73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fadc6f-7a2d-436d-9f25-3132392f77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = os.path.join(output_folder, \"test.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46358c05-2068-431f-bea1-ded9276e82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = \"test\\ntest\"\n",
    "data2 = \"test\\ntest\"\n",
    "csv_data = [\n",
    "    (\"scenario1.csv\", data1),\n",
    "    (\"scenario2.csv\", data2)\n",
    "]\n",
    "\n",
    "with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    for filename, data in csv_data:\n",
    "        zf.writestr(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a27bf-ef40-418e-98e4-fe84aff09013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
