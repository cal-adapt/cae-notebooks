{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74513442-4067-44c4-b1c8-7216c5670d98",
   "metadata": {
    "tags": []
   },
   "source": [
    "Data Download Daily LOCA2 to Monthly \n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc33c9-127b-4d9d-ac27-08e2fab953d6",
   "metadata": {},
   "source": [
    "**Download LOC2 data for 1 simulation and converts daily values to monthly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152967e-37f9-4109-abc3-9d685726f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running this notebook in an environment outside of the Cal-Adapt Analytics Engine Jupyter Hub make sure to install intake-esm and s3fs packages\n",
    "import intake\n",
    "\n",
    "# Open catalog of available data sets using intake-esm package\n",
    "cat = intake.open_esm_datastore('https://cadcat.s3.amazonaws.com/cae-collection.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662b901",
   "metadata": {},
   "source": [
    "Adding TimeScale and Variable ID:\n",
    "table_id = time scale:  {\"monthly\": \"mon\", \"daily\": \"day\", \"hourly\": \"1hr\"}\n",
    "=ssp370\n",
    "variable_id = pr, tasmax, tasmin\n",
    "grid_label = Catalog names we want 3k: {\"45 km\": \"d01\", \"9 km\": \"d02\", \"3 km\": \"d03\"}\n",
    "activity_id=\"LOCA2\"\n",
    "experiment_id=\"ssp370\" for right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup easy to read naming convention\n",
    "dict_table_id = {\"monthly\": \"mon\", \"daily\": \"day\", \"hourly\": \"1hr\"}\n",
    "dict_grid_label = {\"45 km\": \"d01\", \"9 km\": \"d02\", \"3 km\": \"d03\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94324af9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get the catalog info for LOCA2 by querying for experiment and all other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "do_historical = True\n",
    "\n",
    "#Set current variables here.\n",
    "historical_id = \"historical\" \n",
    "simulation_id = \"ssp370\"\n",
    "member_id = \"r1i1p1f1\"\n",
    "source_id = \"ACCESS-CM2\"\n",
    "\n",
    "#Set default variable\n",
    "activity_id =\"LOCA2\"\n",
    "table_id = dict_table_id[\"daily\"]\n",
    "variable_id = [\"pr\",\"tasmax\",\"tasmin\"]\n",
    "grid_label = dict_grid_label[\"3 km\"]\n",
    "\n",
    "#Use these cordinates to clip around the watershed of interest.\n",
    "latitude = [34.775317,42.432494]\n",
    "longitude = [-123.097421,-117.980799]\n",
    "\n",
    "#Set historical or other simulation time slice.\n",
    "time_slice = (2015, 2100)  #Simulation\n",
    "experiment_id = simulation_id\n",
    "\n",
    "if do_historical: \n",
    "    time_slice = (1950, 2014)   #Historical\n",
    "    experiment_id = historical_id\n",
    "\n",
    "#Get sub catalog from variables above\n",
    "cat_loca = cat.search(activity_id=activity_id, \n",
    "                      table_id=table_id, \n",
    "                      variable_id=variable_id,\n",
    "                      experiment_id=experiment_id,\n",
    "                      grid_label=grid_label,\n",
    "                      member_id=member_id,\n",
    "                      source_id=source_id\n",
    "                     )\n",
    "\n",
    "cat_loca.unique()[\"path\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254524d8",
   "metadata": {},
   "source": [
    "**This will give you an idea of the available query parameters that can be entered to retrieve a particular set of data. Below is a sample query against the whole catalog to refine catalog entries to those of interest:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161b47c-ef50-41c6-bbb9-1b6327e64af1",
   "metadata": {},
   "source": [
    "Load data, convert to monthly, and clip to area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a470b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bounding box\n",
    "from shapely.geometry import mapping\n",
    "import xarray as xr\n",
    "cat_subset = cat_loca.search(member_id=member_id)\n",
    "data_dict = cat_subset.to_dataset_dict(\n",
    "     xarray_open_kwargs={'consolidated': True},\n",
    "     storage_options={'anon': True})\n",
    "\n",
    "dsname=\"\"\n",
    "\n",
    "# There should only be one dataset to work with at this point.\n",
    "for dname, ds in data_dict.items():\n",
    "    ds = ds.assign_coords({\"simulation\": ds.attrs[\"source_id\"]})\n",
    "        \n",
    "    # Time slice\n",
    "    ds = ds.sel(\n",
    "        time=slice(str(time_slice[0]), str(time_slice[1]))\n",
    "        )\n",
    "    \n",
    "    #Convert our daily values to monthly.  Precip is the accumulated and temperature is the average.\n",
    "    ds_precip = ds['pr'].resample(time=\"M\").sum()\n",
    "    ds_temp = ds[['tasmin','tasmax']].resample(time=\"M\").mean()\n",
    "    \n",
    "    #Merge the dataset back into on dataset.\n",
    "    ds= xr.merge([ds_precip,ds_temp])\n",
    "\n",
    "    #This needs to be done for the cliping.\n",
    "    ds.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "    ds.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    \n",
    "    #Get the subset of data for watershed.\n",
    "    ds = ds.rio.clip_box(\n",
    "        minx=longitude[0],\n",
    "        miny=latitude[0],\n",
    "        maxx=longitude[1],\n",
    "        maxy=latitude[1],\n",
    "        crs=4326,\n",
    "    )\n",
    "  \n",
    "    dsname = dname\n",
    "    #Update the dataset dictionary\n",
    "    data_dict.update({dname: ds})\n",
    "    \n",
    "data_dict[dsname]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3597f-f13b-4757-a298-b7bc2441b0a4",
   "metadata": {},
   "source": [
    "Save output to netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720335a-893d-426e-aff2-1521bb2f5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "filout = '%s_%s_%s_%s.nc'%(str(dsname).replace(\"day\",\"%s.mon\"%member_id),\n",
    "                           str(time_slice[0]),str(time_slice[1]),\"box_clip\") \n",
    "#Uncomment and set path to local diretory.\n",
    "#filout=os.path.join(\"C:\\Data\\RandD\\Visual Studio Code\\DWR\", filout)\n",
    "\n",
    "data_dict[dsname].to_netcdf(filout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
