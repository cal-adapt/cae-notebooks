{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef234a4-1197-4ff1-b82f-24b9cc28d249",
   "metadata": {},
   "source": [
    "# DFU Notebook 4: Working with hourly projections data \n",
    "Exploring how hourly projections data can be used as inputs into DFU hourly models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac647be-c6c9-4244-a38f-0828d59b4f28",
   "metadata": {},
   "source": [
    "## Step 0: Setup \n",
    "Import the climakitae library and any other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d46996-9deb-4736-a3b8-2f56d8a1290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "from climakitae.cluster import Cluster\n",
    "from climakitae.utils import get_closest_gridcell\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from xclim.core.calendar import convert_calendar\n",
    "from xclim.sdba.adjustment import QuantileDeltaMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb29575-fd42-4d6d-b901-ce5a7578bdd3",
   "metadata": {},
   "source": [
    "Initialize a [climakitae.Application](https://climakitae.readthedocs.io/en/latest/generated/climakitae.Application.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877edad9-6eda-45ee-9b77-f4082cfc0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ck.Application()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081178fa-5ac4-47a7-aeeb-8212ac1195c6",
   "metadata": {},
   "source": [
    "Additionally, get set up to make the computing go faster by executing the following cell. It will likely take several minutes to spin up! Learn more about dask and see some common troubleshooting tips on our FAQ page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e32be-44e5-4c65-8b9b-aeab045d68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = Cluster()\n",
    "# cluster.adapt(minimum=0, maximum=8)\n",
    "# client = cluster.get_client()\n",
    "# cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce8036-d1fa-49b2-b7f9-e56e8ab8c304",
   "metadata": {},
   "source": [
    "# Part 1: Monthly extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a8040-e211-4d0c-874e-75eea968a700",
   "metadata": {},
   "source": [
    "## 1a) Retrieve catalog data using a configuration csv file\n",
    "We can easily use the climakitae helper function `retrieve` to use a configuration csv file to retrieve data from the AE data catalog. To modify the retrieved data, simply modify the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137bd9f-d352-4343-99f3-1a382bce28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_hourly = app.retrieve(\"data/config_hourly_2m_temp_sac.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc3ebd-831a-4d64-a1b8-779657bbce92",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can review the retrieved data easily in the notebook. You'll see that we've retrieved hourly 2 meter air temperature data for SSP 3-7.0 for the time period of 1980-2050 at a grid resolution of 9km, subsetted to Sacramento County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a201c9f-d145-4d92-a907-2c381833cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.select()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a4cd2-22d7-4b2c-9924-d4b338080253",
   "metadata": {},
   "source": [
    "## 1b) Get data from the closest grid cell to the weather station. \n",
    "As an example - to replicate the historical observations at Sacramento Executive Airport, grab the grid cell from the model nearest to the airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bd803-b127-4c56-beef-bc100021d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(\"data/CEC_Forecast_Weather Stations_California.csv\", index_col=\"STATION\")\n",
    "one_station = stations_df.loc[\"SACRAMENTO EXECUTIVE AIRPORT\"]\n",
    "\n",
    "t2_hourly_sac = get_closest_gridcell(\n",
    "    data=t2_hourly,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")\n",
    "t2_hourly_sac = t2_hourly_sac.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668c169-db55-4092-9ee4-2c0bbe6eb862",
   "metadata": {},
   "source": [
    "## 1c) Read the data into memory. \n",
    "Until this point, the data is only lazily loaded into the notebook, so this step will take several minutes. You'll notice that we've added a [Jupyter magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html), `%%time`, to the top of the cell, which will print final time it takes to perform this step once the code finishes running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910bfb5-c5da-471a-9458-ca5543b0659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2_hourly_sac = app.load(t2_hourly_sac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c4642-0149-4591-a79c-1fe8d862d73a",
   "metadata": {},
   "source": [
    "## 1d) Bias correct the data\n",
    "First, we'll read in the weather station data from a netcdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc4be7-03bf-483c-9d60-ea19aa6d8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_da = xr.open_dataset('data/station-data/KSAC_temperatures_1981-2010.nc').temperatures # Read in data\n",
    "obs_da.attrs[\"units\"] = \"degF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc36ba0-4641-47c1-80c5-680b6d8057d8",
   "metadata": {},
   "source": [
    "Next, we'll remove leap years from both the observational station data and the model data, to ensure that they use the same calendar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa1e57-e5ba-493e-b402-4a4da8afc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_da = convert_calendar(obs_da, \"noleap\")\n",
    "t2_hourly_sac_noleap = convert_calendar(t2_hourly_sac, \"noleap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4253e6-619e-432c-bdc6-9c97dd9cf3b5",
   "metadata": {},
   "source": [
    "Finally, we'll use xclim to bias correct the gridded data using the weather station data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02f45b-bb93-4675-aaf1-2b35e14527d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_correct(obs_da, da, nquantiles=20, group=\"time.dayofyear\", kind=\"+\"): \n",
    "    \"\"\"Perform bias correction using observational data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs_da: xr.DataArray \n",
    "        Observational dataset \n",
    "    da: xr.DataArray \n",
    "        Model data to bias correct \n",
    "    nquantiles: xr.DataArray, optional\n",
    "        The number of quantiles to use\n",
    "        Default to 20\n",
    "    group: str, optional\n",
    "         The grouping information\n",
    "         Default to \"time.dayofyear\" \n",
    "    kind: str, optional \n",
    "         Either additive or multiplicative\n",
    "         Default to additive: \"+\" \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray \n",
    "        Bias corrected input data model_da \n",
    "        \n",
    "    See Also\n",
    "    --------\n",
    "    xclim.sdba.adjustment.QuantileDeltaMapping\n",
    "    \n",
    "    \"\"\"\n",
    "    QDM = QuantileDeltaMapping.train(\n",
    "        obs_da, \n",
    "        # Input data, sliced to time period of observational data\n",
    "        da.sel(time=slice(str(obs_da.time.values[0].year), str(obs_da.time.values[-1].year))), \n",
    "        nquantiles=nquantiles, \n",
    "        group=group,\n",
    "        kind=kind\n",
    "    )\n",
    "    da_adj = QDM.adjust(da)\n",
    "    da_adj.name = da.name\n",
    "    return da_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff9c41-a4e0-4f3c-b44d-40bf52d42419",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_hourly_sac_bias_corrected = bias_correct(obs_da, t2_hourly_sac_noleap.chunk(dict(time=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328726b-0285-4085-9174-89952e7e64df",
   "metadata": {},
   "source": [
    "## 1e) Find the monthly minimum and maximum air temperature\n",
    "We'll resample the hourly data to monthly using [xarray's resample function](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.resample.html#xarray.DataArray.resample), then compute a minimum and maximum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267bf891-cf9e-4dbc-8f94-36b8333b6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_mon_min_bias_corrected = t2_hourly_sac_bias_corrected.resample(time=\"MS\").min().assign_attrs({\"frequency\":\"monthly\"})\n",
    "t2_mon_max_bias_corrected = t2_hourly_sac_bias_corrected.resample(time=\"MS\").max().assign_attrs({\"frequency\":\"monthly\"})\n",
    "\n",
    "# Rename DataArrays \n",
    "t2_mon_min_bias_corrected.name = 'Bias Corrected Minimum Monthly Air Temperature at 2m'\n",
    "t2_mon_max_bias_corrected.name = 'Bias Corrected Maximum Monthly Air Temperature at 2m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e0924-77f5-47dc-956a-4554f013017a",
   "metadata": {},
   "source": [
    "## 1f) Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f26ca-b94a-4be6-9ca7-42e445c9cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_lineplot(data, dynamic=True, ylim=(0,120),ylabel=\"Air Temperature (degF)\",line_dash=\"solid\"): \n",
    "    \"\"\"Create an interactive lineplot using monthly data for each simulation in the dataset.\n",
    "    Setting dynamic=False (the default) makes the plot take longer to produce upfront, but everything \n",
    "    is zippy after (the developer's personal preference). \n",
    "    Setting dynamic=True means the plot will only be generated once you change the settings.\n",
    "    line_dash options: 'solid', 'dashed', 'dotted', 'dotdash', 'dashdot'\n",
    "    \"\"\"\n",
    "    plots_all = None\n",
    "    for (sim, color) in zip(data.simulation.values,['#377eb8', '#ff7f00', '#4daf4a','#f781bf']):\n",
    "        plot_i = data.sel(simulation=sim).hvplot.line(\n",
    "            groupby=\"time.month\", \n",
    "            width=550, height=350, \n",
    "            label=sim,\n",
    "            line_dash=line_dash,\n",
    "            grid=True,\n",
    "            ylabel=ylabel,\n",
    "            color=color,\n",
    "            ylim=ylim, # Set limits of y axis \n",
    "            dynamic=dynamic \n",
    "        )\n",
    "        plots_all = plot_i if plots_all is None else plots_all*plot_i\n",
    "\n",
    "    plots_all = plots_all.opts(legend_position='bottom') # Move legend to bottom of plot \n",
    "    return plots_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734eed4a-7c4a-4b67-a8bd-c4c195ce15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Convert back to pandas datetime \n",
    "# This raises a warning and I'm not sure if it will cause issues down the line\n",
    "t2_mon_min_bias_corrected[\"time\"] = t2_mon_min_bias_corrected.indexes[\"time\"].to_datetimeindex()\n",
    "t2_mon_max_bias_corrected[\"time\"] = t2_mon_max_bias_corrected.indexes[\"time\"].to_datetimeindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46acc4-96c7-43e4-b4dd-778721be4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1 = interactive_lineplot(t2_mon_min_bias_corrected)\n",
    "pl2 = interactive_lineplot(t2_mon_max_bias_corrected)\n",
    "bias_corrected_plot = (pl1*pl2).opts(legend_position='bottom')\n",
    "\n",
    "bias_corrected_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba242b-5530-4303-a8b3-35b634f48bdf",
   "metadata": {},
   "source": [
    "## 1g) Show bias corrected vs. raw data\n",
    "First, repeat the procedure above to compute the monthly min and max for the raw, non biased corrected data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11289f80-fe30-4065-9b0d-d25a89925d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample raw data to monthly, compute min and max. \n",
    "# Then, rename the output DataArrays \n",
    "t2_mon_min = t2_hourly_sac.resample(time=\"MS\").min().assign_attrs({\"frequency\":\"monthly\"})\n",
    "t2_mon_max = t2_hourly_sac.resample(time=\"MS\").max().assign_attrs({\"frequency\":\"monthly\"})\n",
    "t2_mon_min.name = 'Minimum Monthly Air Temperature at 2m'\n",
    "t2_mon_max.name = 'Maximum Monthly Air Temperature at 2m'\n",
    "\n",
    "# Combine with bias corrected data to make a single \n",
    "# xr.Dataset object that can be easily plotted \n",
    "t2_mon_min_bias_corrected[\"time\"] = t2_mon_min.time.values\n",
    "t2_mon_max_bias_corrected[\"time\"] = t2_mon_max.time.values\n",
    "t2_min_all = xr.merge([t2_mon_min, t2_mon_min_bias_corrected])\n",
    "t2_max_all = xr.merge([t2_mon_max, t2_mon_max_bias_corrected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ece13-aed8-4ddb-b5c9-2dd642c73041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight just one month and simulation\n",
    "simulation = \"cnrm-esm2-1\"\n",
    "month_int = 7 \n",
    "min_to_plot = t2_min_all.sel(simulation=simulation).isel(time=(t2_min_all.time.dt.month == month_int)).squeeze()\n",
    "max_to_plot = t2_max_all.sel(simulation=simulation).isel(time=(t2_max_all.time.dt.month == month_int)).squeeze()\n",
    "\n",
    "# Make the plot \n",
    "pl = (min_to_plot.hvplot.line(\n",
    "    groupby=[\"simulation\",\"time.month\"], \n",
    "    width=450, height=350, \n",
    "    grid=True, cmap=\"viridis\", \n",
    "    ylabel=\"Air Temperature (degF)\"\n",
    ").opts(legend_position='bottom') + max_to_plot.hvplot.line(\n",
    "    groupby=[\"simulation\",\"time.month\"], \n",
    "    width=450, height=350, \n",
    "    grid=True, cmap=\"viridis\", \n",
    "    ylabel=\"Air Temperature (degF)\"\n",
    ").opts(legend_position='bottom')).opts(\n",
    "    title=\"{0}: Bias corrected vs. non bias corrected temperature data\".format(simulation)\n",
    ")\n",
    "display(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26f28c-30a0-4f2c-8aa1-9618e418ffdb",
   "metadata": {},
   "source": [
    "# Part 2: Diurnal trends\n",
    "Find the day in each season that has the lowest minimum temperature **or** the highest maximum temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35f4ef-bb64-474d-821a-9984295dbc2d",
   "metadata": {},
   "source": [
    "## 2a) Retrieve the data \n",
    "Same as we've done in Part 1, here we'll grab the data using the `retrieve_from_csv` function and get the closest gridcell to the Sacramento weatherstation.\n",
    "\n",
    "Along with the future 30yr data, we'll also retrieve the Historical Reconstruction ERA5-WRF data from 1981-2010 as our historical baseline. We'll add this data to our plots at the end, so that it can be compared to the future period. By setting `merge` to `False` in the funtion, we're indicating that we want the two datasets returned separately, instead of merged into the same object (which would be incompatible as the datasets cover different time periods and have different dimensions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b33e6-78c4-4519-8c1c-696ffdf7de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_hourly_fut_sim, t2_hourly_historical, t2_hourly_hist_sim = app.retrieve(\"data/config_hourly_2m_temp.csv\", merge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6ae75-8d79-4a29-94ad-e40f7f458a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_hourly_future_sac = get_closest_gridcell(\n",
    "    data=t2_hourly_fut_sim,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")\n",
    "t2_hourly_historical_sac = get_closest_gridcell(\n",
    "    data=t2_hourly_hist_sim,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")\n",
    "t2_hourly_reconstruction_sac = get_closest_gridcell(\n",
    "    data=t2_hourly_historical,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3155190-a6cc-4649-be86-3608a550fba7",
   "metadata": {},
   "source": [
    "## 2b) Read the data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ffd7c-6ae0-4323-8e6c-a3c76a60308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2_hourly_future_sac = app.load(t2_hourly_future_sac)\n",
    "t2_hourly_historical_sac = app.load(t2_hourly_historical_sac)\n",
    "t2_hourly_reconstruction_sac = app.load(t2_hourly_reconstruction_sac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd25e21-5c5a-48da-9639-07fa2d4ce95e",
   "metadata": {},
   "source": [
    "## 2c) Extract extreme diurnal cycle from each simulation\n",
    "Here is a function to return the diurnal cycle of a day in which a particular extreme occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a29cc1-8f10-4abd-8886-99b303d4e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diurnal_cycle_by_season(y, how):\n",
    "    if how == 'min':\n",
    "        index_value_is_reached = y.argmin().values\n",
    "    elif how == 'min_daily_max':\n",
    "        max_daily = y.resample(time='1D').max()\n",
    "        index_value_is_reached = max_daily.argmin().values\n",
    "    elif how == 'max_daily_range':\n",
    "        daily_range = y.resample(time='1D').max() - y.resample(time='1D').min()\n",
    "        index_value_is_reached = daily_range.argmax().values\n",
    "\n",
    "    time_value_is_reached = y.isel(time=index_value_is_reached).time.values\n",
    "    day_value_is_reached = pd.to_datetime(time_value_is_reached).date()\n",
    "    diurnal_cycle = y.sel(time=slice(day_value_is_reached,pd.tseries.offsets.DateOffset(hour=23)+day_value_is_reached))\n",
    "    return xr.DataArray(diurnal_cycle.squeeze().values,coords={\"time_of_day\":diurnal_cycle.time.dt.hour.values})\n",
    "\n",
    "def get_diurnal_cycle(t2_hourly_one_season,how='min'):\n",
    "    return t2_hourly_one_season.groupby('time.season').apply(get_diurnal_cycle_by_season,how=how)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8386978-c4d0-48c0-a122-23e01fdd23a4",
   "metadata": {},
   "source": [
    "Choose which extreme you are interested in by setting `method` to `\"min\"` or `\"min_daily_max\"` or `\"max_daily_range\"`. We'll find the diurnal cycle for the entire day in which this occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170056d-151c-4047-8c49-22fa15a85413",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'max_daily_range' #'min', 'min_daily_max'\n",
    "diurnal_cycle_sims_all_fut = t2_hourly_future_sac.groupby('simulation').apply(get_diurnal_cycle,how=method) \n",
    "diurnal_cycle_sims_all_hist = t2_hourly_historical_sac.groupby('simulation').apply(get_diurnal_cycle,how=method)\n",
    "diurnal_cycle_reconstruct = t2_hourly_reconstruction_sac.groupby('simulation').apply(get_diurnal_cycle,how=method)\n",
    "# note: could stack on scenario *and* simulation, and then groupby that combined dim if there were more than one scenario selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f51e2b-c1f6-41e0-b9a9-0f6bdae6e84b",
   "metadata": {},
   "source": [
    "## 2d) Plot the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f390a29-aa2e-4961-89ce-711393ae44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_future = diurnal_cycle_sims_all_fut.hvplot.line(\n",
    "            x=\"time_of_day\", \n",
    "            by=\"simulation\",\n",
    "            grid=True, \n",
    "            xlabel=\"Hour of Day\",\n",
    "            width=575, height=250,\n",
    "        ) \n",
    "\n",
    "plots_historical = diurnal_cycle_sims_all_hist.hvplot.line(\n",
    "            x=\"time_of_day\", \n",
    "            by=\"simulation\",\n",
    "            grid=True, \n",
    "            xlabel=\"Hour of Day\",\n",
    "            width=575, height=250,\n",
    "        ) \n",
    "\n",
    "plot_reconstruct = diurnal_cycle_reconstruct.hvplot.line(\n",
    "            x=\"time_of_day\", \n",
    "            by=\"simulation\",\n",
    "            line_dash=\"dashed\",\n",
    "            color=\"black\",\n",
    "            grid=True, \n",
    "            xlabel=\"Hour of Day\",\n",
    "            width=575, height=250,\n",
    "        ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c27b9-105a-41f3-986f-5f4cbd7c1125",
   "metadata": {},
   "source": [
    "This now takes a moment to generate... \n",
    "\n",
    "Recall, also, that these data are not bias-corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974f0af-e97e-410a-ab7d-441aac6854fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruct * plots_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7bb34-a300-44b3-a8c1-5d2f2ae2164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94ce7b-ff40-4c0e-be16-d390bcebd202",
   "metadata": {},
   "source": [
    "## 2e) Observe the output data structure\n",
    "The data used to generate the plots above are available in the xr.DataArray object `diurnal_data`, computed in the code cell above. Here, we'll display the data so that you can observe the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa2713-0a01-426c-80f2-50a88a998493",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(diurnal_cycle_sims_all_fut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6bca92-28ad-4554-baea-33e2bcd328aa",
   "metadata": {},
   "source": [
    "## 2d) Export the results \n",
    "Choose your desired filetype (we recommend NetCDF) and export the data. We've left the actual export code, `app.export_dataset` commented out; if you want to save the file, simply remove the comment (#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50069a63-766a-49b0-80b2-6aeaf587b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.export_as()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5b605-48ed-4fec-aa3f-237fa938e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#app.export_dataset(diurnal_data, file_name=\"diurnal_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
