{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef234a4-1197-4ff1-b82f-24b9cc28d249",
   "metadata": {},
   "source": [
    "# DFU Notebook 4: Working with hourly projections data \n",
    "Exploring how hourly projections data can be used as inputs into DFU hourly models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac647be-c6c9-4244-a38f-0828d59b4f28",
   "metadata": {},
   "source": [
    "## Step 0: Setup \n",
    "Import the climakitae library and any other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d46996-9deb-4736-a3b8-2f56d8a1290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "from climakitae.cluster import Cluster\n",
    "from climakitae.utils import get_closest_gridcell\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from xclim.core.calendar import convert_calendar\n",
    "from xclim.sdba.adjustment import QuantileDeltaMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb29575-fd42-4d6d-b901-ce5a7578bdd3",
   "metadata": {},
   "source": [
    "Initialize a [climakitae.Application](https://climakitae.readthedocs.io/en/latest/generated/climakitae.Application.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877edad9-6eda-45ee-9b77-f4082cfc0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ck.Application()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081178fa-5ac4-47a7-aeeb-8212ac1195c6",
   "metadata": {},
   "source": [
    "Additionally, get set up to make the computing go faster by executing the following cell. It will likely take several minutes to spin up! Learn more about dask and see some common troubleshooting tips on our FAQ page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e32be-44e5-4c65-8b9b-aeab045d68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster()\n",
    "cluster.adapt(minimum=0, maximum=8)\n",
    "client = cluster.get_client()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce8036-d1fa-49b2-b7f9-e56e8ab8c304",
   "metadata": {},
   "source": [
    "# Part 1: Monthly extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a8040-e211-4d0c-874e-75eea968a700",
   "metadata": {},
   "source": [
    "### 1a) Retrieve catalog data using a configuration csv file\n",
    "We can easily use the climakitae helper function `retrieve_from_csv` to use a configuration csv file to retrieve data from the AE data catalog. To modify the retrieved data, simply modify the csv file. See the [function documentation](https://climakitae.readthedocs.io/en/latest/generated/climakitae.Application.retrieve_from_csv.html#climakitae.Application.retrieve_from_csv) for more information. Because we are retrieving two data variables, the data will be returned as an [xarray Dataset](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137bd9f-d352-4343-99f3-1a382bce28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_daily = app.retrieve(\"data/config_min_max_daily_temp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc3ebd-831a-4d64-a1b8-779657bbce92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1b) Preview the data \n",
    "You can review the retrieved data easily in the notebook. You'll see that we've retrieved daily minimum and maximum 2 meter air temperature data for SSP 3-7.0 for the time period of 1980-2050 at a grid resolution of 9km. <br><br>The daily min and max data has been pre-computed by our team using the hourly 2m Air Temperature data so that these derived variables don't need to be computed on the fly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34c995-0f1c-4a42-a956-c5f1c6901601",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(t2_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328726b-0285-4085-9174-89952e7e64df",
   "metadata": {},
   "source": [
    "### 1c) Find the monthly minimum and maximum air temperature\n",
    "We'll resample the daily data to monthly using [xarray's resample function](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.resample.html#xarray.DataArray.resample), then compute a minimum and maximum. We'll combine the derived monthly variables to create a new xarray Dataset object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ed317-1430-4b2c-9b9d-b5266657bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to monthly\n",
    "mon_min = t2_daily[\"Daily minimum air temperature at 2m\"].resample(\n",
    "    time=\"MS\").min().assign_attrs({\"frequency\":\"monthly\"})\n",
    "mon_max = t2_daily[\"Daily maximum air temperature at 2m\"].resample(\n",
    "    time=\"MS\").max().assign_attrs({\"frequency\":\"monthly\"})\n",
    "\n",
    "# Rename variable daily --> monthly \n",
    "mon_min.name = \"Monthly minimum air temperature at 2m\"\n",
    "mon_max.name = \"Monthly maximum air temperature at 2m\"\n",
    "\n",
    "# Create new combined object \n",
    "t2_monthly = xr.merge([mon_min, mon_max], combine_attrs=\"drop_conflicts\").squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822fefe-ffdf-4c1c-9296-d97b25a2d114",
   "metadata": {},
   "source": [
    "### 1d) Get data from the closest grid cell to the weather station. \n",
    "As an example - to replicate the historical observations at Sacramento Executive Airport, grab the grid cell from the model nearest to the airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143dc1e-2bba-4848-b9c8-127200199f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(\"data/CEC_Forecast_Weather Stations_California.csv\", index_col=\"STATION\")\n",
    "one_station = stations_df.loc[\"SACRAMENTO EXECUTIVE AIRPORT\"]\n",
    "\n",
    "t2_monthly_sac = get_closest_gridcell(\n",
    "    data=t2_monthly,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0e619-6f23-4f93-b6d5-2dbf6f90c7c3",
   "metadata": {},
   "source": [
    "### 1e) Read the data into memory. \n",
    "Until this point, the data is only lazily loaded into the notebook, so this step will take several minutes. You'll notice that we've added a [Jupyter magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html), `%%time`, to the top of the cell, which will print final time it takes to perform this step once the code finishes running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d2059-eb67-41fd-963d-7ab049b3625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2_monthly_sac = app.load(t2_monthly_sac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ccb6de-e6a6-4533-a05d-bfc4f0310320",
   "metadata": {},
   "source": [
    "### 1f) Bias correct the data\n",
    "First, we'll read in the weather station data from a netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3cb4f-3286-49eb-b600-69ca97f23af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_da = xr.open_dataset('data/station-data/KSAC_temperatures_1981-2010.nc').temperatures # Read in data\n",
    "obs_da.attrs[\"units\"] = \"degF\"\n",
    "obs_da = convert_calendar(obs_da, \"noleap\") # Convert calendar to exclude leap days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610660b6-718a-418a-8b0d-8b7ac800b9c7",
   "metadata": {},
   "source": [
    "Next, we'll use the station data to perform the bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad05b7f-7f89-4d99-9121-7f4ce9c4df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_correct(obs_da, da, nquantiles=20, group=\"time.dayofyear\", kind=\"+\"): \n",
    "    \"\"\"Perform bias correction using observational data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs_da: xr.DataArray \n",
    "        Observational dataset \n",
    "    da: xr.DataArray \n",
    "        Model data to bias correct \n",
    "    nquantiles: xr.DataArray, optional\n",
    "        The number of quantiles to use\n",
    "        Default to 20\n",
    "    group: str, optional\n",
    "         The grouping information\n",
    "         Default to \"time.dayofyear\" \n",
    "    kind: str, optional \n",
    "         Either additive or multiplicative\n",
    "         Default to additive: \"+\" \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray \n",
    "        Bias corrected input data model_da \n",
    "        \n",
    "    See Also\n",
    "    --------\n",
    "    xclim.sdba.adjustment.QuantileDeltaMapping\n",
    "    \n",
    "    \"\"\"\n",
    "    QDM = QuantileDeltaMapping.train(\n",
    "        obs_da, \n",
    "        # Input data, sliced to time period of observational data\n",
    "        da.sel(time=slice(str(obs_da.time.values[0].year), str(obs_da.time.values[-1].year))), \n",
    "        nquantiles=nquantiles, \n",
    "        group=group,\n",
    "        kind=kind\n",
    "    )\n",
    "    da_adj = QDM.adjust(da)\n",
    "    da_adj.name = da.name\n",
    "    return da_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd0eb1-ade3-40dd-aad1-cfa579e4f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert calendar to exclude leap days\n",
    "#t2_monthly_sac_no_leap = convert_calendar(t2_monthly_sac, \"noleap\")\n",
    "\n",
    "# Bias correct each variable individually because QuantileDeltaMapping can only accept xr.DataArray as input\n",
    "t2_min_bias_corrected = bias_correct(\n",
    "    obs_da, \n",
    "    convert_calendar(t2_monthly_sac[\"Monthly minimum air temperature at 2m\"], \"noleap\")\n",
    ") \n",
    "t2_max_bias_corrected = bias_correct(\n",
    "    obs_da, \n",
    "    convert_calendar(t2_monthly_sac[\"Monthly maximum air temperature at 2m\"], \"noleap\")\n",
    ") \n",
    "\n",
    "# Convert back to pandas datetime \n",
    "# This raises a warning and I'm not sure if it will cause issues down the line\n",
    "t2_min_bias_corrected[\"time\"] = t2_min_bias_corrected.indexes[\"time\"].to_datetimeindex()\n",
    "t2_max_bias_corrected[\"time\"] = t2_max_bias_corrected.indexes[\"time\"].to_datetimeindex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e0924-77f5-47dc-956a-4554f013017a",
   "metadata": {},
   "source": [
    "### 1g) Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f26ca-b94a-4be6-9ca7-42e445c9cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_lineplot(data, dynamic=True, ylim=(0,130),ylabel=\"Air Temperature (degF)\",line_dash=\"solid\"): \n",
    "    \"\"\"Create an interactive lineplot using monthly data for each simulation in the dataset.\n",
    "    Setting dynamic=False (the default) makes the plot take longer to produce upfront, but everything \n",
    "    is zippy after (the developer's personal preference). \n",
    "    Setting dynamic=True means the plot will only be generated once you change the settings.\n",
    "    line_dash options: 'solid', 'dashed', 'dotted', 'dotdash', 'dashdot'\n",
    "    \"\"\"\n",
    "    plots_all = None\n",
    "    for (sim, color) in zip(data.simulation.values,['#377eb8', '#ff7f00', '#4daf4a','#f781bf']):\n",
    "        plot_i = data.sel(simulation=sim).hvplot.line(\n",
    "            groupby=\"time.month\", \n",
    "            width=550, height=350, \n",
    "            label=sim,\n",
    "            line_dash=line_dash,\n",
    "            grid=True,\n",
    "            ylabel=ylabel,\n",
    "            color=color,\n",
    "            ylim=ylim, # Set limits of y axis \n",
    "            dynamic=dynamic \n",
    "        )\n",
    "        plots_all = plot_i if plots_all is None else plots_all*plot_i\n",
    "\n",
    "    plots_all = plots_all.opts(legend_position='bottom') # Move legend to bottom of plot \n",
    "    return plots_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46acc4-96c7-43e4-b4dd-778721be4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias corrected data\n",
    "pl1 = interactive_lineplot(t2_min_bias_corrected)\n",
    "pl2 = interactive_lineplot(t2_max_bias_corrected)\n",
    "(pl1*pl2).opts(legend_position='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71188ec7-0de4-45c3-8baf-86b6127a9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1 = interactive_lineplot(t2_monthly_sac[\"Monthly minimum air temperature at 2m\"])\n",
    "pl2 = interactive_lineplot(t2_monthly_sac[\"Monthly maximum air temperature at 2m\"])\n",
    "(pl1*pl2).opts(legend_position='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26f28c-30a0-4f2c-8aa1-9618e418ffdb",
   "metadata": {},
   "source": [
    "## Part 2: Diurnal trends\n",
    "Find the day in each season that has the lowest minimum temperature **or** the highest maximum temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35f4ef-bb64-474d-821a-9984295dbc2d",
   "metadata": {},
   "source": [
    "### 2a) Retrieve the data \n",
    "Same as we've done in Part 1, here we'll grab the data using the `retrieve_from_csv` function and get the closest gridcell to the Sacramento weatherstation.\n",
    "\n",
    "Along with the future 30yr data, we'll also retrieve the Historical Reconstruction ERA5-WRF data from 1981-2010 as our historical baseline. We'll add this data to our plots at the end, so that it can be compared to the future period. By setting `merge` to `False` in the funtion, we're indicating that we want the two datasets returned separately, instead of merged into the same object (which would be incompatible as the datasets cover different time periods and have different dimensions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b33e6-78c4-4519-8c1c-696ffdf7de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_hourly_fut_sim, t2_hourly_historical, t2_hourly_hist_sim = app.retrieve(\"data/config_hourly_2m_temp.csv\", merge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6ae75-8d79-4a29-94ad-e40f7f458a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_hourly_future_sac = get_closest_gridcell(\n",
    "    data=t2_hourly_fut_sim,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")\n",
    "t2_hourly_historical_sac = get_closest_gridcell(\n",
    "    data=t2_hourly_hist_sim,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")\n",
    "t2_hourly_reconstruction_sac = get_closest_gridcell(\n",
    "    data=t2_hourly_historical,\n",
    "    lat=one_station.LAT_Y,\n",
    "    lon=one_station.LON_X, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3155190-a6cc-4649-be86-3608a550fba7",
   "metadata": {},
   "source": [
    "### 2b) Read the data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ffd7c-6ae0-4323-8e6c-a3c76a60308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2_hourly_future_sac = app.load(t2_hourly_future_sac)\n",
    "t2_hourly_historical_sac = app.load(t2_hourly_historical_sac)\n",
    "t2_hourly_reconstruction_sac = app.load(t2_hourly_reconstruction_sac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd25e21-5c5a-48da-9639-07fa2d4ce95e",
   "metadata": {},
   "source": [
    "### 2c) Extract extreme diurnal cycle from each simulation\n",
    "Here is a function to return the diurnal cycle of a day in which a particular extreme occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a29cc1-8f10-4abd-8886-99b303d4e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diurnal_cycle_by_season(y, how):\n",
    "    if how == 'min':\n",
    "        index_value_is_reached = y.argmin().values\n",
    "    elif how == 'min_daily_max':\n",
    "        max_daily = y.resample(time='1D').max()\n",
    "        index_value_is_reached = max_daily.argmin().values\n",
    "    elif how == 'max_daily_range':\n",
    "        daily_range = y.resample(time='1D').max() - y.resample(time='1D').min()\n",
    "        index_value_is_reached = daily_range.argmax().values\n",
    "\n",
    "    time_value_is_reached = y.isel(time=index_value_is_reached).time.values\n",
    "    day_value_is_reached = pd.to_datetime(time_value_is_reached).date()\n",
    "    diurnal_cycle = y.sel(time=slice(day_value_is_reached,pd.tseries.offsets.DateOffset(hour=23)+day_value_is_reached))\n",
    "    return xr.DataArray(diurnal_cycle.squeeze().values,coords={\"time_of_day\":diurnal_cycle.time.dt.hour.values})\n",
    "\n",
    "def get_diurnal_cycle(t2_hourly_one_season,how='min'):\n",
    "    return t2_hourly_one_season.groupby('time.season').apply(get_diurnal_cycle_by_season,how=how)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8386978-c4d0-48c0-a122-23e01fdd23a4",
   "metadata": {},
   "source": [
    "Choose which extreme you are interested in by setting `method` to `\"min\"` or `\"min_daily_max\"` or `\"max_daily_range\"`. We'll find the diurnal cycle for the entire day in which this occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170056d-151c-4047-8c49-22fa15a85413",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'max_daily_range' #'min', 'min_daily_max'\n",
    "diurnal_cycle_sims_all_fut = t2_hourly_future_sac.groupby('simulation').apply(get_diurnal_cycle,how=method) \n",
    "diurnal_cycle_sims_all_hist = t2_hourly_historical_sac.groupby('simulation').apply(get_diurnal_cycle,how=method)\n",
    "diurnal_cycle_reconstruct = t2_hourly_reconstruction_sac.groupby('simulation').apply(get_diurnal_cycle,how=method)\n",
    "# note: could stack on scenario *and* simulation, and then groupby that combined dim if there were more than one scenario selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f51e2b-c1f6-41e0-b9a9-0f6bdae6e84b",
   "metadata": {},
   "source": [
    "### 2d) Plot the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f390a29-aa2e-4961-89ce-711393ae44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_future = diurnal_cycle_sims_all_fut.hvplot.line(\n",
    "            x=\"time_of_day\", \n",
    "            by=\"simulation\",\n",
    "            grid=True, \n",
    "            xlabel=\"Hour of Day\",\n",
    "            width=575, height=250,\n",
    "        ) \n",
    "\n",
    "plots_historical = diurnal_cycle_sims_all_hist.hvplot.line(\n",
    "            x=\"time_of_day\", \n",
    "            by=\"simulation\",\n",
    "            grid=True, \n",
    "            xlabel=\"Hour of Day\",\n",
    "            width=575, height=250,\n",
    "        ) \n",
    "\n",
    "plot_reconstruct = diurnal_cycle_reconstruct.hvplot.line(\n",
    "            x=\"time_of_day\", \n",
    "            by=\"simulation\",\n",
    "            line_dash=\"dashed\",\n",
    "            color=\"black\",\n",
    "            grid=True, \n",
    "            xlabel=\"Hour of Day\",\n",
    "            width=575, height=250,\n",
    "        ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c27b9-105a-41f3-986f-5f4cbd7c1125",
   "metadata": {},
   "source": [
    "This now takes a moment to generate... \n",
    "\n",
    "Recall, also, that these data are not bias-corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974f0af-e97e-410a-ab7d-441aac6854fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruct * plots_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7bb34-a300-44b3-a8c1-5d2f2ae2164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94ce7b-ff40-4c0e-be16-d390bcebd202",
   "metadata": {},
   "source": [
    "### 2e) Observe the output data structure\n",
    "The data used to generate the plots above are available in the xr.DataArray object `diurnal_data`, computed in the code cell above. Here, we'll display the data so that you can observe the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa2713-0a01-426c-80f2-50a88a998493",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(diurnal_cycle_sims_all_fut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6bca92-28ad-4554-baea-33e2bcd328aa",
   "metadata": {},
   "source": [
    "### 2d) Export the results \n",
    "Choose your desired filetype (we recommend NetCDF) and export the data. We've left the actual export code, `app.export_dataset` commented out; if you want to save the file, simply remove the comment (#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50069a63-766a-49b0-80b2-6aeaf587b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.export_as()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5b605-48ed-4fec-aa3f-237fa938e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#app.export_dataset(diurnal_data, file_name=\"diurnal_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
