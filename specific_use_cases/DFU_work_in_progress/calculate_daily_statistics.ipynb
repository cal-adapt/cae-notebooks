{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f74c6a-e69a-4036-8fe6-43eaa7d6cd9b",
   "metadata": {},
   "source": [
    "# Calculate daily min, mean, max, and mean temperatures\n",
    "In this notebook, building on the methods covered in the Intro to Annual Consumption Models notebook on reproducing an annual consumption model, we find the daily min, max, mean temperature at target grid cells and/or forecast zones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27471aed-896e-4449-a8dc-f6a1382b2f9b",
   "metadata": {},
   "source": [
    "## Step 0: Set-up \n",
    "Load in the libraries, and define the climakitae `app` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadeb6a-17e8-4fb7-94e7-5ca910fdde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils_notebook_1 import *\n",
    "from climakitae.utils import get_closest_gridcell\n",
    "from climakitae.selectors import Boundaries\n",
    "import climakitae as ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51844ec7-0c0e-4b40-bf73-7d082c8cbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ck.Application()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47947f82-c5ba-4c6b-b18c-0314cd39ce2f",
   "metadata": {},
   "source": [
    "## Step 1: Read in the data \n",
    "For this notebook, we'll read in daily data instead of hourly data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c091088-541c-4251-8ef7-45a08faf1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = app.retrieve(\"data/config_daily_data.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cade98-6a39-44ea-8d00-3af22ba413b1",
   "metadata": {},
   "source": [
    "## Step 2: Read in the station data\n",
    "Like in the intro notebook, we'll demo how to do this for the Sacramento weather station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1733b-da05-4f8e-95b4-fb84a6dcb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(\"data/CEC_Forecast_Weather Stations_California.csv\", index_col=\"STATION\")\n",
    "station_name = \"SACRAMENTO EXECUTIVE AIRPORT\"\n",
    "one_station = stations_df.loc[station_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ba928-1793-458a-b9ae-b97bfdbd0af2",
   "metadata": {},
   "source": [
    "## Step 3: Find the daily min, max, mean values for each data variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b600d3-1364-4af5-b64d-0ff342caec5e",
   "metadata": {},
   "source": [
    "### 3a) Decide if you want to use the closest grid cell, or aggregate to the DFZ \n",
    "We reccommend aggregating the data to the nearest demand forecast zone, but we've also provided the code to use the single closest grid cell to the station instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1902be-779a-4440-ab6c-a1c9730af993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method = \"closest grid cell\" \n",
    "method = \"aggregated DFZ\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a3901-3a62-461d-a5ab-acc488b58f79",
   "metadata": {},
   "source": [
    "### 3b) Compute the daily statistics using your method of choice\n",
    "Here, we show you how to compute the median across the demand forecast zone, but you can also aggregate by min, max, or mean-- see the intro notebook for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7956148-7f84-4ef3-b7cf-0a531763bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip data to get just the single closest grid cell\n",
    "if method == \"closest grid cell\": \n",
    "    daily_data_clipped = get_closest_gridcell(daily_data, one_station.LAT_Y, one_station.LON_X)\n",
    "\n",
    "# Clip data to the demand forecast zone, aggregate across all grid cells \n",
    "elif method == \"aggregated DFZ\": \n",
    "    dfzs_df = Boundaries()._ca_forecast_zones # Load geometries from catalog\n",
    "    daily_data_clipped = clip_data_to_dfz(daily_data, dfzs_df, one_station.LAT_Y, one_station.LON_X)\n",
    "    daily_data_clipped = daily_data_clipped.median(dim=[\"x\",\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af12aa9-ef5c-4d71-90f0-62be32c2c7d6",
   "metadata": {},
   "source": [
    "## Step 4: Output the data to csv files \n",
    "First, we'll load the data into memory. Then, we will convert the xarray dataset to a pandas dataframe object. Lastly, we will output the dataframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e4962-cd52-4943-8a72-7f6e769e9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "daily_data_clipped = app.load(daily_data_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20d091-a060-41e0-a1f8-9bc9ab45c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = daily_data_clipped.isel(scenario=0).drop([\"Lambert_Conformal\",\"scenario\"]).to_dataframe()\n",
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe764c-818c-4414-8012-b46ff2c70855",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"daily_2m_temp_{0}.csv\".format(station_name.replace(\" \", \"_\").lower())\n",
    "daily_df.to_csv(filename, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
