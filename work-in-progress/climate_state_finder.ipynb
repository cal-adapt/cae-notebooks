{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ee3e7d-8397-4383-809b-1c5a23e9fb1e",
   "metadata": {},
   "source": [
    "# Climate State Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c601fd-4892-4713-ba0d-75b453f41996",
   "metadata": {},
   "source": [
    "The goal of this notebook is to develop a generalized climate state finder. Based on user selected variable and event definitions, this notebook will search all simulations to find these climate states. The inputs required are:\n",
    "\n",
    "* Domain, a custom shapefile\n",
    "* One variable\n",
    "* GWL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612af064-2439-4416-8f2b-9cc641175cc4",
   "metadata": {},
   "source": [
    "## Make Selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98876bb5-eb4a-448b-b440-2ce1c1c91a1b",
   "metadata": {},
   "source": [
    "Before running this notebook, make the following selections for variables, spatial domain, and GWLs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc07b4-1887-4113-a741-975752391580",
   "metadata": {},
   "source": [
    "1. Select a timescale - this will impact which downscaling methods are available and which variables are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0e8074-415d-4dce-8274-03b37469d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "timescale = \"monthly\" # options are hourly, daily or monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d7e4d-32cb-4061-a2ce-7dc430bd12c1",
   "metadata": {},
   "source": [
    "2. Select a variable - the code below displays which variables are available based on your timescale options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c0c835-a62b-407a-b86b-acffe61f076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function \n",
    "from climakitae.explore.agnostic import (\n",
    "  show_available_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6811ac5-99ad-4338-bd5d-ad62c48e0c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Air Temperature at 2m',\n",
       " 'Precipitation (total)',\n",
       " 'Relative humidity',\n",
       " 'Dew point temperature',\n",
       " 'Mean wind speed at 10m',\n",
       " 'Maximum wind speed at 10m',\n",
       " 'Surface Pressure',\n",
       " 'Specific humidity at 2m',\n",
       " 'Surface skin temperature',\n",
       " 'Maximum air temperature at 2m',\n",
       " 'Minimum air temperature at 2m',\n",
       " 'Instantaneous downwelling longwave flux at bottom',\n",
       " 'Instantaneous downwelling shortwave flux at bottom',\n",
       " 'Shortwave flux at the surface',\n",
       " 'Longwave flux at the surface',\n",
       " 'Sensible heat flux at the surface',\n",
       " 'Latent heat flux at the surface',\n",
       " 'Ground heat flux',\n",
       " 'Snowfall',\n",
       " 'Liquid water path',\n",
       " 'Evaporation',\n",
       " 'Ice water path',\n",
       " 'Maximum precipitation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display variables available for this analysis \n",
    "# only showing dynamical because statistical has a smaller subset that is in the larger dynamical subset\n",
    "# only difference is max/min RH is available in statistical and not in dynamical \n",
    "show_available_vars(\"Dynamical\", timescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea1adce-b9fe-4479-9da9-ec392039ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make selection from list above\n",
    "climate_variable = \"Precipitation (total)\"\n",
    "climate_units = \"inches\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0873e7-83ad-4044-aa26-1183f6044d64",
   "metadata": {},
   "source": [
    "3. Select a baseline and future GWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c3c6a5-fbaf-4535-b659-8029d42b62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current options 0.8, 1.0, 1.2, 1.5, 2.0, 2.5, 3.0, 4.0\n",
    "baseline_gwl = \"1.0\"\n",
    "future_gwl = \"1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aac9e5-44a3-43e7-b44b-5b5257755757",
   "metadata": {},
   "source": [
    "4. Select Spatial Domain - provide a shapefile to clip data to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec62d0b-c833-4609-aaa5-416a269d05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit path below and filename for shapefile to use\n",
    "\n",
    "shapefile_filename = \"PajaroRiverWatershed.zip\" # replace ellipsis with filepath\n",
    "spatial_domain_name = \"Pajaro\" # name will appear in title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5574cc-c162-4f39-b5c5-9c87c3cc63b3",
   "metadata": {},
   "source": [
    "5. Select Resolution - select the the model resolution (3km, 9km, 45 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a1abee-5334-489b-8d95-f91974158bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = \"3 km\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828df712-8501-4169-ba84-486acc511d60",
   "metadata": {},
   "source": [
    "6. Aggregation Method - select a method to aggregate spatially and temporally (to monthly values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94425267-9b6f-4c97-9cbe-eb54919e7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = \"mean\" # options are mean, median, sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd3228-4cb9-44ec-8ca9-2d8d4a3d35da",
   "metadata": {},
   "source": [
    "7. Climate State Duration - how often should the climate state be observed to be considered a 'hit' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1749a1e9-23f5-4f8e-ba16-f8ef2ecafcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration (in months)\n",
    "duration = 24 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be9c1f-3fd0-4be2-a828-a9f7af435716",
   "metadata": {},
   "source": [
    "## Import libraries & define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38b3b70-0973-40d5-b935-ff1810bcbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climakitae as ck \n",
    "from climakitae.core.data_interface import (\n",
    "    get_data_options, \n",
    "    get_subsetting_options, \n",
    "    get_data\n",
    ")\n",
    "from climakitae.util.utils import add_dummy_time_to_wl\n",
    "from climakitae.core.data_load import load\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2eb0cf2-0f66-4559-9607-c9685d39e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_to_shapefile(da, shapefile):\n",
    "    \"\"\"\n",
    "    Clip a DataArray to the boundaries of a shapefile.\n",
    "\n",
    "    Parameters:\n",
    "    - da: xarray DataArray to be clipped\n",
    "    - shapefile: path to the shapefile\n",
    "\n",
    "    Returns:\n",
    "    - Clipped DataArray\n",
    "    \"\"\"\n",
    "    # Read the shapefile using geopandas\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "\n",
    "    # Ensure the DataArray has a CRS set\n",
    "    #da.rio.write_crs(\"epsg:2228\", inplace=True)\n",
    "\n",
    "    # Clip the DataArray using the shapefile geometry\n",
    "    clipped_da = da.rio.clip(gdf.geometry.apply(mapping), gdf.crs, drop=True)\n",
    "\n",
    "    return clipped_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c643f2-faea-4622-987f-a46bca8bbc6f",
   "metadata": {},
   "source": [
    "## Pull Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67a88e-b84f-4823-9938-85dc268b157c",
   "metadata": {},
   "source": [
    "### Dynamical Downscaling (wrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9a14cc-0d1a-4ca2-ab0a-65a7d00f5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! Returned data array is large. Operations could take up to 5x longer than 1GB of data!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n"
     ]
    }
   ],
   "source": [
    "# WRF downscaling\n",
    "wrf_data =get_data(\n",
    "        variable = climate_variable, \n",
    "        downscaling_method = \"Dynamical\", \n",
    "        resolution = resolution, \n",
    "        timescale = timescale, \n",
    "        units = climate_units,\n",
    "        # Modify your approach \n",
    "        approach = \"Warming Level\",\n",
    "        warming_level= [float(baseline_gwl), float(future_gwl)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71cd41d-c23b-4303-89e6-e37014c71917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename lat lon\n",
    "wrf_data=wrf_data.rename({'x': 'longitude','y': 'latitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64611aea-c0ac-4c4f-9fd7-c6623959f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dummy time variable\n",
    "wrf_data = add_dummy_time_to_wl(wrf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab154ab-c11b-4098-ab79-21526495c8ba",
   "metadata": {},
   "source": [
    "### Statistical Downscaling (LOCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa1f0a17-4992-4403-9043-bfb77f5cea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab correct variable name for LOCA2\n",
    "loca_variable = [climate_variable]\n",
    "# temperature\n",
    "if loca_variable[0] == \"Air Temperature at 2m\":\n",
    "    loca_variable = [\"Maximum air temperature at 2m\", \"Minimum air temperature at 2m\"]\n",
    "# relative humidity\n",
    "if loca_variable[0] == \"Relative humidity\":\n",
    "    loca_variable = [\"Minimum relative humidity\", \"Maximum relative humidity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a9e2211-574f-4d30-9b8f-3e980157bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!!! Returned data array is huge. Operations could take 10x to infinity longer than 1GB of data !!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n"
     ]
    }
   ],
   "source": [
    "# statistical - LOCA2 downscaling variable\n",
    "loca_data = [get_data(\n",
    "        variable = GETVAR, \n",
    "        downscaling_method = \"Statistical\", \n",
    "        resolution = resolution, \n",
    "        units = climate_units,\n",
    "        timescale = timescale, \n",
    "        # Modify your approach \n",
    "        approach = \"Warming Level\",\n",
    "        warming_level= [float(baseline_gwl),float(future_gwl)],\n",
    "    ) for GETVAR in loca_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58948571-9b47-447f-ae6f-e1066ca1ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we need to average \n",
    "if loca_data[0] is not None:\n",
    "    # temperature\n",
    "    if climate_variable == \"Air Temperature at 2m\":\n",
    "        loca_data = (loca_data[0] + loca_data[1]) / 2\n",
    "        loca_data.name = \"Air Temperature at 2m\"\n",
    "        \n",
    "    # relative humidity\n",
    "    if climate_variable == \"Relative humidity\":\n",
    "        loca_data = (loca_data[0] + loca_data[1]) / 2\n",
    "        loca_data.name = \"Relative humidity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa6a5589-a5ff-43fa-b49b-26962d9d70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlist if needed\n",
    "if type(loca_data) == list:\n",
    "    loca_data = loca_data[0]\n",
    "\n",
    "# now merge\n",
    "# first check if there is valid loca data - requires that both x and y have valid data\n",
    "if loca_data is None:\n",
    "    # set to wrf\n",
    "    loca_data = wrf_data\n",
    "    # replace with all NaNs\n",
    "    loca_data = loca_data*np.nan\n",
    "else:\n",
    "    loca_data=loca_data.rename({'lon': 'longitude','lat': 'latitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91536ba1-ef61-431f-82f5-b1d723c10d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dummy time variable\n",
    "loca_data = add_dummy_time_to_wl(loca_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669dd36-e6c5-4aee-9b59-6c48c728702f",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d84a6020-afad-4686-974b-311a674ce647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to shapefile\n",
    "wrf_data = clip_to_shapefile(wrf_data, shapefile_filename)\n",
    "loca_data = clip_to_shapefile(loca_data, shapefile_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c3c36e9-6fa4-4c7d-af93-49286780795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create monthly aggegations\n",
    "if timescale != \"monthly\":\n",
    "    wrf_data = eval(f\"wrf_data.resample(time = '1M').{aggregation}()\")\n",
    "    loca_data = eval(f\"loca_data.resample(time = '1M').{aggregation}()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdfbc289-d40f-40a9-8e56-70a3e176efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across domain (we want single timeseries)\n",
    "wrf_data = eval(f\"wrf_data.{aggregation}(['longitude','latitude'])\")\n",
    "loca_data = eval(f\"loca_data.{aggregation}(['longitude','latitude'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bb5ec-5146-4f6d-8f46-7f36ae1b7467",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd6a16-fbf2-4fe5-a91f-762e57c44d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data to read 725.62 KB of data into memory... \n",
      "[###########                             ] | 29% Completed | 34.42 ss"
     ]
    }
   ],
   "source": [
    "loca_data = load(loca_data, progress_bar=True)\n",
    "wrf_data = load(wrf_data, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe193e50-ae75-4f14-8d5d-2c9829c76f69",
   "metadata": {},
   "source": [
    "## Calculate Anomaly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94750a38-5a74-42dd-808e-20a5a6b82057",
   "metadata": {},
   "source": [
    "### Calculate climatological mean of baseline gwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5108648-6f16-46b2-8632-eeb1f54c2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate monthly mean for each simulation for the baseline gwl\n",
    "loca_clim_mean = loca_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\").median()\n",
    "wrf_clim_mean = wrf_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\").median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2927b57-6057-4a17-b765-e315a1dc8b45",
   "metadata": {},
   "source": [
    "### Calculate anomaly of future gwl to climatological mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499753b8-af6c-4b9c-8af2-08d6389fac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the monthly climatology from the future gwl data to create an anomaly\n",
    "loca_anom = loca_data.sel(warming_level = float(future_gwl)).groupby(\"time.month\") - loca_clim_mean\n",
    "wrf_anom = wrf_data.sel(warming_level = float(future_gwl)).groupby(\"time.month\") - wrf_clim_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf141613-804f-40c1-8277-dce7aca94ab9",
   "metadata": {},
   "source": [
    "### Calculate Rolling Average Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b35ad-c374-442f-98d3-ec6ab6e2447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loca_anom = loca_anom.rolling(time=duration).median()\n",
    "wrf_anom= wrf_anom.rolling(time=duration).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ccf6f-cadd-4e7f-8851-e7d7caa43662",
   "metadata": {},
   "source": [
    "## Define Climate States "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a0634-8efd-4c65-b20f-9c7926f158e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate historical anomaly\n",
    "hist_loca_anom = loca_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\") - loca_clim_mean\n",
    "hist_wrf_anom = wrf_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\") - wrf_clim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58630137-5812-4248-af9c-79c434d4f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rolling average\n",
    "hist_loca_anom = hist_loca_anom.rolling(time=duration).median()\n",
    "hist_wrf_anom = hist_wrf_anom.rolling(time=duration).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2cfa0-dddf-4242-9f7b-de19274f57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an upper and lower threshold \n",
    "locaHigh = hist_loca_anom.quantile(q=0.75,dim=\"time\")\n",
    "locaLow = hist_loca_anom.quantile(q=0.25,dim=\"time\")\n",
    "wrfHigh = hist_wrf_anom.quantile(q=0.75,dim=\"time\")\n",
    "wrfLow = hist_wrf_anom.quantile(q=0.25,dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620af47-22e7-45e3-a40f-3881f7cb2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "locaLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c2021-6114-43f3-ad6e-8ade70347db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to data array\n",
    "wrf_anom = wrf_anom.assign_coords(climate_state_high = (\"simulation\",wrfHigh.values))\n",
    "wrf_anom = wrf_anom.assign_coords(climate_state_low = (\"simulation\",wrfLow.values))\n",
    "loca_anom = loca_anom.assign_coords(climate_state_high = (\"simulation\",locaHigh.values))\n",
    "loca_anom = loca_anom.assign_coords(climate_state_low = (\"simulation\",locaLow.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b13c9-e6fd-43d0-a66c-8bc52de0e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a 'hit' for in climate state\n",
    "# initialize an array to fill\n",
    "wrfClimateHit = np.zeros(wrf_anom.values.shape)\n",
    "locaClimateHit = np.zeros(loca_anom.values.shape)\n",
    "\n",
    "# loop through each time stamp\n",
    "for itime in range(0,len(wrf_anom[\"time\"])):\n",
    "    # look at this time stamp + duration \n",
    "    timeIndex = list(range(itime,(itime+duration)))\n",
    "    # remove any values that are greater than our time\n",
    "    timeIndex = [x for x in timeIndex if x < len(wrf_anom[\"time\"])]\n",
    "\n",
    "    ### Start with WRF\n",
    "    # pull out the data to test\n",
    "    testWRFData = wrf_anom[timeIndex,:]\n",
    "    \n",
    "    # for each simulation, check if the values are greater (less) than upper (lower) threshold\n",
    "    wrfHighCounts = (testWRFData > wrfHigh).sum(dim=\"time\")\n",
    "    wrfLowCounts = (testWRFData < wrfLow).sum(dim=\"time\")\n",
    "\n",
    "    # if you have greater than or equal to duration, count as a 'hit'\n",
    "    wrfHighHitIndex = (wrfHighCounts >= duration)\n",
    "    wrfLowHitIndex = (wrfLowCounts >= duration)\n",
    "\n",
    "    # now save hits\n",
    "    wrfClimateHit[np.ix_(timeIndex,wrfHighHitIndex)]  = 1 \n",
    "    wrfClimateHit[np.ix_(timeIndex,wrfLowHitIndex)] = -1 \n",
    "\n",
    "    ### Move to LOCA2\n",
    "    # pull out the data to test\n",
    "    testLOCAData = loca_anom[timeIndex,:]\n",
    "    \n",
    "    # for each simulation, check if the values are greater (less) than upper (lower) threshold\n",
    "    locaHighCounts = (testLOCAData > locaHigh).sum(dim=\"time\")\n",
    "    locaLowCounts = (testLOCAData < locaLow).sum(dim=\"time\")\n",
    "\n",
    "    # if you have greater than or equal to duration, count as a 'hit'\n",
    "    locaHighHitIndex = (locaHighCounts >= duration)\n",
    "    locaLowHitIndex = (locaLowCounts >= duration)\n",
    "\n",
    "    # now save hits\n",
    "    locaClimateHit[np.ix_(timeIndex,locaHighHitIndex)] = 1 \n",
    "    locaClimateHit[np.ix_(timeIndex,locaLowHitIndex)] = -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9e2bb-bd96-4059-8bbd-b74bdae42cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add hits to xarray as a new \n",
    "wrf_anom = wrf_anom.to_dataset()\n",
    "wrf_anom = wrf_anom.assign(climate_state_hit=((\"time\",\"simulation\"),wrfClimateHit))\n",
    "loca_anom = loca_anom.to_dataset()\n",
    "loca_anom = loca_anom.assign(climate_state_hit=((\"time\",\"simulation\"),locaClimateHit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc80ca-eb15-41a1-a90a-b546a0b3546a",
   "metadata": {},
   "source": [
    "## Prep for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8892616-c82b-4230-8840-85c8189544fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 'model' variable\n",
    "lsims=loca_anom.simulation.values.tolist()\n",
    "loca_models = [s.split(\"_\")[1] for s in lsims]\n",
    "loca_anom = loca_anom.assign_coords(models = (\"simulation\",loca_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9168902-1f08-4fb4-be17-2d96a6715568",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsims=wrf_anom.simulation.values.tolist()\n",
    "wrf_models = [s.split(\"_\")[1] for s in wsims]\n",
    "wrf_anom = wrf_anom.assign_coords(models = (\"simulation\",wrf_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724f970-3402-4c37-8f8f-4a544ab4661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame to make plotting easier\n",
    "locaDF = loca_anom.to_dataframe().reset_index()\n",
    "wrfDF = wrf_anom.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a56e83-ca61-453f-aadc-37c867bfeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a downscaling name\n",
    "locaDF[\"downscaling\"] = \"loca2\"\n",
    "wrfDF[\"downscaling\"] = \"wrf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e34d6e-3c3d-4f1c-b95f-1ebd4d18036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into one \n",
    "finalDF = pd.concat([locaDF, wrfDF],keys=locaDF.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b75c8-8ff9-4d99-bf48-18348435b1cd",
   "metadata": {},
   "source": [
    "## Plot Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e029b-e5ca-4a7b-b9cb-4a0f649ac220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the data \n",
    "def annotate(data, **kws):\n",
    "    ax = plt.gca()\n",
    "    ax.axhline(0, ls='--',color=\"black\")\n",
    "    ax.fill_between(data.time,data[climate_variable],where=data.climate_state_hit == 1,facecolor='maroon',alpha=.5)\n",
    "    ax.fill_between(data.time,data[climate_variable],where=data.climate_state_hit == -1,facecolor='darkblue',alpha=.5)\n",
    "g1 = sns.relplot(\n",
    "    data=finalDF,\n",
    "    x=\"time\", y=climate_variable,\n",
    "    col=\"simulation\",color=\"black\",col_wrap=4,\n",
    "    kind=\"line\", \n",
    "    height=5, aspect=1, facet_kws=dict(sharex=False), \n",
    ")\n",
    "g1.map_dataframe(annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762ffe8-9b55-4e0b-8e1a-13c9442657b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for saving everything, if it does not exist already\n",
    "folder_path = \"climate_state\"  # Replace with your desired folder path\n",
    "\n",
    "try:\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    print(f\"Folder '{folder_path}' created successfully or already exists.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating folder '{folder_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3f4b7-b3a7-48ac-887f-cd12dd5173b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure to a file\n",
    "g1.savefig(f'climate_state/climate_state_finder_{climate_variable}_under_{future_gwl}gwl_with_{duration}{timescale}duration.jpeg'.replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bba684-d9c2-4bb8-a915-80cdf4f4e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a variable called 'wrf' and 'loca2' into the data\n",
    "wrf_anom[\"downscaling\"] = \"wrf\"\n",
    "loca_anom[\"downscaling\"] = \"loca2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde73517-23da-4946-a80b-6747cfae64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat\n",
    "final = xr.concat([loca_anom,wrf_anom],dim=\"simulation\",\n",
    "                         coords=\"minimal\",compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c8239-f7aa-4f70-aa00-7fd4f703ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save climate state data (to be loaded into event finder)\n",
    "final.to_netcdf(f'climate_state/climate_state_{climate_variable}_under_{future_gwl}gwl_with_{duration}{timescale}duration.nc'.replace(\" \", \"_\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
