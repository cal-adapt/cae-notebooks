{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ee3e7d-8397-4383-809b-1c5a23e9fb1e",
   "metadata": {},
   "source": [
    "# Climate State Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c601fd-4892-4713-ba0d-75b453f41996",
   "metadata": {},
   "source": [
    "The goal of this notebook is to develop a generalized climate state finder. Based on user selected variable and event definitions, this notebook will search all simulations to find these climate states. The inputs required are:\n",
    "\n",
    "* Domain, a custom shapefile\n",
    "* One variable\n",
    "* GWL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612af064-2439-4416-8f2b-9cc641175cc4",
   "metadata": {},
   "source": [
    "## Make Selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98876bb5-eb4a-448b-b440-2ce1c1c91a1b",
   "metadata": {},
   "source": [
    "Before running this notebook, make the following selections for variables, spatial domain, and GWLs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc07b4-1887-4113-a741-975752391580",
   "metadata": {},
   "source": [
    "1. Select a timescale - this will impact which downscaling methods are available and which variables are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0e8074-415d-4dce-8274-03b37469d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "timescale = \"monthly\" # options are hourly, daily or monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d7e4d-32cb-4061-a2ce-7dc430bd12c1",
   "metadata": {},
   "source": [
    "2. Select a variable - the code below displays which variables are available based on your timescale options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c0c835-a62b-407a-b86b-acffe61f076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function \n",
    "from climakitae.explore.agnostic import (\n",
    "  show_available_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6811ac5-99ad-4338-bd5d-ad62c48e0c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Air Temperature at 2m',\n",
       " 'Precipitation (total)',\n",
       " 'Relative humidity',\n",
       " 'Dew point temperature',\n",
       " 'Mean wind speed at 10m',\n",
       " 'Maximum wind speed at 10m',\n",
       " 'Surface Pressure',\n",
       " 'Specific humidity at 2m',\n",
       " 'Surface skin temperature',\n",
       " 'Maximum air temperature at 2m',\n",
       " 'Minimum air temperature at 2m',\n",
       " 'Instantaneous downwelling longwave flux at bottom',\n",
       " 'Instantaneous downwelling shortwave flux at bottom',\n",
       " 'Shortwave flux at the surface',\n",
       " 'Longwave flux at the surface',\n",
       " 'Sensible heat flux at the surface',\n",
       " 'Latent heat flux at the surface',\n",
       " 'Ground heat flux',\n",
       " 'Snowfall',\n",
       " 'Liquid water path',\n",
       " 'Evaporation',\n",
       " 'Ice water path',\n",
       " 'Maximum precipitation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display variables available for this analysis \n",
    "# only showing dynamical because statistical has a smaller subset that is in the larger dynamical subset\n",
    "# only difference is max/min RH is available in statistical and not in dynamical \n",
    "show_available_vars(\"Dynamical\", timescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea1adce-b9fe-4479-9da9-ec392039ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make selection from list above\n",
    "climate_variable = \"Precipitation (total)\"\n",
    "climate_units = \"inches\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0873e7-83ad-4044-aa26-1183f6044d64",
   "metadata": {},
   "source": [
    "3. Select a baseline and future GWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c3c6a5-fbaf-4535-b659-8029d42b62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current options 0.8, 1.0, 1.2, 1.5, 2.0, 2.5, 3.0, 4.0\n",
    "baseline_gwl = \"0.8\"\n",
    "future_gwl = \"0.8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aac9e5-44a3-43e7-b44b-5b5257755757",
   "metadata": {},
   "source": [
    "4. Select Spatial Domain - provide a shapefile to clip data to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec62d0b-c833-4609-aaa5-416a269d05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit path below and filename for shapefile to use\n",
    "\n",
    "shapefile_filename = \"PajaroRiverWatershed.zip\" # replace ellipsis with filepath\n",
    "spatial_domain_name = \"Pajaro\" # name will appear in title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5574cc-c162-4f39-b5c5-9c87c3cc63b3",
   "metadata": {},
   "source": [
    "5. Select Resolution - select the the model resolution (3km, 9km, 45 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a1abee-5334-489b-8d95-f91974158bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = \"3 km\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828df712-8501-4169-ba84-486acc511d60",
   "metadata": {},
   "source": [
    "6. Aggregation Method - select a method to aggregate spatially and temporally (to monthly values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94425267-9b6f-4c97-9cbe-eb54919e7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = \"mean\" # options are mean, median, sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd3228-4cb9-44ec-8ca9-2d8d4a3d35da",
   "metadata": {},
   "source": [
    "7. Climate State Duration - how often should the climate state be observed to be considered a 'hit' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1749a1e9-23f5-4f8e-ba16-f8ef2ecafcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration (in months)\n",
    "duration = 24 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be9c1f-3fd0-4be2-a828-a9f7af435716",
   "metadata": {},
   "source": [
    "## Import libraries & define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38b3b70-0973-40d5-b935-ff1810bcbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climakitae as ck \n",
    "from climakitae.core.data_interface import (\n",
    "    get_data_options, \n",
    "    get_subsetting_options, \n",
    "    get_data\n",
    ")\n",
    "from climakitae.util.utils import add_dummy_time_to_wl\n",
    "from climakitae.core.data_load import load\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2eb0cf2-0f66-4559-9607-c9685d39e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_to_shapefile(da, shapefile):\n",
    "    \"\"\"\n",
    "    Clip a DataArray to the boundaries of a shapefile.\n",
    "\n",
    "    Parameters:\n",
    "    - da: xarray DataArray to be clipped\n",
    "    - shapefile: path to the shapefile\n",
    "\n",
    "    Returns:\n",
    "    - Clipped DataArray\n",
    "    \"\"\"\n",
    "    # Read the shapefile using geopandas\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "\n",
    "    # Ensure the DataArray has a CRS set\n",
    "    #da.rio.write_crs(\"epsg:2228\", inplace=True)\n",
    "\n",
    "    # Clip the DataArray using the shapefile geometry\n",
    "    clipped_da = da.rio.clip(gdf.geometry.apply(mapping), gdf.crs, drop=True)\n",
    "\n",
    "    return clipped_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c643f2-faea-4622-987f-a46bca8bbc6f",
   "metadata": {},
   "source": [
    "## Pull Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67a88e-b84f-4823-9938-85dc268b157c",
   "metadata": {},
   "source": [
    "### Dynamical Downscaling (wrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9a14cc-0d1a-4ca2-ab0a-65a7d00f5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! Returned data array is large. Operations could take up to 5x longer than 1GB of data!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n"
     ]
    }
   ],
   "source": [
    "# WRF downscaling\n",
    "wrf_data =get_data(\n",
    "        variable = climate_variable, \n",
    "        downscaling_method = \"Dynamical\", \n",
    "        resolution = resolution, \n",
    "        timescale = timescale, \n",
    "        units = climate_units,\n",
    "        # Modify your approach \n",
    "        approach = \"Warming Level\",\n",
    "        warming_level= [float(baseline_gwl), float(future_gwl)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71cd41d-c23b-4303-89e6-e37014c71917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename lat lon\n",
    "wrf_data=wrf_data.rename({'x': 'longitude','y': 'latitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64611aea-c0ac-4c4f-9fd7-c6623959f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dummy time variable\n",
    "wrf_data = add_dummy_time_to_wl(wrf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab154ab-c11b-4098-ab79-21526495c8ba",
   "metadata": {},
   "source": [
    "### Statistical Downscaling (LOCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa1f0a17-4992-4403-9043-bfb77f5cea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab correct variable name for LOCA2\n",
    "loca_variable = [climate_variable]\n",
    "# temperature\n",
    "if loca_variable[0] == \"Air Temperature at 2m\":\n",
    "    loca_variable = [\"Maximum air temperature at 2m\", \"Minimum air temperature at 2m\"]\n",
    "# relative humidity\n",
    "if loca_variable[0] == \"Relative humidity\":\n",
    "    loca_variable = [\"Minimum relative humidity\", \"Maximum relative humidity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a9e2211-574f-4d30-9b8f-3e980157bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!!! Returned data array is huge. Operations could take 10x to infinity longer than 1GB of data !!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n"
     ]
    }
   ],
   "source": [
    "# statistical - LOCA2 downscaling variable\n",
    "loca_data = [get_data(\n",
    "        variable = GETVAR, \n",
    "        downscaling_method = \"Statistical\", \n",
    "        resolution = resolution, \n",
    "        units = climate_units,\n",
    "        timescale = timescale, \n",
    "        # Modify your approach \n",
    "        approach = \"Warming Level\",\n",
    "        warming_level= [float(baseline_gwl),float(future_gwl)],\n",
    "    ) for GETVAR in loca_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58948571-9b47-447f-ae6f-e1066ca1ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we need to average \n",
    "if loca_data[0] is not None:\n",
    "    # temperature\n",
    "    if climate_variable == \"Air Temperature at 2m\":\n",
    "        loca_data = (loca_data[0] + loca_data[1]) / 2\n",
    "        loca_data.name = \"Air Temperature at 2m\"\n",
    "        \n",
    "    # relative humidity\n",
    "    if climate_variable == \"Relative humidity\":\n",
    "        loca_data = (loca_data[0] + loca_data[1]) / 2\n",
    "        loca_data.name = \"Relative humidity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa6a5589-a5ff-43fa-b49b-26962d9d70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlist if needed\n",
    "if type(loca_data) == list:\n",
    "    loca_data = loca_data[0]\n",
    "\n",
    "# now merge\n",
    "# first check if there is valid loca data - requires that both x and y have valid data\n",
    "if loca_data is None:\n",
    "    # set to wrf\n",
    "    loca_data = wrf_data\n",
    "    # replace with all NaNs\n",
    "    loca_data = loca_data*np.nan\n",
    "else:\n",
    "    loca_data=loca_data.rename({'lon': 'longitude','lat': 'latitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91536ba1-ef61-431f-82f5-b1d723c10d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dummy time variable\n",
    "loca_data = add_dummy_time_to_wl(loca_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669dd36-e6c5-4aee-9b59-6c48c728702f",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d84a6020-afad-4686-974b-311a674ce647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to shapefile\n",
    "wrf_data = clip_to_shapefile(wrf_data, shapefile_filename)\n",
    "loca_data = clip_to_shapefile(loca_data, shapefile_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c3c36e9-6fa4-4c7d-af93-49286780795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create monthly aggegations\n",
    "if timescale != \"monthly\":\n",
    "    wrf_data = eval(f\"wrf_data.resample(time = '1M').{aggregation}()\")\n",
    "    loca_data = eval(f\"loca_data.resample(time = '1M').{aggregation}()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdfbc289-d40f-40a9-8e56-70a3e176efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across domain (we want single timeseries)\n",
    "wrf_data = eval(f\"wrf_data.{aggregation}(['longitude','latitude'])\")\n",
    "loca_data = eval(f\"loca_data.{aggregation}(['longitude','latitude'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bb5ec-5146-4f6d-8f46-7f36ae1b7467",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cbd6a16-fbf2-4fe5-a91f-762e57c44d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data to read 725.62 KB of data into memory... \n",
      "[########################################] | 100% Completed | 137.91 s\n",
      "Complete!\n",
      "Processing data to read 22.50 KB of data into memory... \n",
      "[########################################] | 100% Completed | 9.40 ss\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "loca_data = load(loca_data, progress_bar=True)\n",
    "wrf_data = load(wrf_data, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe193e50-ae75-4f14-8d5d-2c9829c76f69",
   "metadata": {},
   "source": [
    "## Calculate Anomaly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94750a38-5a74-42dd-808e-20a5a6b82057",
   "metadata": {},
   "source": [
    "### Calculate climatological mean of baseline gwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5108648-6f16-46b2-8632-eeb1f54c2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate monthly mean for each simulation for the baseline gwl\n",
    "loca_clim_mean = loca_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\").median()\n",
    "wrf_clim_mean = wrf_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\").median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2927b57-6057-4a17-b765-e315a1dc8b45",
   "metadata": {},
   "source": [
    "### Calculate anomaly of future gwl to climatological mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "499753b8-af6c-4b9c-8af2-08d6389fac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the monthly climatology from the future gwl data to create an anomaly\n",
    "loca_anom = loca_data.sel(warming_level = float(future_gwl)).groupby(\"time.month\") - loca_clim_mean\n",
    "wrf_anom = wrf_data.sel(warming_level = float(future_gwl)).groupby(\"time.month\") - wrf_clim_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf141613-804f-40c1-8277-dce7aca94ab9",
   "metadata": {},
   "source": [
    "### Calculate Rolling Average Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "852b35ad-c374-442f-98d3-ec6ab6e2447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loca_anom = loca_anom.rolling(time=duration).median()\n",
    "wrf_anom= wrf_anom.rolling(time=duration).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ccf6f-cadd-4e7f-8851-e7d7caa43662",
   "metadata": {},
   "source": [
    "## Define Climate States "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "734a0634-8efd-4c65-b20f-9c7926f158e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate historical anomaly\n",
    "hist_loca_anom = loca_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\") - loca_clim_mean\n",
    "hist_wrf_anom = wrf_data.sel(warming_level = float(baseline_gwl)).groupby(\"time.month\") - wrf_clim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58630137-5812-4248-af9c-79c434d4f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rolling average\n",
    "hist_loca_anom = hist_loca_anom.rolling(time=duration).median()\n",
    "hist_wrf_anom = hist_wrf_anom.rolling(time=duration).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7b2cfa0-dddf-4242-9f7b-de19274f57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an upper and lower threshold \n",
    "locaHigh = hist_loca_anom.quantile(q=0.75,dim=\"time\")\n",
    "locaLow = hist_loca_anom.quantile(q=0.25,dim=\"time\")\n",
    "wrfHigh = hist_wrf_anom.quantile(q=0.75,dim=\"time\")\n",
    "wrfLow = hist_wrf_anom.quantile(q=0.25,dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "369c2021-6114-43f3-ad6e-8ade70347db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable 'climate_state_high': Could not convert tuple of form (dims, data[, attrs, encoding]): ('simulation', array([[0.04533779, 0.15395322, 0.04462019, 0.03803679, 0.22295686,\n        0.02997085, 0.04797653, 0.03863467],\n       [0.04533779, 0.15395322, 0.04462019, 0.03803679, 0.22295686,\n        0.02997085, 0.04797653, 0.03863467]])) to Variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/variable.py:144\u001b[0m, in \u001b[0;36mas_variable\u001b[0;34m(obj, name, auto_convert)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/variable.py:365\u001b[0m, in \u001b[0;36mVariable.__init__\u001b[0;34m(self, dims, data, attrs, encoding, fastpath)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    unrecognized encoding items.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_compatible_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfastpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfastpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/namedarray/core.py:264\u001b[0m, in \u001b[0;36mNamedArray.__init__\u001b[0;34m(self, dims, data, attrs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_dimensions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(attrs) \u001b[38;5;28;01mif\u001b[39;00m attrs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/namedarray/core.py:508\u001b[0m, in \u001b[0;36mNamedArray._parse_dimensions\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dims) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must have the same length as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of data dimensions, ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m     )\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(dims)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(dims):\n",
      "\u001b[0;31mValueError\u001b[0m: dimensions ('simulation',) must have the same length as the number of data dimensions, ndim=2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# add to data array\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wrf_anom \u001b[38;5;241m=\u001b[39m \u001b[43mwrf_anom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_state_high\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimulation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwrfHigh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m wrf_anom \u001b[38;5;241m=\u001b[39m wrf_anom\u001b[38;5;241m.\u001b[39massign_coords(climate_state_low \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation\u001b[39m\u001b[38;5;124m\"\u001b[39m,wrfLow\u001b[38;5;241m.\u001b[39mvalues))\n\u001b[1;32m      4\u001b[0m loca_anom \u001b[38;5;241m=\u001b[39m loca_anom\u001b[38;5;241m.\u001b[39massign_coords(climate_state_high \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation\u001b[39m\u001b[38;5;124m\"\u001b[39m,locaHigh\u001b[38;5;241m.\u001b[39mvalues))\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/common.py:664\u001b[0m, in \u001b[0;36mDataWithCoords.assign_coords\u001b[0;34m(self, coords, **coords_kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_assign_results(coords_combined)\n\u001b[0;32m--> 664\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/coordinates.py:579\u001b[0m, in \u001b[0;36mCoordinates.update\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    577\u001b[0m     other_coords \u001b[38;5;241m=\u001b[39m other\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     other_coords \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_coords_with_default_indexes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvariables\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Discard original indexed coordinates prior to merge allows to:\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# - fail early if the new coordinates don't preserve the integrity of existing\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m#   multi-coordinate indexes\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# - drop & replace coordinates without alignment (note: we must keep indexed\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m#   coordinates extracted from the DataArray objects passed as values to\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m#   `other` - if any - as those are still used for aligning the old/new coordinates)\u001b[39;00m\n\u001b[1;32m    589\u001b[0m coords_to_align \u001b[38;5;241m=\u001b[39m drop_indexed_coords(\u001b[38;5;28mset\u001b[39m(other_coords) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(other), \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/coordinates.py:1130\u001b[0m, in \u001b[0;36mcreate_coords_with_default_indexes\u001b[0;34m(coords, data_vars)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, DataArray):\n\u001b[1;32m   1128\u001b[0m     dataarray_coords\u001b[38;5;241m.\u001b[39mappend(obj\u001b[38;5;241m.\u001b[39mcoords)\n\u001b[0;32m-> 1130\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[43mas_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_convert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variable\u001b[38;5;241m.\u001b[39mdims \u001b[38;5;241m==\u001b[39m (name,):\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;66;03m# still needed to convert to IndexVariable first due to some\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;66;03m# pandas multi-index edge cases.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m     variable \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mto_index_variable()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/variable.py:146\u001b[0m, in \u001b[0;36mas_variable\u001b[0;34m(obj, name, auto_convert)\u001b[0m\n\u001b[1;32m    144\u001b[0m         obj \u001b[38;5;241m=\u001b[39m Variable(dims_, data_, \u001b[38;5;241m*\u001b[39mattrs)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: Could not convert tuple of form \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(dims, data[, attrs, encoding]): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to Variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_scalar(obj):\n\u001b[1;32m    151\u001b[0m     obj \u001b[38;5;241m=\u001b[39m Variable([], obj)\n",
      "\u001b[0;31mValueError\u001b[0m: Variable 'climate_state_high': Could not convert tuple of form (dims, data[, attrs, encoding]): ('simulation', array([[0.04533779, 0.15395322, 0.04462019, 0.03803679, 0.22295686,\n        0.02997085, 0.04797653, 0.03863467],\n       [0.04533779, 0.15395322, 0.04462019, 0.03803679, 0.22295686,\n        0.02997085, 0.04797653, 0.03863467]])) to Variable."
     ]
    }
   ],
   "source": [
    "# add to data array\n",
    "wrf_anom = wrf_anom.assign_coords(climate_state_high = (\"simulation\",wrfHigh.values))\n",
    "wrf_anom = wrf_anom.assign_coords(climate_state_low = (\"simulation\",wrfLow.values))\n",
    "loca_anom = loca_anom.assign_coords(climate_state_high = (\"simulation\",locaHigh.values))\n",
    "loca_anom = loca_anom.assign_coords(climate_state_low = (\"simulation\",locaLow.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b13c9-e6fd-43d0-a66c-8bc52de0e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a 'hit' for in climate state\n",
    "# initialize an array to fill\n",
    "wrfClimateHit = np.zeros(wrf_anom.values.shape)\n",
    "locaClimateHit = np.zeros(loca_anom.values.shape)\n",
    "\n",
    "# loop through each time stamp\n",
    "for itime in range(0,len(wrf_anom[\"time\"])):\n",
    "    # look at this time stamp + duration \n",
    "    timeIndex = list(range(itime,(itime+duration)))\n",
    "    # remove any values that are greater than our time\n",
    "    timeIndex = [x for x in timeIndex if x < len(wrf_anom[\"time\"])]\n",
    "\n",
    "    ### Start with WRF\n",
    "    # pull out the data to test\n",
    "    testWRFData = wrf_anom[timeIndex,:]\n",
    "    \n",
    "    # for each simulation, check if the values are greater (less) than upper (lower) threshold\n",
    "    wrfHighCounts = (testWRFData > wrfHigh).sum(dim=\"time\")\n",
    "    wrfLowCounts = (testWRFData < wrfLow).sum(dim=\"time\")\n",
    "\n",
    "    # if you have greater than or equal to duration, count as a 'hit'\n",
    "    wrfHighHitIndex = (wrfHighCounts >= duration)\n",
    "    wrfLowHitIndex = (wrfLowCounts >= duration)\n",
    "\n",
    "    # now save hits\n",
    "    wrfClimateHit[np.ix_(timeIndex,wrfHighHitIndex)]  = 1 \n",
    "    wrfClimateHit[np.ix_(timeIndex,wrfLowHitIndex)] = -1 \n",
    "\n",
    "    ### Move to LOCA2\n",
    "    # pull out the data to test\n",
    "    testLOCAData = loca_anom[timeIndex,:]\n",
    "    \n",
    "    # for each simulation, check if the values are greater (less) than upper (lower) threshold\n",
    "    locaHighCounts = (testLOCAData > locaHigh).sum(dim=\"time\")\n",
    "    locaLowCounts = (testLOCAData < locaLow).sum(dim=\"time\")\n",
    "\n",
    "    # if you have greater than or equal to duration, count as a 'hit'\n",
    "    locaHighHitIndex = (locaHighCounts >= duration)\n",
    "    locaLowHitIndex = (locaLowCounts >= duration)\n",
    "\n",
    "    # now save hits\n",
    "    locaClimateHit[np.ix_(timeIndex,locaHighHitIndex)] = 1 \n",
    "    locaClimateHit[np.ix_(timeIndex,locaLowHitIndex)] = -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9e2bb-bd96-4059-8bbd-b74bdae42cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add hits to xarray as a new \n",
    "wrf_anom = wrf_anom.to_dataset()\n",
    "wrf_anom = wrf_anom.assign(climate_state_hit=((\"time\",\"simulation\"),wrfClimateHit))\n",
    "loca_anom = loca_anom.to_dataset()\n",
    "loca_anom = loca_anom.assign(climate_state_hit=((\"time\",\"simulation\"),locaClimateHit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc80ca-eb15-41a1-a90a-b546a0b3546a",
   "metadata": {},
   "source": [
    "## Prep for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8892616-c82b-4230-8840-85c8189544fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 'model' variable\n",
    "lsims=loca_anom.simulation.values.tolist()\n",
    "loca_models = [s.split(\"_\")[1] for s in lsims]\n",
    "loca_anom = loca_anom.assign_coords(models = (\"simulation\",loca_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9168902-1f08-4fb4-be17-2d96a6715568",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsims=wrf_anom.simulation.values.tolist()\n",
    "wrf_models = [s.split(\"_\")[1] for s in wsims]\n",
    "wrf_anom = wrf_anom.assign_coords(models = (\"simulation\",wrf_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724f970-3402-4c37-8f8f-4a544ab4661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame to make plotting easier\n",
    "locaDF = loca_anom.to_dataframe().reset_index()\n",
    "wrfDF = wrf_anom.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a56e83-ca61-453f-aadc-37c867bfeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a downscaling name\n",
    "locaDF[\"downscaling\"] = \"loca2\"\n",
    "wrfDF[\"downscaling\"] = \"wrf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e34d6e-3c3d-4f1c-b95f-1ebd4d18036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into one \n",
    "finalDF = pd.concat([locaDF, wrfDF],keys=locaDF.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b75c8-8ff9-4d99-bf48-18348435b1cd",
   "metadata": {},
   "source": [
    "## Plot Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e029b-e5ca-4a7b-b9cb-4a0f649ac220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the data \n",
    "def annotate(data, **kws):\n",
    "    ax = plt.gca()\n",
    "    ax.axhline(0, ls='--',color=\"black\")\n",
    "    ax.fill_between(data.time,data[climate_variable],where=data.climate_state_hit == 1,facecolor='maroon',alpha=.5)\n",
    "    ax.fill_between(data.time,data[climate_variable],where=data.climate_state_hit == -1,facecolor='darkblue',alpha=.5)\n",
    "g1 = sns.relplot(\n",
    "    data=finalDF,\n",
    "    x=\"time\", y=climate_variable,\n",
    "    col=\"simulation\",color=\"black\",col_wrap=4,\n",
    "    kind=\"line\", \n",
    "    height=5, aspect=1, facet_kws=dict(sharex=False), \n",
    ")\n",
    "g1.map_dataframe(annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762ffe8-9b55-4e0b-8e1a-13c9442657b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for saving everything, if it does not exist already\n",
    "folder_path = \"climate_state\"  # Replace with your desired folder path\n",
    "\n",
    "try:\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    print(f\"Folder '{folder_path}' created successfully or already exists.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating folder '{folder_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3f4b7-b3a7-48ac-887f-cd12dd5173b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure to a file\n",
    "g1.savefig(f'climate_state/climate_state_finder_{climate_variable}_under_{future_gwl}gwl_with_{duration}{timescale}duration.jpeg'.replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bba684-d9c2-4bb8-a915-80cdf4f4e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a variable called 'wrf' and 'loca2' into the data\n",
    "wrf_anom[\"downscaling\"] = \"wrf\"\n",
    "loca_anom[\"downscaling\"] = \"loca2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde73517-23da-4946-a80b-6747cfae64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat\n",
    "final = xr.concat([loca_anom,wrf_anom],dim=\"simulation\",\n",
    "                         coords=\"minimal\",compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c8239-f7aa-4f70-aa00-7fd4f703ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save climate state data (to be loaded into event finder)\n",
    "final.to_netcdf(f'climate_state/climate_state_{climate_variable}_under_{future_gwl}gwl_with_{duration}{timescale}duration.nc'.replace(\" \", \"_\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
