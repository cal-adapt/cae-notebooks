{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3cf884-99e9-4d57-b06e-1bd5e28bf2a8",
   "metadata": {},
   "source": [
    "# Event Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a9512-4168-450d-a7f8-a8673acb50f0",
   "metadata": {},
   "source": [
    "The goal of this notebook is to develop a generalized event finder. Based on user selected variable and event definitions, this notebook will search all simulations to find these events.  \n",
    "\n",
    "Inputs:\n",
    "\n",
    "* Domain\n",
    "* Variable\n",
    "* Low and/or High thresholds\n",
    "* Duration \n",
    "* Global Warming Level\n",
    "\n",
    "**Runtime**: With the default settings, this notebook takes approximately 27 minutes to run from start to finish. Modifications to selections may increase the runtime.\n",
    "\n",
    "**Troubleshooting**: Kernel crashing? Try loading a smaller spatial area by setting the `latitude` and `longitude` variables or using a `cached_area`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060f3db-9d70-4adf-8a3a-2d1262284f24",
   "metadata": {},
   "source": [
    "## Make Selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58342c3-171b-4c3f-8484-ba83e129f458",
   "metadata": {},
   "source": [
    "Before running this notebook, make the following selections for variables, domain, and GWLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa10fb54-bcee-4ae6-b2b3-381b619fc5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - Initializing ClimateData interface\n",
      "2026-01-15 19:24:03 - climakitae.new_core.dataset_factory - INFO - DatasetFactory initialized with 3 validators and 10 processors\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - ClimateData initialization successful\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - ✅ Ready to query!\n"
     ]
    }
   ],
   "source": [
    "from climakitae.core.constants import UNSET\n",
    "from climakitae.new_core.user_interface import ClimateData\n",
    "\n",
    "cd = ClimateData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1bee8-e922-42a6-86ce-a1cdeb4152d5",
   "metadata": {},
   "source": [
    "1. Select a timescale - this will impact which downscaling methods are available and which variables are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdddfe99-51b2-4605-9bf4-1735310dcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "timescale = \"day\"  # options are 1hr, day, mon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c120955-37b7-4451-9d01-cd0f90aec6e5",
   "metadata": {},
   "source": [
    "2. Select a variable - the code below displays which variables are available based on your timescale options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d70e60-f97a-4925-a102-93d7301ed801",
   "metadata": {},
   "source": [
    "Here are the options for dynamically downscaled (WRF) variables for selected timescale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476785a8-f9e0-48d9-9b42-54fb475e1142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - Activity ID set to: WRF\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - Table ID set to: day\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - Variables (constrained by current query)::\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - ------------------------------------------\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - cape:                    Convective Available Potential Energy\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - cf:                      Capacity factor\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - cin:                     Convective Inhibition\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - dew_point:               No description available\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - effective_temp_index:    No description available\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - etrans_sfc:              Evapotranspiration\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - evap_sfc:                Evaporation\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - gen:                     Power generation\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - gh_sfc:                  Ground heat flux\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - iwp:                     Ice water path\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - lcl:                     Lifting Condensation Level\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - lfc:                     Level of Free Convection\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - lh_sfc:                  Latent heat flux at the surface\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - lw_dwn:                  Instantaneous downwelling longwave flux at bottom\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - lw_sfc:                  Longwave flux at the surface\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - lwp:                     Liquid water path\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - noaa_heat_index:         No description available\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - pblh:                    Planetary boundary layer height\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - prec:                    Precipitation (total)\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - prec_c:                  Precipitation (convective only)\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - prec_max:                Maximum precipitation\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - prec_snow:               Snowfall\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - psfc:                    Surface Pressure\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - q2:                      Water Vapor Mixing Ratio at 2m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - rh:                      Relative humidity\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - rh_max:                  Maximum relative humidity\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - rh_min:                  Minimum relative humidity\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - sfc_runoff:              Surface runoff\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - sh_sfc:                  Sensible heat flux at the surface\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - snow:                    Snow water equivalent\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - subsfc_runoff:           Subsurface runoff\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - sw_dwn:                  Instantaneous downwelling shortwave flux at bottom\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - sw_sfc:                  Shortwave flux at the surface\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - t2:                      Air Temperature at 2m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - t2max:                   Maximum air temperature at 2m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - t2min:                   Minimum air temperature at 2m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - tskin:                   Surface skin temperature\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - u10:                     West-East component of Wind at 10m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - v10:                     North-South component of Wind at 10m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - wspd10max:               Maximum wind speed at 10m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - wspd10mean:              Mean wind speed at 10m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd.activity_id(\"WRF\").table_id(timescale).show_variable_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d693f-8e4a-47b9-b9e5-a5e7a3411a3f",
   "metadata": {},
   "source": [
    "Here are the options for statistically downscaled (LOCA2) variables for the selected timescale. This is a smaller set than the dynamiclly downscaled variables. Daily average humidity and air temperature are not listed, but can be selected in this notebook by using \"tas\" or \"hurs\" (daily max and min will be averaged)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a723eb7-711a-42ab-b348-cd918c5b4fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - Activity ID set to: LOCA2\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - Table ID set to: day\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - Variables (constrained by current query)::\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - ------------------------------------------\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - hursmax:    Maximum relative humidity\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - hursmin:    Minimum relative humidity\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - huss:       Specific humidity at 2m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - pr:         Precipitation (total)\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - rsds:       Shortwave flux at the surface\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - tasmax:     Maximum air temperature at 2m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - tasmin:     Minimum air temperature at 2m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - uas:        West-East component of Wind at 10m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - vas:        North-South component of Wind at 10m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - wspeed:     Wind speed at 10m\n",
      "2026-01-15 19:24:03 - climakitae.new_core.user_interface - INFO - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd.activity_id(\"LOCA2\").table_id(timescale).show_variable_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4e3520-b2d7-4286-9413-6eb4b6f01732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make selection from lists above\n",
    "\n",
    "# Dynamically downscaled variable (required)\n",
    "event_variable_wrf = \"prec\"\n",
    "\n",
    "# Set units\n",
    "event_units_wrf = \"inches/d\"\n",
    "\n",
    "# Statistically downscaled variable (optional)\n",
    "# For \"Relative humidity\" use \"hurs\"\n",
    "# For \"Air Temperature at 2m\" use \"tas\"\n",
    "# For no variable use UNSET (no quotes)\n",
    "event_variable_loca2 = \"pr\"\n",
    "\n",
    "# Set units\n",
    "event_units_loca2 = \"inches\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e2688-9fcd-46b2-8b22-b2e6c2529aab",
   "metadata": {},
   "source": [
    "3. Define Event - Select a method for establishing the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4e8c6d-95ff-44d5-a072-5cb3df6e6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function that will be used to calculate the event threshold\n",
    "event_threshold_function = \"1 in x\"  # options are \"percentile\" or \"1 in x\"\n",
    "event_threshold_direction = (\n",
    "    \">\"  # look for events above or below the result from the threshold function\n",
    ")\n",
    "event_threshold_function_params = (\n",
    "    10  # if 1 in X include X, if quantile, include quantile (0.25, 0.5, etc.)\n",
    ")\n",
    "event_duration = 1  # how many consecutive events need to be observed to be a hit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f22c3-573c-49b7-8fc7-4409f29a7890",
   "metadata": {},
   "source": [
    "4. Select a baseline and future GWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173ae0ad-f3fd-4ae0-9f15-da6ca8e8cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current options 0.8, 1.0, 1.2, 1.5, 2.0, 2.5, 3.0, 4.0\n",
    "baseline_gwl = 1.0\n",
    "future_gwl = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fb2e4-fde5-444e-9625-52b15e975547",
   "metadata": {},
   "source": [
    "5. Select Spatial Domain - A spatial domain can be selected via a lat/lon box, a cached area, or a user-provided shapefile. Selections can be made in the cell below.\n",
    "\n",
    "For example, someone studying the Pajaro watershed might have a shapefile path that looks like this:\n",
    "```\n",
    "# User selection\n",
    "spatial_domain = \"Pajaro\"\n",
    "shapefile_filename = \"PajaroRiverWatershed.zip\"\n",
    "\n",
    "# Other variables left unset:\n",
    "lats = ()\n",
    "lons = ()\n",
    "cached_area = UNSET\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0184a4-2211-4009-a64c-fcdffcfe0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name will appear in title\n",
    "spatial_domain = \"CA\"\n",
    "\n",
    "# can define lat/lon box OR cached area OR shapefile\n",
    "lats = ()  # () to leave undefined\n",
    "lons = ()\n",
    "cached_area = \"Santa Cruz County\"  # UNSET for no cached area\n",
    "\n",
    "# edit filename below for shapefile to use\n",
    "shapefile_filename = UNSET  # use UNSET for no shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc217f-1798-4f01-b229-5355a1a4af66",
   "metadata": {},
   "source": [
    "6. Select Resolution - select the the model resolution (3km, 9km, 45 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bec78e6-f175-4c18-9548-51955a7750c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = \"d03\"  # Options are d01 (45 km), d02 (9 km), or d03 (3 km)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e596229-2674-4975-86bc-aca0715007e6",
   "metadata": {},
   "source": [
    "7. Aggregation Method - select a method to aggregate spatially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ef88e1-63e8-4951-8a2b-4a2ff26426fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = \"mean\"  # options are mean, median, sum, min, max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9b766-5caa-451e-9cd0-27257d5bd049",
   "metadata": {},
   "source": [
    "8. Processes - choices for warming levels, units, and clipping are assembled into a dictionary of processes to apply to data selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ea19a58-8def-437b-9a5e-5e3c7d8918ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary is passed to the ClimateData catalog call when pulling data\n",
    "process_dict = {\n",
    "    \"warming_level\": {\n",
    "        \"warming_levels\": [baseline_gwl],\n",
    "    },\n",
    "    \"metric_calc\": {\"metric\": aggregation, \"dims\": [\"lat\", \"lon\"]},\n",
    "}\n",
    "\n",
    "# add clipping selection\n",
    "if (len(lats) > 0) and (len(lons) > 0):\n",
    "    process_dict[\"clip\"] = (lats, lons)\n",
    "elif cached_area is not UNSET:\n",
    "    process_dict[\"clip\"] = [cached_area]\n",
    "elif shapefile_filename is not UNSET:\n",
    "    process_dict[\"clip\"] = shapefile_filename\n",
    "else:\n",
    "    print(\"Process 'clip' unset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c13e8a5-9b40-49d4-8252-713d06ba9be2",
   "metadata": {},
   "source": [
    "## Import libraries & define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb26eb0-4136-40aa-b899-3fb5eabbc7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/jovyan/.local/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/jovyan/.local/lib/python3.12/site-packages (from seaborn) (2.3.5)\n",
      "Requirement already satisfied: pandas>=1.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/jovyan/.local/lib/python3.12/site-packages (from seaborn) (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jovyan/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jovyan/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jovyan/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jovyan/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/jovyan/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/jovyan/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "\n",
    "import climakitae as ck\n",
    "\n",
    "from climakitae.util.utils import add_dummy_time_to_wl\n",
    "from climakitae.explore.threshold_tools import (\n",
    "    get_block_maxima,\n",
    "    get_return_value,\n",
    ")\n",
    "from climakitae.core.data_load import load\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a63905-0dfe-460e-8f86-2f021b4a1251",
   "metadata": {},
   "source": [
    "## Step 1: Define Event "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f16c35-fcb4-443c-b608-c78269cd8fe8",
   "metadata": {},
   "source": [
    "Use the baseline GWL to define the event threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79040e-9c8c-4e6b-9f99-9f217001ef3f",
   "metadata": {},
   "source": [
    "### Pull Baseline Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d9193-67a6-4b81-b3e2-56ca177df2f9",
   "metadata": {},
   "source": [
    "#### Dynamical Downscaling (WRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b892744-6079-4e86-ad02-6f9e231e7705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Catalog set to: cadcat\n",
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Activity ID set to: WRF\n",
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Institution ID set to: UCLA\n",
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Table ID set to: day\n",
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Grid label set to: d03\n",
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Variable set to: prec\n",
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Processes set: 4 operations configured\n",
      "2026-01-15 19:31:07 - climakitae.new_core.user_interface - INFO - Starting data retrieval with query: {'catalog': 'cadcat', 'installation': UNSET, 'activity_id': 'WRF', 'institution_id': 'UCLA', 'source_id': UNSET, 'experiment_id': UNSET, 'table_id': 'day', 'grid_label': 'd03', 'variable_id': 'prec', 'station_id': UNSET, 'network_id': UNSET, 'processes': {'warming_level': {'warming_levels': [1.0]}, 'metric_calc': {'metric': 'mean', 'dims': ['lat', 'lon']}, 'clip': ['Santa Cruz County'], 'convert_units': 'inches/d'}}\n",
      "2026-01-15 19:31:07 - climakitae.new_core.dataset_factory - INFO - Determined catalog key: cadcat\n",
      "2026-01-15 19:31:09 - climakitae.new_core.dataset_factory - INFO - Adding 7 processing steps to dataset\n",
      "2026-01-15 19:31:09 - climakitae.new_core.dataset_factory - INFO - Dataset created successfully\n",
      "2026-01-15 19:31:09 - climakitae.new_core.user_interface - INFO - Dataset created successfully\n",
      "2026-01-15 19:31:09 - climakitae.new_core.dataset - INFO - Executing dataset processing pipeline\n",
      "2026-01-15 19:31:09 - climakitae.new_core.param_validation.abc_param_validation - INFO - Found 17 datasets matching your query.\n",
      "2026-01-15 19:31:09 - climakitae.new_core.param_validation.abc_param_validation - INFO - Checking processes ...\n",
      "2026-01-15 19:31:12 - climakitae.new_core.param_validation.clip_param_validator - INFO - Boundary key 'Santa Cruz County' validation result: True\n",
      "2026-01-15 19:31:12 - climakitae.new_core.param_validation.cadcat_param_validator - INFO - Query validation result: True\n",
      "2026-01-15 19:31:12 - climakitae.new_core.dataset - INFO - Parameter validation successful\n",
      "2026-01-15 19:31:12 - climakitae.new_core.data_access.data_access - INFO - Querying cadcat catalog\n",
      "2026-01-15 19:31:14 - climakitae.new_core.data_access.data_access - INFO - Retrieved 17 dataset(s) from catalog\n",
      "2026-01-15 19:31:14 - climakitae.new_core.dataset - INFO - Data retrieved successfully\n",
      "2026-01-15 19:31:14 - climakitae.new_core.dataset - INFO - Executing 7 processing steps\n",
      "2026-01-15 19:31:14 - climakitae.new_core.processors.filter_unadjusted_models - WARNING - \n",
      "\n",
      "Your query selected models that do not have a-priori bias adjustment. \n",
      "These models have been removed from the returned query. \n",
      "To include them, please add the following processor to your query: \n",
      "ClimateData().processes('filter_unadjusted_models': 'no')\n",
      "\n",
      "2026-01-15 19:31:14 - climakitae.new_core.processors.filter_unadjusted_models - INFO - Filtered out 6 unadjusted model entries\n",
      "2026-01-15 19:31:14 - climakitae.new_core.processors.processor_utils - INFO - Prepending historical data to SSP scenarios. This is the default concatenation strategy for retrieved data in climakitae. To change this behavior, set 'concat': 'sim' in your processes dictionary.\n",
      "2026-01-15 19:31:15 - climakitae.new_core.processors.warming_level - WARNING - \n",
      "\n",
      "Incomplete warming level for WRF.UCLA.EC-Earth3-Veg.ssp370.day.d03.r1i1p1f1 at 1.0C. \n",
      "Skipping this warming level.\n",
      "2026-01-15 19:31:15 - climakitae.new_core.processors.warming_level - WARNING - No valid slices found for WRF.UCLA.EC-Earth3-Veg.ssp370.day.d03.r1i1p1f1. Ensure the warming level times table is correctly configured.\n",
      "2026-01-15 19:31:15 - climakitae.new_core.processors.concatenate - INFO - Concatenated datasets along 'sim' dimension.\n",
      "2026-01-15 19:31:17 - climakitae.new_core.processors.convert_units - INFO - Units successfully converted to 'inches/d'\n",
      "2026-01-15 19:31:17 - climakitae.new_core.processors.metric_calc - WARNING - None of the specified dimensions ['time'] exist in the data. Available dimensions: ['sim', 'x', 'time_delta', 'y', 'warming_level']\n",
      "2026-01-15 19:31:17 - climakitae.new_core.processors.update_attributes - INFO - UpdateAttributes applied to result; added 8 attributes\n",
      "2026-01-15 19:31:17 - climakitae.new_core.dataset - INFO - All processing steps completed successfully\n",
      "2026-01-15 19:31:17 - climakitae.new_core.user_interface - INFO - ✅ Data retrieval successful!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object has inconsistent chunks along dimension latitude. This can be fixed by calling unify_chunks().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     18\u001b[39m wrf_data = add_dummy_time_to_wl(wrf_data)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# aggregate across domain (we want single timeseries)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# wrf_data = eval(f\"wrf_data.{aggregation}(['longitude','latitude'])\")\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m wrf_data = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrf_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.squeeze()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/climakitae/climakitae/core/data_load.py:86\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(xr_da, progress_bar)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read lazily loaded dask array into memory for faster access\u001b[39;00m\n\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m \n\u001b[32m     83\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Check if data is already loaded into memory\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxr_da\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchunks\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYour data is already loaded into memory\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m xr_da\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/dataset.py:2459\u001b[39m, in \u001b[36mDataset.chunks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2442\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2443\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunks\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Mapping[Hashable, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...]]:\n\u001b[32m   2444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2445\u001b[39m \u001b[33;03m    Mapping from dimension names to block lengths for this dataset's data.\u001b[39;00m\n\u001b[32m   2446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2457\u001b[39m \u001b[33;03m    xarray.unify_chunks\u001b[39;00m\n\u001b[32m   2458\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_chunksizes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/common.py:2060\u001b[39m, in \u001b[36mget_chunksizes\u001b[39m\u001b[34m(variables)\u001b[39m\n\u001b[32m   2058\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m dim, c \u001b[38;5;129;01min\u001b[39;00m v.chunksizes.items():\n\u001b[32m   2059\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m chunks \u001b[38;5;129;01mand\u001b[39;00m c != chunks[dim]:\n\u001b[32m-> \u001b[39m\u001b[32m2060\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2061\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObject has inconsistent chunks along dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2062\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mThis can be fixed by calling unify_chunks().\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2063\u001b[39m                 )\n\u001b[32m   2064\u001b[39m             chunks[dim] = c\n\u001b[32m   2065\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Frozen(chunks)\n",
      "\u001b[31mValueError\u001b[39m: Object has inconsistent chunks along dimension latitude. This can be fixed by calling unify_chunks()."
     ]
    }
   ],
   "source": [
    "process_dict.update({\"convert_units\": event_units_wrf})\n",
    "\n",
    "wrf_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(timescale)\n",
    "    .grid_label(resolution)\n",
    "    .variable(event_variable_wrf)\n",
    "    .processes(process_dict)\n",
    "    .get()\n",
    ")\n",
    "\n",
    "# rename lat lon\n",
    "wrf_data = wrf_data.rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    "\n",
    "# add a dummy time variable\n",
    "wrf_data = add_dummy_time_to_wl(wrf_data)\n",
    "\n",
    "# aggregate across domain (we want single timeseries)\n",
    "# wrf_data = eval(f\"wrf_data.{aggregation}(['longitude','latitude'])\")\n",
    "\n",
    "# load data\n",
    "wrf_data = load(wrf_data, progress_bar=True).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b14f0-bd4f-4ea5-84bf-13e3b7595d07",
   "metadata": {},
   "source": [
    "#### Statistical Downscaling (LOCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20297d5-cbde-43ae-8270-748d8ef2ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if event_variable_loca2 is not UNSET:\n",
    "    loca_variable = [event_variable_loca2]\n",
    "    # temperature\n",
    "    if loca_variable[0] == \"tas\":\n",
    "        loca_variable = [\"tasmax\", \"tasmin\"]\n",
    "    # relative humidity\n",
    "    if loca_variable[0] == \"hurs\":\n",
    "        loca_variable = [\"hursmax\", \"hursmin\"]\n",
    "\n",
    "    process_dict.update({\"convert_units\": event_units_loca2})\n",
    "\n",
    "    # statistical - loca2 downscaling xvariable\n",
    "    loca_data = [\n",
    "        cd.catalog(\"cadcat\")\n",
    "        .activity_id(\"LOCA2\")\n",
    "        .table_id(timescale)\n",
    "        .grid_label(resolution)\n",
    "        .variable(GETVAR)\n",
    "        .processes(process_dict)\n",
    "        .get()\n",
    "        for GETVAR in loca_variable\n",
    "    ]\n",
    "\n",
    "    # if we need to average\n",
    "    if event_variable_loca2 in [\"tas\", \"hurs\"]:\n",
    "        loca_data = (\n",
    "            loca_data[0][loca_variable[0]] + loca_data[1][loca_variable[1]]\n",
    "        ) / 2\n",
    "        loca_data = loca_data.to_dataset(name=event_variable_loca2)\n",
    "        loca_data.attrs[\"frequency\"] = timescale\n",
    "\n",
    "    # unlist if needed\n",
    "    if type(loca_data) == list:\n",
    "        loca_data = loca_data[0]\n",
    "\n",
    "    loca_data = loca_data.rename({\"lon\": \"longitude\", \"lat\": \"latitude\"})\n",
    "\n",
    "    # add a dummy time variable\n",
    "    loca_data = add_dummy_time_to_wl(loca_data)\n",
    "\n",
    "    # aggregate across domain (we want single timeseries)\n",
    "    # loca_data = eval(f\"loca_data.{aggregation}(['longitude','latitude'])\")\n",
    "\n",
    "    # load data\n",
    "    loca_data = load(loca_data, progress_bar=True).squeeze()\n",
    "else:\n",
    "    # set to wrf\n",
    "    loca_data = wrf_data\n",
    "    # replace with all NaNs\n",
    "    loca_data = loca_data * np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df8018-03ae-4123-bb1f-bd5edbaf8f1d",
   "metadata": {},
   "source": [
    "### Define Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcda25-e3da-434c-b50f-dcec84af2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine what method to define event\n",
    "if event_threshold_function == \"percentile\":\n",
    "    # calculate the percentile\n",
    "    loca_threshold = (\n",
    "        loca_data[event_variable_loca2]\n",
    "        .quantile(dim=\"time\", q=event_threshold_function_params)\n",
    "        .squeeze()\n",
    "    )\n",
    "    wrf_threshold = (\n",
    "        wrf_data[event_variable_wrf]\n",
    "        .quantile(dim=\"time\", q=event_threshold_function_params)\n",
    "        .squeeze()\n",
    "    )\n",
    "\n",
    "# if 1 in x\n",
    "if event_threshold_function == \"1 in x\":\n",
    "    if event_threshold_direction == \">\":\n",
    "        extreme_type = \"max\"\n",
    "    else:\n",
    "        extreme_type = \"min\"\n",
    "    # initialize\n",
    "    loca_list = []\n",
    "    for sim in loca_data.sim:\n",
    "        loca_ams = get_block_maxima(\n",
    "            loca_data[event_variable_loca2].sel({\"sim\": sim}),\n",
    "            check_ess=False,\n",
    "            extremes_type=extreme_type,\n",
    "        )\n",
    "        loca_rv = get_return_value(\n",
    "            loca_ams,\n",
    "            return_period=event_threshold_function_params,\n",
    "            multiple_points=False,\n",
    "        )\n",
    "        loca_rv = loca_rv.expand_dims(dim=\"sim\")\n",
    "        loca_list.append(loca_rv)\n",
    "    loca_threshold = xr.concat(loca_list, loca_data.sim)\n",
    "    loca_threshold = loca_threshold[\"return_value\"].squeeze()\n",
    "    # intalize\n",
    "    wrf_list = []\n",
    "    for sim in wrf_data.sim:\n",
    "        wrf_ams = get_block_maxima(\n",
    "            wrf_data[event_variable_wrf].sel({\"sim\": sim}),\n",
    "            check_ess=False,\n",
    "            extremes_type=extreme_type,\n",
    "        )\n",
    "        wrf_rv = get_return_value(\n",
    "            wrf_ams,\n",
    "            return_period=event_threshold_function_params,\n",
    "            multiple_points=False,\n",
    "        )\n",
    "        wrf_rv = wrf_rv.expand_dims(dim=\"sim\")\n",
    "        wrf_list.append(wrf_rv)\n",
    "    wrf_threshold = xr.concat(wrf_list, wrf_data.sim)\n",
    "    wrf_threshold = wrf_threshold[\"return_value\"].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c179e-46f5-4757-b6c3-cd1d21c55094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove baseline data to free up memory\n",
    "del loca_data\n",
    "del wrf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f4909-4ac2-4de9-b578-bd468564c64c",
   "metadata": {},
   "source": [
    "## Step 2: Estimate Event 'Hits'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88245347-207a-4e90-8cea-25b2e40d6b9e",
   "metadata": {},
   "source": [
    "Use the future GWL to estimate event hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1403e2-38c7-4ef2-8219-e286026813d5",
   "metadata": {},
   "source": [
    "### Pull Future GWL Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b83966-01fd-4aea-ad7e-f899dd1eb631",
   "metadata": {},
   "source": [
    "#### Dynamical Downscaling (WRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d6a0b-8011-440e-9fd7-ac405c99789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRF downscaling\n",
    "process_dict.update({\"warming_level\": {\"warming_levels\": [future_gwl]}})\n",
    "process_dict.update({\"convert_units\": event_units_wrf})\n",
    "\n",
    "wrf_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(timescale)\n",
    "    .grid_label(resolution)\n",
    "    .variable(event_variable_wrf)\n",
    "    .processes(process_dict)\n",
    "    .get()\n",
    ")\n",
    "\n",
    "# rename lat lon\n",
    "wrf_data = wrf_data.rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    "\n",
    "# add a dummy time variable\n",
    "wrf_data = add_dummy_time_to_wl(wrf_data)\n",
    "\n",
    "# aggregate across domain (we want single timeseries)\n",
    "# wrf_data = eval(f\"wrf_data.{aggregation}(['longitude','latitude'])\")\n",
    "\n",
    "# If simulation is missing in baseline dataset,\n",
    "# drop from future.\n",
    "wrf_data = wrf_data.sel({\"sim\": wrf_threshold.sim.data})\n",
    "\n",
    "# load data\n",
    "wrf_data = load(wrf_data, progress_bar=True).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae453be-2f9d-41dd-874e-9b89ba8912db",
   "metadata": {},
   "source": [
    "#### Statistical Downscaling (LOCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e20059-8450-4f61-bb6c-a83f81f30b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if event_variable_loca2 is not UNSET:\n",
    "    # grab correct variable name for LOCA2\n",
    "    loca_variable = [event_variable_loca2]\n",
    "    # temperature\n",
    "    if loca_variable[0] == \"tas\":\n",
    "        loca_variable = [\"tasmax\", \"tasmin\"]\n",
    "    # relative humidity\n",
    "    if loca_variable[0] == \"hurs\":\n",
    "        loca_variable = [\"hursmax\", \"hursmin\"]\n",
    "\n",
    "    process_dict.update({\"convert_units\": event_units_loca2})\n",
    "\n",
    "    # statistical - loca2 downscaling xvariable\n",
    "    loca_data = [\n",
    "        cd.catalog(\"cadcat\")\n",
    "        .activity_id(\"LOCA2\")\n",
    "        .table_id(timescale)\n",
    "        .grid_label(resolution)\n",
    "        .variable(GETVAR)\n",
    "        .processes(process_dict)\n",
    "        .get()\n",
    "        for GETVAR in loca_variable\n",
    "    ]\n",
    "\n",
    "    # if we need to average\n",
    "    if event_variable_loca2 in [\"tas\", \"hurs\"]:\n",
    "        loca_data = (\n",
    "            loca_data[0][loca_variable[0]] + loca_data[1][loca_variable[1]]\n",
    "        ) / 2\n",
    "        loca_data = loca_data.to_dataset(name=event_variable_loca2)\n",
    "        loca_data.attrs[\"frequency\"] = timescale\n",
    "\n",
    "    # pull data from list if needed\n",
    "    if type(loca_data) == list:\n",
    "        loca_data = loca_data[0]\n",
    "\n",
    "    loca_data = loca_data.rename({\"lon\": \"longitude\", \"lat\": \"latitude\"})\n",
    "\n",
    "    # add a dummy time variable\n",
    "    loca_data = add_dummy_time_to_wl(loca_data)\n",
    "\n",
    "    # aggregate across domain (we want single timeseries)\n",
    "    # loca_data = eval(f\"loca_data.{aggregation}(['longitude','latitude'])\")\n",
    "\n",
    "    # If simulation is missing in baseline dataset,\n",
    "    # drop from future.\n",
    "    loca_data = loca_data.sel({\"sim\": loca_threshold.sim.data})\n",
    "\n",
    "    # load data\n",
    "    loca_data = load(loca_data, progress_bar=True).squeeze()\n",
    "else:\n",
    "    # set to wrf\n",
    "    loca_data = wrf_data\n",
    "    # replace with all NaNs\n",
    "    loca_data = loca_data * np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bacdda-e0dd-4e9e-b14b-1ebbc9654285",
   "metadata": {},
   "source": [
    "### Count Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364dc94-ad72-42f1-b466-34364ae2d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a 'hit' for in events\n",
    "# initialize an array to fill\n",
    "wrfEventHit = np.zeros(wrf_data[event_variable_wrf].shape)\n",
    "if event_variable_loca2 is not UNSET:\n",
    "    locaEventHit = np.zeros(loca_data[event_variable_loca2].shape)\n",
    "else:\n",
    "    locaEventHit = wrfEventHit\n",
    "\n",
    "# loop through each time stamp\n",
    "for itime in range(0, len(wrf_data[\"time\"])):\n",
    "    # look at this time stamp + duration\n",
    "    timeIndex = list(range(itime, (itime + event_duration)))\n",
    "    # remove any values that are greater than our time\n",
    "    timeIndex = [x for x in timeIndex if x < len(wrf_data[\"time\"])]\n",
    "\n",
    "    ### Start with WRF\n",
    "    # pull out the data to test\n",
    "    testWRFData = wrf_data[event_variable_wrf][:, timeIndex]\n",
    "\n",
    "    # for each simulation, check if the values are greater or less than the threshold\n",
    "    if event_threshold_direction == \"<\":\n",
    "        wrfCounts = (testWRFData < wrf_threshold).sum(dim=\"time\")\n",
    "    if event_threshold_direction == \">\":\n",
    "        wrfCounts = (testWRFData > wrf_threshold).sum(dim=\"time\")\n",
    "\n",
    "    # if you have greater than or equal to duration count as a 'hit'\n",
    "    wrfHitIndex = wrfCounts >= event_duration\n",
    "\n",
    "    # now save hits\n",
    "    wrfEventHit[wrfHitIndex, itime] = 1\n",
    "\n",
    "    ### Move to Loca\n",
    "    if event_variable_loca2 is not UNSET:\n",
    "        # pull out the data to test\n",
    "        testLOCAData = loca_data[event_variable_loca2][:, timeIndex]\n",
    "\n",
    "        # for each simulation, check if the values are greater or less than the threshold\n",
    "        if event_threshold_direction == \"<\":\n",
    "            locaCounts = (testLOCAData < loca_threshold).sum(dim=\"time\")\n",
    "        if event_threshold_direction == \">\":\n",
    "            locaCounts = (testLOCAData > loca_threshold).sum(dim=\"time\")\n",
    "\n",
    "        # if you have greater than or equal to duration count as a 'hit'\n",
    "        locaHitIndex = locaCounts >= event_duration\n",
    "\n",
    "        # now save hits\n",
    "        locaEventHit[locaHitIndex, itime] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1934c61-4a87-4391-ab79-a6661b066ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add hits to xarray\n",
    "wrf_data = wrf_data.assign_coords(event_hit=((\"sim\", \"time\"), wrfEventHit))\n",
    "loca_data = loca_data.assign_coords(event_hit=((\"sim\", \"time\"), locaEventHit))\n",
    "\n",
    "# Rename so that there's only a single variable in the final dataframe\n",
    "if event_variable_loca2 is not UNSET:\n",
    "    loca_data = loca_data.rename({event_variable_loca2: event_variable_wrf})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f8040-66b1-41d0-85ae-17098531be5f",
   "metadata": {},
   "source": [
    "## Prep for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe5ee8-c927-4b59-8a00-d36ec4641fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsims = wrf_data.sim.values.tolist()\n",
    "wrf_models = [s.split(\"_\")[2] for s in wsims]\n",
    "wrf_data = wrf_data.assign_coords(models=(\"sim\", wrf_models))\n",
    "\n",
    "# create a realization variable\n",
    "wrf_realization = [s.split(\"_\")[3] + \"_\" + s.split(\"_\")[6] for s in wsims]\n",
    "wrf_data = wrf_data.assign_coords(realization=(\"sim\", wrf_realization))\n",
    "\n",
    "# create a data frame to make plotting easier\n",
    "wrfDF = wrf_data.to_dataframe().reset_index()\n",
    "\n",
    "# Create a downscaling name\n",
    "wrfDF[\"downscaling\"] = \"wrf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ff484-c839-4bbf-8720-218d95ca32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if event_variable_loca2 is not UNSET:\n",
    "    # create a 'model' variable\n",
    "    lsims = loca_data.sim.values.tolist()\n",
    "    loca_models = [s.split(\"_\")[2] for s in lsims]\n",
    "    loca_data = loca_data.assign_coords(models=(\"sim\", loca_models))\n",
    "\n",
    "    # create a realization variable\n",
    "    loca_realization = [s.split(\"_\")[3] + \"_\" + s.split(\"_\")[6] for s in lsims]\n",
    "    loca_data = loca_data.assign_coords(realization=(\"sim\", loca_realization))\n",
    "\n",
    "    # create a data frame to make plotting easier\n",
    "    locaDF = loca_data.to_dataframe().reset_index()\n",
    "\n",
    "    locaDF[\"downscaling\"] = \"loca2\"\n",
    "else:\n",
    "    # Just an empty dataframe\n",
    "    locaDF = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b464e37-5358-4024-b6b6-6264628b3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into one\n",
    "finalDF = pd.concat([locaDF, wrfDF], keys=wrfDF.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c210f7-be93-414b-9dea-498a0e49bc24",
   "metadata": {},
   "source": [
    "## Step 3: Plot Results (Yay!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12359547-1330-4172-8330-3bb154720ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the data\n",
    "def annotate(data, **kws):\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(\n",
    "        data.time.where(data.event_hit == 1),\n",
    "        data[event_variable_wrf].where(data.event_hit == 1),\n",
    "        color=\"r\",\n",
    "    )\n",
    "\n",
    "\n",
    "g1 = sns.relplot(\n",
    "    data=finalDF,\n",
    "    x=\"time\",\n",
    "    y=event_variable_wrf,\n",
    "    col=\"sim\",\n",
    "    color=\"grey\",\n",
    "    col_wrap=4,\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=1,\n",
    "    facet_kws=dict(sharex=False),\n",
    ")\n",
    "g1.map_dataframe(annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c2710-2530-4bb8-98e4-036506c642e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure to a file\n",
    "if event_threshold_function == \"1 in x\":\n",
    "    event_name = f\"1_in_{event_threshold_function_params}\"\n",
    "else:\n",
    "    event_name = f\"{event_threshold_function_params}_percentile\"\n",
    "g1.savefig(\n",
    "    f\"event_finder_{event_variable_wrf}_under_{future_gwl}gwl_with_{event_name}_{event_duration}{timescale}duration_{spatial_domain}.jpeg\".replace(\n",
    "        \" \", \"_\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd2dd8c-a7f8-4b7a-889d-311af99e5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save event data\n",
    "finalDF.to_parquet(\n",
    "    f\"event_{event_variable_wrf}_under_{future_gwl}gwl_with_{event_name}_{event_duration}{timescale}duration_{spatial_domain}\".replace(\n",
    "        \" \", \"_\"\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (climakitae)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
