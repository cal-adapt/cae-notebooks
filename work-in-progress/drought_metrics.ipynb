{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8912da04-5728-44ec-a4a9-27571c03e63b",
   "metadata": {},
   "source": [
    "# Drought Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a0987",
   "metadata": {},
   "source": [
    "In this notebook, we will be exploring how to calculate PDSI and EDDI using AE variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0253ca8c",
   "metadata": {},
   "source": [
    "To start, we will calculate Potential Evapotranspiration, since that variable is needed for both PDSI and EDDI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f081d-f6d2-44cb-a8ad-3018bff1e6e7",
   "metadata": {},
   "source": [
    "### Using the Penman-Monteith method (most physically accurate) to calculate Potential Evapotranspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae473a-7074-4a08-93ce-baf3c9c9f0cf",
   "metadata": {},
   "source": [
    "**Variables needed:**\n",
    "- `tasmin`\n",
    "- `tasmax`\n",
    "- `relative humidity`\n",
    "- `radiation flux`\n",
    "    - rsds\n",
    "    - rsus\n",
    "    - rlds\n",
    "    - rlus\n",
    "- `wind speed (10m wind will be converted to 2m)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192138d2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9752727-9950-4d3e-9ce9-2e3f63df0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xclim\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "from climakitae.core.data_interface import get_data\n",
    "from climakitae.core.data_load import load\n",
    "from climakitae.core.data_export import export\n",
    "from climakitae.util.utils import add_dummy_time_to_wl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cfcec",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d5ec82-885d-42b0-90fd-45b55c3c9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 37.805993\n",
    "lon = -122.273715\n",
    "\n",
    "variables_dict = {\n",
    "    \"tasmax\": \"Maximum air temperature at 2m\",\n",
    "    \"tasmin\": \"Minimum air temperature at 2m\",\n",
    "    \"hurs\": \"Relative humidity\",\n",
    "    \"rsds\": \"Instantaneous downwelling shortwave flux at bottom\",\n",
    "    \"rsus\": \"Instantaneous upwelling shortwave flux at bottom\",\n",
    "    \"rlds\": \"Instantaneous downwelling longwave flux at bottom\",\n",
    "    \"rlus\": \"Instantaneous upwelling longwave flux at bottom\",\n",
    "    \"wspd10mean\": \"Mean wind speed at 10m\",\n",
    "    \"precip\": \"Precipitation (total)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a286df6-b4fb-421d-a60b-8330a2b7bc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Maximum air temperature at 2m\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 12.03 MB of data into memory... \n",
      "[########################################] | 100% Completed | 30.77 s\n",
      "Complete!\n",
      "Computing Minimum air temperature at 2m\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 12.03 MB of data into memory... \n",
      "[########################################] | 100% Completed | 30.85 s\n",
      "Complete!\n",
      "Computing Relative humidity\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 12.03 MB of data into memory... \n",
      "[########################################] | 100% Completed | 34.35 s\n",
      "Complete!\n",
      "Computing Instantaneous downwelling shortwave flux at bottom\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 12.03 MB of data into memory... \n",
      "[########################################] | 100% Completed | 26.80 s\n",
      "Complete!\n",
      "Computing Instantaneous upwelling shortwave flux at bottom\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 288.72 MB of data into memory... \n",
      "[########################################] | 100% Completed | 177.59 s\n",
      "Complete!\n",
      "Computing Instantaneous downwelling longwave flux at bottom\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 12.03 MB of data into memory... \n",
      "[########################################] | 100% Completed | 34.95 s\n",
      "Complete!\n",
      "Computing Instantaneous upwelling longwave flux at bottom\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 288.72 MB of data into memory... \n",
      "[########################################] | 100% Completed | 269.25 s\n",
      "Complete!\n",
      "Computing Mean wind speed at 10m\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 12.03 MB of data into memory... \n",
      "[########################################] | 100% Completed | 43.18 s\n",
      "Complete!\n",
      "Computing Precipitation (total)\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "Processing data to read 12.03 MB of data into memory... \n",
      "[########################################] | 100% Completed | 26.95 s\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "### Retrieving the different variables needed for PET\n",
    "datas = []\n",
    "\n",
    "for _, (variable, var_long_name) in enumerate(variables_dict.items()):\n",
    "\n",
    "    file_path = f\"tmp_data/{variable}_daily.nc\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Reading {variable} from file.\")\n",
    "        da = xr.open_dataarray(file_path)\n",
    "        \n",
    "    else:\n",
    "        # continue\n",
    "        print(f\"Computing {var_long_name}\")\n",
    "        ae_var_name = var_long_name\n",
    "        timescale = 'daily'\n",
    "        # if variable == 'tasmin':\n",
    "        #     ae_var_name = 'Air Temperature at 2m'\n",
    "        if variable == 'rlus' or variable == 'rsus':\n",
    "            timescale = 'hourly'\n",
    "        da = get_data(\n",
    "            variable=ae_var_name,\n",
    "            resolution='3 km',\n",
    "            timescale=timescale,\n",
    "            latitude=(lat - 0.04, lat + 0.04),\n",
    "            longitude=(lon - 0.04, lon + 0.04),\n",
    "            approach=\"Warming Level\",\n",
    "            warming_level=[0.8, 1.5, 2.0, 3.0],\n",
    "            # scenario='SSP 3-7.0',\n",
    "            # time_slice=(2030, 2060),\n",
    "            downscaling_method=\"Dynamical\"\n",
    "        )\n",
    "        da = load(add_dummy_time_to_wl(da), progress_bar=True)\n",
    "        if variable == 'tasmin':\n",
    "            agg_da = da.squeeze().resample(time='D').min()\n",
    "        elif variable == 'tasmax':\n",
    "            agg_da = da.squeeze().resample(time='D').max()\n",
    "        elif variable == 'precip':\n",
    "            agg_da = da.squeeze().resample(time='D').sum()\n",
    "        else:\n",
    "            agg_da = da.squeeze().resample(time='D').mean()\n",
    "        agg_da.to_netcdf(file_path)  # Save for reuse\n",
    "        da = agg_da\n",
    "\n",
    "    datas.append(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd47984-650c-4893-8ba3-0caf2db3a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating daily variables for all hourly variables\n",
    "tasmin = datas[0]\n",
    "tasmax = datas[1]\n",
    "hurs = datas[2] / 100 # Convert from % to fraction\n",
    "new_hurs = hurs.assign_attrs(units='1')\n",
    "rsds = datas[3]\n",
    "rsus = datas[4]\n",
    "rlds = datas[5]\n",
    "rlus = datas[6]\n",
    "sfcWind = datas[7]\n",
    "precip = datas[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9715258-4c1a-46a1-9f4b-40b58d69a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd xclim\n",
    "# !git checkout v0.54.0\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8208bed-13ab-40e4-883d-f91d8a5103c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_calc = xclim.indices.potential_evapotranspiration(\n",
    "    tasmin=tasmin,\n",
    "    tasmax=tasmax,\n",
    "    hurs=new_hurs,\n",
    "    rsds=rsds,\n",
    "    rsus=rsus,\n",
    "    rlds=rlds,\n",
    "    rlus=rlus,\n",
    "    sfcWind=sfcWind,\n",
    "    method=\"FAO_PM98\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d85ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserving a spatial mask for later\n",
    "spatial_mask = ~pet_calc.isel(warming_level=0, time=0, simulation=0).isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00443502-b72e-469f-9126-15d95e7f5d9f",
   "metadata": {},
   "source": [
    "# PDSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f5fe6",
   "metadata": {},
   "source": [
    "Here, we will use the PDSI function from the `climate_indices` library, which is also what drought.gov has referenced. However, we will install a specific commit of the package that is compatible with the AE hub environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac810e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/monocongo/climate_indices.git@43c5451\n",
      "  Cloning https://github.com/monocongo/climate_indices.git (to revision 43c5451) to /tmp/pip-req-build-_lj75s7h\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/monocongo/climate_indices.git /tmp/pip-req-build-_lj75s7h\n",
      "\u001b[33m  WARNING: Did not find branch or tag '43c5451', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q 43c5451\n",
      "  Resolved https://github.com/monocongo/climate_indices.git to commit 43c5451\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cftime>=1.6.4 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from climate_indices==2.1.0) (1.6.4)\n",
      "Requirement already satisfied: dask>=2024.12.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from climate_indices==2.1.0) (2025.5.1)\n",
      "Requirement already satisfied: h5netcdf>=1.4.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from climate_indices==2.1.0) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.14.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from climate_indices==2.1.0) (1.15.2)\n",
      "Requirement already satisfied: xarray>=2024.11.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from climate_indices==2.1.0) (2025.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.0b1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from cftime>=1.6.4->climate_indices==2.1.0) (2.2.6)\n",
      "Requirement already satisfied: click>=8.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask>=2024.12.0->climate_indices==2.1.0) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask>=2024.12.0->climate_indices==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask>=2024.12.0->climate_indices==2.1.0) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask>=2024.12.0->climate_indices==2.1.0) (25.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask>=2024.12.0->climate_indices==2.1.0) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask>=2024.12.0->climate_indices==2.1.0) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask>=2024.12.0->climate_indices==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: h5py in /srv/conda/envs/notebook/lib/python3.12/site-packages (from h5netcdf>=1.4.0->climate_indices==2.1.0) (3.13.0)\n",
      "Requirement already satisfied: locket in /srv/conda/envs/notebook/lib/python3.12/site-packages (from partd>=1.4.0->dask>=2024.12.0->climate_indices==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: pandas>=2.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from xarray>=2024.11.0->climate_indices==2.1.0) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=2.1->xarray>=2024.11.0->climate_indices==2.1.0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=2.1->xarray>=2024.11.0->climate_indices==2.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=2.1->xarray>=2024.11.0->climate_indices==2.1.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray>=2024.11.0->climate_indices==2.1.0) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Pip install the specific commit of the package that supports AE package versions\n",
    "!pip install git+https://github.com/monocongo/climate_indices.git@43c5451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef1e4ee-bc9f-4d9c-91ca-4aa0cd80b6bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making imports from `climate_indices` package\n",
    "import climate_indices\n",
    "from climate_indices.palmer import pdsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df17a2af-d944-47fc-ac19-148a3208ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling PET and precip to monthly since the function only takes monthly variables\n",
    "mon_pet = (pet_calc * 86400 / 25.4).resample(time='1ME').sum()\n",
    "mon_precip = (precip / 25.4).resample(time='1ME').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f8f4c9-9d02-429b-982b-24d5d98d40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining WL objects together, historical WL as 2000-2030, future WL as 2030-2060\n",
    "def combine_wl_to_dummy_time(\n",
    "    da: xr.DataArray,\n",
    "    baseline_wl: float,\n",
    "    future_wls: list[float],\n",
    "    start_date: str = \"2000-01-31\",\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Combine baseline warming level with multiple future warming levels into one\n",
    "    DataArray along a new 'combined_wl' dimension.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xr.DataArray\n",
    "        Original data with dims including 'warming_level' and 'time'.\n",
    "    baseline_wl : float\n",
    "        The warming level used for the first time segment.\n",
    "    future_wls : list of float\n",
    "        Warming levels to concatenate after baseline.\n",
    "    start_date : str\n",
    "        Start date for the combined time series (monthly freq).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        Combined DataArray with new dimension 'combined_wl' and coordinate labels like \"0.8 to 1.5\".\n",
    "    \"\"\"\n",
    "    months_per_wl = da.sizes['time']\n",
    "    total_months = 2 * months_per_wl\n",
    "    new_time = pd.date_range(start_date, periods=total_months, freq='ME')\n",
    "\n",
    "    combined_list = []\n",
    "    combined_labels = []\n",
    "\n",
    "    for fw in future_wls:\n",
    "        da_base = da.sel(warming_level=baseline_wl)\n",
    "        da_future = da.sel(warming_level=fw)\n",
    "\n",
    "        combined = xr.concat([da_base, da_future], dim='time')\n",
    "        combined = combined.assign_coords(time=new_time)\n",
    "\n",
    "        wl_flag = np.array([baseline_wl] * months_per_wl + [fw] * months_per_wl)\n",
    "        combined = combined.assign_coords(warming_level_flag=('time', wl_flag))\n",
    "\n",
    "        combined_list.append(combined)\n",
    "        combined_labels.append(f\"{int(baseline_wl * 10):02d}_to_{int(fw * 10):02d}\")\n",
    "\n",
    "    combined_da = xr.concat(combined_list, dim='combined_wl')\n",
    "    combined_da = combined_da.assign_coords(combined_wl=combined_labels)\n",
    "\n",
    "    return combined_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b74e88e-4b66-4b02-a8b0-cb860ba3334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one Dataset of PET and precip with WLs combined\n",
    "mon_pet_transform = combine_wl_to_dummy_time(mon_pet, baseline_wl=0.8, future_wls=[1.5,2.0,3.0])\n",
    "mon_precip_transform = combine_wl_to_dummy_time(mon_precip, baseline_wl=0.8, future_wls=[1.5,2.0,3.0])\n",
    "\n",
    "combined_ds = xr.Dataset({'precip': mon_precip_transform, 'pet': mon_pet_transform})\n",
    "\n",
    "# Applying spatial mask\n",
    "combined_ds = combined_ds.where(spatial_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8349ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to vectorize PDSI calculation across `combined_ds` dimensions.\n",
    "def calc_pdsi(timeseries: xr.Dataset):\n",
    "    \"\"\"\n",
    "    Compute the Palmer Drought Severity Index (PDSI) from a Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries : xarray.Dataset\n",
    "        Dataset containing 'precip' and 'pet' variables with a time dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        PDSI values along the time dimension.\n",
    "    \"\"\"\n",
    "    # Extracting precip and PET by each timeseries and calculating PDSI\n",
    "    precip = timeseries['precip'].squeeze()\n",
    "    pet = timeseries['pet'].squeeze()\n",
    "    \n",
    "    pdsi_calc = pdsi(\n",
    "        precips=precip.values,\n",
    "        pet=pet.values,\n",
    "        awc=5,\n",
    "        data_start_year=2000,\n",
    "        calibration_year_initial=2000,\n",
    "        calibration_year_final=2030,\n",
    "    )\n",
    "    retval = xr.DataArray(pdsi_calc[0], coords={\"time\": precip.time.values}, dims=['time'])\n",
    "    \n",
    "    # Clipping PDSI to realistic values\n",
    "    return retval.clip(min=-10, max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac6bc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the PDSI function across all dimensions so that a timeseries of PET/precip is always being passed into `pdsi`\n",
    "pdsi_da = combined_ds.groupby([\n",
    "    'combined_wl',\n",
    "    'x',\n",
    "    'y',\n",
    "    'simulation'\n",
    "]).apply(\n",
    "    lambda timeseries: calc_pdsi(timeseries)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8455864",
   "metadata": {},
   "source": [
    "### Exporting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b42cc1",
   "metadata": {},
   "source": [
    "The results will have the following dimensions:\n",
    "- time\n",
    "- wl (showing which WL PDSI was calibrated on, and then which WL PDSI was calculated on)\n",
    "- x\n",
    "- y\n",
    "- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving these results and cleaning the data\n",
    "final_pdsi = pdsi_da.isel(time=slice(360, 720))\n",
    "final_pdsi = final_pdsi.rename({'combined_wl': 'wl'})\n",
    "export(final_pdsi, filename='pdsi_wl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0251ad5-9c45-4f47-b161-699d6a2c5469",
   "metadata": {},
   "source": [
    "## EDDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699eb10",
   "metadata": {},
   "source": [
    "Now, we will calculate EDDI using PET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a46f5f-3357-46f9-bb75-facf2af91d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `standardized_index` from xclim, which we will apply to our PET data object to generate EDDI\n",
    "from xclim.indices.stats import standardized_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eddi(timeseries: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Compute the Evaporative Demand Drought Index (EDDI) for a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries : xarray.DataArray\n",
    "        1D time series of ET₀. NaNs are skipped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        EDDI values. Positive = dry, negative = wet.\n",
    "    \"\"\"\n",
    "    eddi = standardized_index(\n",
    "        da=timeseries,\n",
    "        freq='MS',\n",
    "        window=1,\n",
    "        dist=\"gamma\",\n",
    "        method=\"ML\",\n",
    "        zero_inflated=False,\n",
    "        fitkwargs={},\n",
    "        cal_start=\"2000-01-31\",\n",
    "        cal_end=\"2029-12-31\"\n",
    "    )\n",
    "    # Clipping EDDI to realistic values\n",
    "    retval = eddi.clip(min=-2.5, max=2.5)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the `calc_eddi` function across all dimensions so that a timeseries of PET is always being passed into `calc_eddi`\n",
    "eddi_da = combined_ds['pet'].groupby([\n",
    "    'combined_wl',\n",
    "    'x',\n",
    "    'y',\n",
    "    'simulation'\n",
    "]).apply(\n",
    "    lambda timeseries: calc_eddi(timeseries)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8636779",
   "metadata": {},
   "source": [
    "### Exporting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f56080",
   "metadata": {},
   "source": [
    "The results will have the following dimensions:\n",
    "- time\n",
    "- wl (showing which WL EDDI was calibrated on, and then which WL EDDI was calculated on)\n",
    "- x\n",
    "- y\n",
    "- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ae363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving these results and cleaning the data\n",
    "final_eddi = eddi_da.isel(time=slice(360, 720))\n",
    "final_eddi = final_eddi.rename({'combined_wl': 'wl'})\n",
    "export(final_eddi, filename='eddi_wl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
