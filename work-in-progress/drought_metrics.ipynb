{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0361f0",
   "metadata": {},
   "source": [
    "# Drought Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64641b82",
   "metadata": {},
   "source": [
    "This notebook calculates two drought metrics, the Palmer Drought Severity Index (PDSI) and the Evaporative Demand Drought Index (EDDI), using WRF data in the AE catalog. Both PDSI and EDDI require Potentinal Evaportranspiration (PET). PET is computed first using the Penman-Monteith method. At the end of the notebook, the user will be able to export monthly PDSI and EDDI for under different global warming levels for a specific lat/lon as netcdf files to be used for further analyses.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98506237",
   "metadata": {},
   "source": [
    "**Intended Application:** As a user, I want to <font color=\"red\"> export future drought indicies for different global warming levels </font> by:\n",
    "1. Calculating PET using the Penman-Montieth Method\n",
    "2. Calculating the PDSI using PET and exporting the monthly timeseries to a netcdf\n",
    "3. Calculating the EDDI using PET and exporting the monthly timeseries to a netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35f46e",
   "metadata": {},
   "source": [
    "**Runtime:** With the default settings, this notebook takes approximately 25 minutes to run from start to finish. Modifications to selections may increase the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab2f9c",
   "metadata": {},
   "source": [
    "**Troubleshooting:** Getting an `IndexError: index 40 is out of bounds for axis 0 with size 40` when trying to run the PDSI calculation? Try changing your lat/lon or point of interest further away from the boundaries of our 3 km WRF domain (as seen in [<span style=\"color:blue\">this graphic</span>](https://analytics.cal-adapt.org/faq/#what-data-is-available))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de287f",
   "metadata": {},
   "source": [
    "### Using the Penman-Monteith method (most physically accurate) to calculate Potential Evapotranspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04c18f",
   "metadata": {},
   "source": [
    "**Variables needed:**\n",
    "- `tasmin`\n",
    "- `tasmax`\n",
    "- `relative humidity`\n",
    "- `radiation flux`\n",
    "    - rsds\n",
    "    - rsus\n",
    "    - rlds\n",
    "    - rlus\n",
    "- `wind speed (10m wind will be converted to 2m)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babc840",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e19917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xclim\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "from pyproj import CRS\n",
    "from climakitae.core.data_interface import get_data\n",
    "from climakitae.core.data_load import load\n",
    "from climakitae.core.data_export import export\n",
    "from climakitae.util.utils import add_dummy_time_to_wl\n",
    "from climakitae.util.utils import reproject_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5626f6",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b31d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 37.787964\n",
    "lon = -122.065063\n",
    "\n",
    "variables_dict = {\n",
    "    \"tasmax\": \"Maximum air temperature at 2m\",\n",
    "    \"tasmin\": \"Minimum air temperature at 2m\",\n",
    "    \"hurs\": \"Relative humidity\",\n",
    "    \"rsds\": \"Instantaneous downwelling shortwave flux at bottom\",\n",
    "    \"rsus\": \"Instantaneous upwelling shortwave flux at bottom\",\n",
    "    \"rlds\": \"Instantaneous downwelling longwave flux at bottom\",\n",
    "    \"rlus\": \"Instantaneous upwelling longwave flux at bottom\",\n",
    "    \"wspd10mean\": \"Mean wind speed at 10m\",\n",
    "    \"precip\": \"Precipitation (total)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9173e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making a `intermediate_data` folder to hold intermediate data variables needed for PET\n",
    "!mkdir $input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03173361",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**: The following cell saves out the intermediate data that is required for PET into an `input_data` directory. If you change the lat/lon coordinate from above and DON'T delete or move the data already inside the `input_data` directory, it will just re-read the same data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0132b29-804a-4eef-893f-2f60adfefc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieving the different variables needed for PET\n",
    "datas = []\n",
    "\n",
    "for _, (variable, var_long_name) in enumerate(variables_dict.items()):\n",
    "\n",
    "    file_path = f\"tmp_data/{variable}_daily.nc\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Reading {variable} from file.\")\n",
    "        da = xr.open_dataarray(file_path)\n",
    "        \n",
    "    else:\n",
    "        # continue\n",
    "        print(f\"Computing {var_long_name}\")\n",
    "        ae_var_name = var_long_name\n",
    "        timescale = 'daily'\n",
    "        # if variable == 'tasmin':\n",
    "        #     ae_var_name = 'Air Temperature at 2m'\n",
    "        if variable == 'rlus' or variable == 'rsus':\n",
    "            timescale = 'hourly'\n",
    "        da = get_data(\n",
    "            variable=ae_var_name,\n",
    "            resolution='3 km',\n",
    "            timescale=timescale,\n",
    "            latitude=(lat - 0.1, lat + 0.1),\n",
    "            longitude=(lon - 0.1, lon + 0.1),\n",
    "            approach=\"Warming Level\",\n",
    "            warming_level=[0.8, 1.5, 2.0, 3.0],\n",
    "            # scenario='SSP 3-7.0',\n",
    "            # time_slice=(2030, 2060),\n",
    "            downscaling_method=\"Dynamical\"\n",
    "        )\n",
    "        da = load(add_dummy_time_to_wl(da), progress_bar=True)\n",
    "        if variable == 'tasmin':\n",
    "            agg_da = da.squeeze().resample(time='D').min()\n",
    "        elif variable == 'tasmax':\n",
    "            agg_da = da.squeeze().resample(time='D').max()\n",
    "        elif variable == 'precip':\n",
    "            agg_da = da.squeeze().resample(time='D').sum()\n",
    "        else:\n",
    "            agg_da = da.squeeze().resample(time='D').mean()\n",
    "        agg_da.to_netcdf(file_path)  # Save for reuse\n",
    "        da = agg_da\n",
    "\n",
    "    datas.append(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df54b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating daily variables for all hourly variables\n",
    "tasmin = datas[0]\n",
    "tasmax = datas[1]\n",
    "hurs = datas[2] / 100 # Convert from % to fraction\n",
    "new_hurs = hurs.assign_attrs(units='1')\n",
    "rsds = datas[3]\n",
    "rsus = datas[4]\n",
    "rlds = datas[5]\n",
    "rlus = datas[6]\n",
    "sfcWind = datas[7]\n",
    "precip = datas[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f5bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating PET from xclim\n",
    "pet_calc = xclim.indices.potential_evapotranspiration(\n",
    "    tasmin=tasmin,\n",
    "    tasmax=tasmax,\n",
    "    hurs=new_hurs,\n",
    "    rsds=rsds,\n",
    "    rsus=rsus,\n",
    "    rlds=rlds,\n",
    "    rlus=rlus,\n",
    "    sfcWind=sfcWind,\n",
    "    method=\"FAO_PM98\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cbcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserving CRS and a spatial mask for later\n",
    "crs = CRS.from_cf(pet_calc['Lambert_Conformal'].attrs)\n",
    "spatial_mask = ~pet_calc.isel(warming_level=0, time=0, simulation=0).isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d01841",
   "metadata": {},
   "source": [
    "# PDSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415dcfc7",
   "metadata": {},
   "source": [
    "Here, we will use the PDSI function from the `climate_indices` library, which is also what drought.gov has referenced. However, we will install a specific commit of the package that is compatible with the AE hub environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0bc9fcf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making imports from `climate_indices` package\n",
    "import climate_indices\n",
    "from climate_indices.palmer import pdsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb75906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling PET and precip to monthly since the function only takes monthly variables\n",
    "mon_pet = (pet_calc * 86400 / 25.4).resample(time='1ME').sum()\n",
    "mon_precip = (precip / 25.4).resample(time='1ME').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd18cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining WL objects together, historical WL as 2000-2030, future WL as 2030-2060\n",
    "def combine_wl_to_dummy_time(\n",
    "    da: xr.DataArray,\n",
    "    baseline_wl: float,\n",
    "    future_wls: list[float],\n",
    "    start_date: str = \"2000-01-31\",\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Combine baseline warming level with multiple future warming levels into one\n",
    "    DataArray along a new 'combined_wl' dimension.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xr.DataArray\n",
    "        Original data with dims including 'warming_level' and 'time'.\n",
    "    baseline_wl : float\n",
    "        The warming level used for the first time segment.\n",
    "    future_wls : list of float\n",
    "        Warming levels to concatenate after baseline.\n",
    "    start_date : str\n",
    "        Start date for the combined time series (monthly freq).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        Combined DataArray with new dimension 'combined_wl' and coordinate labels like \"0.8 to 1.5\".\n",
    "    \"\"\"\n",
    "    months_per_wl = da.sizes['time']\n",
    "    total_months = 2 * months_per_wl\n",
    "    new_time = pd.date_range(start_date, periods=total_months, freq='ME')\n",
    "\n",
    "    combined_list = []\n",
    "    combined_labels = []\n",
    "\n",
    "    for fw in future_wls:\n",
    "        da_base = da.sel(warming_level=baseline_wl)\n",
    "        da_future = da.sel(warming_level=fw)\n",
    "\n",
    "        combined = xr.concat([da_base, da_future], dim='time')\n",
    "        combined = combined.assign_coords(time=new_time)\n",
    "\n",
    "        wl_flag = np.array([baseline_wl] * months_per_wl + [fw] * months_per_wl)\n",
    "        combined = combined.assign_coords(warming_level_flag=('time', wl_flag))\n",
    "\n",
    "        combined_list.append(combined)\n",
    "        combined_labels.append(f\"{int(baseline_wl * 10):02d}_to_{int(fw * 10):02d}\")\n",
    "\n",
    "    combined_da = xr.concat(combined_list, dim='combined_wl')\n",
    "    combined_da = combined_da.assign_coords(combined_wl=combined_labels)\n",
    "\n",
    "    return combined_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "119fa7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one Dataset of PET and precip with WLs combined\n",
    "mon_pet_transform = combine_wl_to_dummy_time(mon_pet, baseline_wl=0.8, future_wls=[1.5,2.0,3.0])\n",
    "mon_precip_transform = combine_wl_to_dummy_time(mon_precip, baseline_wl=0.8, future_wls=[1.5,2.0,3.0])\n",
    "\n",
    "combined_ds = xr.Dataset({'precip': mon_precip_transform, 'pet': mon_pet_transform})\n",
    "\n",
    "# Applying spatial mask\n",
    "combined_ds = combined_ds.where(spatial_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b5de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to vectorize PDSI calculation across `combined_ds` dimensions.\n",
    "def calc_pdsi(timeseries: xr.Dataset):\n",
    "    \"\"\"\n",
    "    Compute the Palmer Drought Severity Index (PDSI) from a Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries : xarray.Dataset\n",
    "        Dataset containing 'precip' and 'pet' variables with a time dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        PDSI values along the time dimension.\n",
    "    \"\"\"\n",
    "    # Extracting precip and PET by each timeseries and calculating PDSI\n",
    "    precip = timeseries['precip'].squeeze()\n",
    "    pet = timeseries['pet'].squeeze()\n",
    "    \n",
    "    pdsi_calc = pdsi(\n",
    "        precips=precip.values,\n",
    "        pet=pet.values,\n",
    "        awc=5,\n",
    "        data_start_year=2000,\n",
    "        calibration_year_initial=2000,\n",
    "        calibration_year_final=2030,\n",
    "    )\n",
    "    retval = xr.DataArray(pdsi_calc[0], coords={\"time\": precip.time.values}, dims=['time'])\n",
    "    \n",
    "    # Clipping PDSI to realistic values\n",
    "    return retval.clip(min=-10, max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c625f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the PDSI function across all dimensions so that a timeseries of PET/precip is always being passed into `pdsi`\n",
    "pdsi_da = combined_ds.groupby([\n",
    "    'combined_wl',\n",
    "    'x',\n",
    "    'y',\n",
    "    'simulation'\n",
    "]).apply(\n",
    "    lambda timeseries: calc_pdsi(timeseries)\n",
    ")\n",
    "\n",
    "# Writing crs and reprojecting PDSI to lat/lon\n",
    "pdsi_da = pdsi_da.rio.write_crs(crs.to_wkt())\n",
    "pdsi_da = pdsi_da.transpose('time', 'combined_wl', 'simulation', 'y', 'x')\n",
    "pdsi_latlon = reproject_data(pdsi_da, 'EPSG:4326')\n",
    "del pdsi_latlon.attrs[\"_FillValue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc3157f",
   "metadata": {},
   "source": [
    "### Exporting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d745c44",
   "metadata": {},
   "source": [
    "The results will have the following dimensions:\n",
    "- time\n",
    "- wl (showing which WL PDSI was calibrated on, and then which WL PDSI was calculated on)\n",
    "- lat\n",
    "- lon\n",
    "- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1dc40f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and labeling the data before exporting it in the next cell\n",
    "final_pdsi = pdsi_latlon.isel(time=slice(360, 720))\n",
    "final_pdsi = final_pdsi.rename({'combined_wl': 'wl'}).rename(\"pdsi\")\n",
    "final_pdsi = final_pdsi.assign_attrs({\n",
    "    \"long_name\": \"Palmer Drought Severity Index\",\n",
    "    \"units\": \"from -10 (dry) to +10 (wet)\",\n",
    "})\n",
    "pdsi_filename = f\"pdsi_wl_lat{str(lat).replace('.', '_')}_lon{str(lon).replace('.', '_')}.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c6f3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the DataArray\n",
    "if os.path.exists(pdsi_filename):\n",
    "    raise Exception(\n",
    "        (\n",
    "            f\"File {pdsi_filename} exists. \"\n",
    "            \"Please either delete that file from the work space \"\n",
    "            \"or specify a new file name here.\"\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    final_pdsi.to_netcdf(pdsi_filename, encoding={\"pdsi\": {\"_FillValue\": -9999.0}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2e324",
   "metadata": {},
   "source": [
    "## EDDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0645679",
   "metadata": {},
   "source": [
    "Now, we will calculate EDDI using PET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d38a1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `standardized_index` from xclim, which we will apply to our PET data object to generate EDDI\n",
    "from xclim.indices.stats import standardized_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3228b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eddi(timeseries: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Compute the Evaporative Demand Drought Index (EDDI) for a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries : xarray.DataArray\n",
    "        1D time series of ETâ‚€. NaNs are skipped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        EDDI values. Positive = dry, negative = wet.\n",
    "    \"\"\"\n",
    "    eddi = standardized_index(\n",
    "        da=timeseries,\n",
    "        freq='MS',\n",
    "        window=1,\n",
    "        dist=\"gamma\",\n",
    "        method=\"ML\",\n",
    "        zero_inflated=False,\n",
    "        fitkwargs={},\n",
    "        cal_start=\"2000-01-31\",\n",
    "        cal_end=\"2029-12-31\"\n",
    "    )\n",
    "    # Clipping EDDI to realistic values\n",
    "    retval = eddi.clip(min=-2.5, max=2.5)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1240839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the `calc_eddi` function across all dimensions so that a timeseries of PET is always being passed into `calc_eddi`\n",
    "eddi_da = combined_ds['pet'].groupby([\n",
    "    'combined_wl',\n",
    "    'x',\n",
    "    'y',\n",
    "    'simulation'\n",
    "]).apply(\n",
    "    lambda timeseries: calc_eddi(timeseries)\n",
    ")\n",
    "\n",
    "# Writing crs and reprojecting EDDI to lat/lon\n",
    "eddi_da = eddi_da.rio.write_crs(crs.to_wkt())\n",
    "eddi_da = eddi_da.transpose('time', 'combined_wl', 'simulation', 'y', 'x')\n",
    "eddi_da_latlon = reproject_data(eddi_da, 'EPSG:4326')\n",
    "del eddi_da_latlon.attrs[\"_FillValue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45176f23",
   "metadata": {},
   "source": [
    "### Exporting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ee541",
   "metadata": {},
   "source": [
    "The results will have the following dimensions:\n",
    "- time\n",
    "- wl (showing which WL EDDI was calibrated on, and then which WL EDDI was calculated on)\n",
    "- lat\n",
    "- lon\n",
    "- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d86782f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving these results and cleaning the data\n",
    "final_eddi = eddi_da_latlon.isel(time=slice(360, 720))\n",
    "final_eddi = final_eddi.rename({'combined_wl': 'wl'}).rename(\"eddi\")\n",
    "final_eddi = final_eddi.assign_attrs({\n",
    "    \"long_name\": \"Evaporative Demand Drought Index\",\n",
    "    \"units\": \"from -2.5 (wet) to +2.5 (dry)\",\n",
    "})\n",
    "eddi_filename = f\"eddi_wl_lat{str(lat).replace('.', '_')}_lon{str(lon).replace('.', '_')}.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "707286f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the DataArray\n",
    "if os.path.exists(eddi_filename):\n",
    "    raise Exception(\n",
    "        (\n",
    "            f\"File {eddi_filename} exists. \"\n",
    "            \"Please either delete that file from the work space \"\n",
    "            \"or specify a new file name here.\"\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    final_eddi.to_netcdf(eddi_filename, encoding={\"eddi\": {\"_FillValue\": -9999.0}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
