{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8912da04-5728-44ec-a4a9-27571c03e63b",
   "metadata": {},
   "source": [
    "# Drought Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a0987",
   "metadata": {},
   "source": [
    "In this notebook, we will be exploring how to calculate PDSI and EDDI using AE variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0253ca8c",
   "metadata": {},
   "source": [
    "To start, we will calculate Potential Evapotranspiration, since that variable is needed for both PDSI and EDDI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f081d-f6d2-44cb-a8ad-3018bff1e6e7",
   "metadata": {},
   "source": [
    "### Using the Penman-Monteith method (most physically accurate) to calculate Potential Evapotranspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae473a-7074-4a08-93ce-baf3c9c9f0cf",
   "metadata": {},
   "source": [
    "**Variables needed:**\n",
    "- `tasmin`\n",
    "- `tasmax`\n",
    "- `relative humidity`\n",
    "- `radiation flux`\n",
    "    - rsds\n",
    "    - rsus\n",
    "    - rlds\n",
    "    - rlus\n",
    "- `wind speed (10m wind will be converted to 2m)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192138d2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9752727-9950-4d3e-9ce9-2e3f63df0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xclim\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "from climakitae.core.data_interface import get_data\n",
    "from climakitae.core.data_load import load\n",
    "from climakitae.core.data_export import export\n",
    "from climakitae.util.utils import add_dummy_time_to_wl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cfcec",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5ec82-885d-42b0-90fd-45b55c3c9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 37.805993\n",
    "lon = -122.273715\n",
    "\n",
    "variables_dict = {\n",
    "    \"tasmax\": \"Maximum air temperature at 2m\",\n",
    "    \"tasmin\": \"Minimum air temperature at 2m\",\n",
    "    \"hurs\": \"Relative humidity\",\n",
    "    \"rsds\": \"Instantaneous downwelling shortwave flux at bottom\",\n",
    "    \"rsus\": \"Instantaneous upwelling shortwave flux at bottom\",\n",
    "    \"rlds\": \"Instantaneous downwelling longwave flux at bottom\",\n",
    "    \"rlus\": \"Instantaneous upwelling longwave flux at bottom\",\n",
    "    \"wspd10mean\": \"Mean wind speed at 10m\",\n",
    "    \"precip\": \"Precipitation (total)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a286df6-b4fb-421d-a60b-8330a2b7bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieving the different variables needed for PET\n",
    "datas = []\n",
    "\n",
    "for _, (variable, var_long_name) in enumerate(variables_dict.items()):\n",
    "\n",
    "    file_path = f\"tmp_data/{variable}_daily.nc\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Reading {variable} from file.\")\n",
    "        da = xr.open_dataarray(file_path)\n",
    "        \n",
    "    else:\n",
    "        # continue\n",
    "        print(f\"Computing {var_long_name}\")\n",
    "        ae_var_name = var_long_name\n",
    "        timescale = 'daily'\n",
    "        # if variable == 'tasmin':\n",
    "        #     ae_var_name = 'Air Temperature at 2m'\n",
    "        if variable == 'rlus' or variable == 'rsus':\n",
    "            timescale = 'hourly'\n",
    "        da = get_data(\n",
    "            variable=ae_var_name,\n",
    "            resolution='3 km',\n",
    "            timescale=timescale,\n",
    "            latitude=(lat - 0.1, lat + 0.1),\n",
    "            longitude=(lon - 0.1, lon + 0.1),\n",
    "            approach=\"Warming Level\",\n",
    "            warming_level=[0.8, 1.5, 2.0, 3.0],\n",
    "            # scenario='SSP 3-7.0',\n",
    "            # time_slice=(2030, 2060),\n",
    "            downscaling_method=\"Dynamical\"\n",
    "        )\n",
    "        da = load(add_dummy_time_to_wl(da), progress_bar=True)\n",
    "        if variable == 'tasmin':\n",
    "            agg_da = da.squeeze().resample(time='D').min()\n",
    "        elif variable == 'tasmax':\n",
    "            agg_da = da.squeeze().resample(time='D').max()\n",
    "        elif variable == 'precip':\n",
    "            agg_da = da.squeeze().resample(time='D').sum()\n",
    "        else:\n",
    "            agg_da = da.squeeze().resample(time='D').mean()\n",
    "        agg_da.to_netcdf(file_path)  # Save for reuse\n",
    "        da = agg_da\n",
    "\n",
    "    datas.append(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd47984-650c-4893-8ba3-0caf2db3a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating daily variables for all hourly variables\n",
    "tasmin = datas[0]\n",
    "tasmax = datas[1]\n",
    "hurs = datas[2] / 100 # Convert from % to fraction\n",
    "new_hurs = hurs.assign_attrs(units='1')\n",
    "rsds = datas[3]\n",
    "rsus = datas[4]\n",
    "rlds = datas[5]\n",
    "rlus = datas[6]\n",
    "sfcWind = datas[7]\n",
    "precip = datas[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9715258-4c1a-46a1-9f4b-40b58d69a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd xclim\n",
    "# !git checkout v0.54.0\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8208bed-13ab-40e4-883d-f91d8a5103c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_calc = xclim.indices.potential_evapotranspiration(\n",
    "    tasmin=tasmin,\n",
    "    tasmax=tasmax,\n",
    "    hurs=new_hurs,\n",
    "    rsds=rsds,\n",
    "    rsus=rsus,\n",
    "    rlds=rlds,\n",
    "    rlus=rlus,\n",
    "    sfcWind=sfcWind,\n",
    "    method=\"FAO_PM98\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserving a spatial mask for later\n",
    "spatial_mask = ~pet_calc.isel(warming_level=0, time=0, simulation=0).isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00443502-b72e-469f-9126-15d95e7f5d9f",
   "metadata": {},
   "source": [
    "# PDSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f5fe6",
   "metadata": {},
   "source": [
    "Here, we will use the PDSI function from the `climate_indices` library, which is also what drought.gov has referenced. However, we will install a specific commit of the package that is compatible with the AE hub environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac810e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install the specific commit of the package that supports AE package versions\n",
    "!pip install git+https://github.com/monocongo/climate_indices.git@43c5451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1e4ee-bc9f-4d9c-91ca-4aa0cd80b6bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making imports from `climate_indices` package\n",
    "import climate_indices\n",
    "from climate_indices.palmer import pdsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17a2af-d944-47fc-ac19-148a3208ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling PET and precip to monthly since the function only takes monthly variables\n",
    "mon_pet = (pet_calc * 86400 / 25.4).resample(time='1ME').sum()\n",
    "mon_precip = (precip / 25.4).resample(time='1ME').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8f4c9-9d02-429b-982b-24d5d98d40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining WL objects together, historical WL as 2000-2030, future WL as 2030-2060\n",
    "def combine_wl_to_dummy_time(\n",
    "    da: xr.DataArray,\n",
    "    baseline_wl: float,\n",
    "    future_wls: list[float],\n",
    "    start_date: str = \"2000-01-31\",\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Combine baseline warming level with multiple future warming levels into one\n",
    "    DataArray along a new 'combined_wl' dimension.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xr.DataArray\n",
    "        Original data with dims including 'warming_level' and 'time'.\n",
    "    baseline_wl : float\n",
    "        The warming level used for the first time segment.\n",
    "    future_wls : list of float\n",
    "        Warming levels to concatenate after baseline.\n",
    "    start_date : str\n",
    "        Start date for the combined time series (monthly freq).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        Combined DataArray with new dimension 'combined_wl' and coordinate labels like \"0.8 to 1.5\".\n",
    "    \"\"\"\n",
    "    months_per_wl = da.sizes['time']\n",
    "    total_months = 2 * months_per_wl\n",
    "    new_time = pd.date_range(start_date, periods=total_months, freq='ME')\n",
    "\n",
    "    combined_list = []\n",
    "    combined_labels = []\n",
    "\n",
    "    for fw in future_wls:\n",
    "        da_base = da.sel(warming_level=baseline_wl)\n",
    "        da_future = da.sel(warming_level=fw)\n",
    "\n",
    "        combined = xr.concat([da_base, da_future], dim='time')\n",
    "        combined = combined.assign_coords(time=new_time)\n",
    "\n",
    "        wl_flag = np.array([baseline_wl] * months_per_wl + [fw] * months_per_wl)\n",
    "        combined = combined.assign_coords(warming_level_flag=('time', wl_flag))\n",
    "\n",
    "        combined_list.append(combined)\n",
    "        combined_labels.append(f\"{int(baseline_wl * 10):02d}_to_{int(fw * 10):02d}\")\n",
    "\n",
    "    combined_da = xr.concat(combined_list, dim='combined_wl')\n",
    "    combined_da = combined_da.assign_coords(combined_wl=combined_labels)\n",
    "\n",
    "    return combined_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74e88e-4b66-4b02-a8b0-cb860ba3334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one Dataset of PET and precip with WLs combined\n",
    "mon_pet_transform = combine_wl_to_dummy_time(mon_pet, baseline_wl=0.8, future_wls=[1.5,2.0,3.0])\n",
    "mon_precip_transform = combine_wl_to_dummy_time(mon_precip, baseline_wl=0.8, future_wls=[1.5,2.0,3.0])\n",
    "\n",
    "combined_ds = xr.Dataset({'precip': mon_precip_transform, 'pet': mon_pet_transform})\n",
    "\n",
    "# Applying spatial mask\n",
    "combined_ds = combined_ds.where(spatial_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8349ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to vectorize PDSI calculation across `combined_ds` dimensions.\n",
    "def calc_pdsi(timeseries: xr.Dataset):\n",
    "    \"\"\"\n",
    "    Compute the Palmer Drought Severity Index (PDSI) from a Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries : xarray.Dataset\n",
    "        Dataset containing 'precip' and 'pet' variables with a time dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        PDSI values along the time dimension.\n",
    "    \"\"\"\n",
    "    # Extracting precip and PET by each timeseries and calculating PDSI\n",
    "    precip = timeseries['precip'].squeeze()\n",
    "    pet = timeseries['pet'].squeeze()\n",
    "    \n",
    "    pdsi_calc = pdsi(\n",
    "        precips=precip.values,\n",
    "        pet=pet.values,\n",
    "        awc=5,\n",
    "        data_start_year=2000,\n",
    "        calibration_year_initial=2000,\n",
    "        calibration_year_final=2030,\n",
    "    )\n",
    "    retval = xr.DataArray(pdsi_calc[0], coords={\"time\": precip.time.values}, dims=['time'])\n",
    "    \n",
    "    # Clipping PDSI to realistic values\n",
    "    return retval.clip(min=-10, max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the PDSI function across all dimensions so that a timeseries of PET/precip is always being passed into `pdsi`\n",
    "pdsi_da = combined_ds.groupby([\n",
    "    'combined_wl',\n",
    "    'x',\n",
    "    'y',\n",
    "    'simulation'\n",
    "]).apply(\n",
    "    lambda timeseries: calc_pdsi(timeseries)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8455864",
   "metadata": {},
   "source": [
    "### Saving out the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b42cc1",
   "metadata": {},
   "source": [
    "The results will have the following dimensions:\n",
    "- time\n",
    "- wl (showing which WL PDSI was calibrated on, and then which WL PDSI was calculated on)\n",
    "- x\n",
    "- y\n",
    "- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving these results and cleaning the data\n",
    "final_pdsi = pdsi_da.isel(time=slice(360, 720))\n",
    "final_pdsi = final_pdsi.rename({'combined_wl': 'wl'})\n",
    "export(final_pdsi, filename='pdsi_wl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0251ad5-9c45-4f47-b161-699d6a2c5469",
   "metadata": {},
   "source": [
    "## EDDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699eb10",
   "metadata": {},
   "source": [
    "Now, we will calculate EDDI using PET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a46f5f-3357-46f9-bb75-facf2af91d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `standardized_index` from xclim, which we will apply to our PET data object to generate EDDI\n",
    "from xclim.indices.stats import standardized_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eddi(timeseries: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Compute the Evaporative Demand Drought Index (EDDI) for a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries : xarray.DataArray\n",
    "        1D time series of ETâ‚€. NaNs are skipped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        EDDI values. Positive = dry, negative = wet.\n",
    "    \"\"\"\n",
    "    eddi = standardized_index(\n",
    "        da=timeseries,\n",
    "        freq='MS',\n",
    "        window=1,\n",
    "        dist=\"gamma\",\n",
    "        method=\"ML\",\n",
    "        zero_inflated=False,\n",
    "        fitkwargs={},\n",
    "        cal_start=\"2000-01-31\",\n",
    "        cal_end=\"2029-12-31\"\n",
    "    )\n",
    "    # Clipping EDDI to realistic values\n",
    "    retval = eddi.clip(min=-2.5, max=2.5)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the `calc_eddi` function across all dimensions so that a timeseries of PET is always being passed into `calc_eddi`\n",
    "eddi_da = combined_ds['pet'].groupby([\n",
    "    'combined_wl',\n",
    "    'x',\n",
    "    'y',\n",
    "    'simulation'\n",
    "]).apply(\n",
    "    lambda timeseries: calc_eddi(timeseries)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8636779",
   "metadata": {},
   "source": [
    "### Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ae363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving these results and cleaning the data\n",
    "final_eddi = eddi_da.isel(time=slice(360, 720))\n",
    "final_eddi = final_eddi.rename({'combined_wl': 'wl'})\n",
    "export(final_eddi, filename='eddi_wl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
