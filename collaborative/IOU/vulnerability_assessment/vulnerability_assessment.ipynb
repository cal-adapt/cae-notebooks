{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ef497a-dcb7-4b23-aa33-2b7690294144",
   "metadata": {},
   "source": [
    "# Vulnerability Assessment Pilot\n",
    "This notebook demonstrates on-going development of climate adaptation vulnerability assessment (CAVA) support using climate data in the Analytics Engine. \n",
    "\n",
    "To execute a given 'cell' of this notebook, place the cursor in the cell and press the 'play' icon, or simply press shift+enter together. Some cells will take longer to run, and you will see a [$\\ast$] to the left of the cell while AE is still working.\n",
    "\n",
    "**Intended Application**: As a user, I want to **<span style=\"color:#FF0000\">access climate projections data for my vulnerability assessment report</span>** by:\n",
    "1. Retrieve data metrics required for planning needs\n",
    "\n",
    "**Runtime**: With the default settings, this notebook takes approximately **less than 10 minutes** to run from start to finish. Modifications to selections may increase the runtime. <br>*This notebook is currently in progress, runtime will change as improvements and further analyses are added.*\n",
    "\n",
    "### Step 0: Set-up\n",
    "\n",
    "First, we'll import the Python library [climakitae](https://github.com/cal-adapt/climakitae), our AE toolkit for climate data analysis, along with this specific functions from that library that we'll use in this notebook, as well as any other necessary Python libraries to aid in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d6530-a94d-416e-81a3-2fac5e79bf72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "import pandas as pd\n",
    "\n",
    "from climakitae.explore.vulnerability import cava_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b50c3-5e8c-4f4c-b7e2-1839ae0c462f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import locations\n",
    "Now we'll read in point-based locations that we want to retrieve data for. For custom inputs, there are two options: (1) Input a single pair of latitude - longitude values; and (2) Import a csv file of locations that will each run. In the code below we show what each option looks like. \n",
    "\n",
    "Functionality to assess over a gridded area (region) is in the works as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bed4b-a58d-4d9b-9a06-adfb5fb89717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select a single custom location\n",
    "# your_lat = LAT\n",
    "# your_lon = LON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435c50f-dec5-4440-9bd6-e5207a317f92",
   "metadata": {},
   "source": [
    "To import your own custom locations, we recommend putting your csv file in the same folder as this notebook for ease:\n",
    "1. Drag and drop a csv file into the file tree on the left hand side; or\n",
    "2. Use the `upload` button (the \"up arrow\" symbol next to the large blue plus symbol above the file tree). \n",
    "\n",
    "<span style=\"color:#FF0000\">**Formatting note**</span>: For the code cells below to work, there must be **2 columns labeled `lat` and `lon`**. Functionality to accept different labeling is forthcoming!\n",
    "\n",
    "In the cell below, we read the csv file in. We extracted three random locations from the HadISD station list as an example here -- you'll want to replace with your own locations file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7366d-562b-4921-8c70-ae76a91a206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dummy locations from `stations_csv` file\n",
    "from climakitae.core.paths import stations_csv_path\n",
    "from climakitae.util.utils import read_csv_file\n",
    "example_locs = read_csv_file(stations_csv_path, index_col=0)[['LAT_Y', 'LON_X']].rename(columns={'LAT_Y': 'lat', 'LON_X': 'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a24db2-dc22-41b9-a259-682781a0b0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select a location from the location list\n",
    "one_loc = example_locs.loc[example_locs.index == 0]\n",
    "loc_lat = one_loc.lat.values[0]\n",
    "loc_lon = one_loc.lon.values[0]\n",
    "print(loc_lat, loc_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a18588-8941-416f-b641-5dcd7d342884",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve metric data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654fe37-8070-4c9a-8404-051b6412be47",
   "metadata": {},
   "source": [
    "Here, we'll list some of the available arguments for the `cava_data` function for certain parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c35317-e5b9-45bf-9d06-634b0d33725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_variables = [\n",
    "    \"Air Temperature at 2m\",\n",
    "    \"Precipitation (total)\",\n",
    "    \"NOAA Heat Index\",\n",
    "]\n",
    "available_metrics = [\"min\", \"max\", \"mean\", \"median\"]\n",
    "ssps = [\"SSP2-4.5\", \"SSP3-7.0\", \"SSP5-8.5\"]\n",
    "export_method = ['off-ramp', 'calculate', 'both']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495078a-97ab-4be1-b154-20330c6ab270",
   "metadata": {},
   "source": [
    "Now, we'll run the `cava_data` function with the arguments that you have changed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a2fc7-bc64-4edb-8446-648a183eb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cava_data(\n",
    "    example_locs.iloc[:1],\n",
    "    time_start_year=2030,\n",
    "    time_end_year=2050,\n",
    "    units=\"degF\",\n",
    "    downscaling_method=\"Dynamical\",  # default for now ## mandatory\n",
    "    approach=\"time\",  \n",
    "    warming_level='3.0',\n",
    "    wrf_bc=True,\n",
    "    historical_data=\"Historical Climate\",  # or \"historical reconstruction\"\n",
    "    ssp_data=[\"SSP3-7.0\"],\n",
    "    variable=\"Air Temperature at 2m\",  ## mandatory, must eventually accept temp, precip, or heat index\n",
    "    metric_calc=\"max\", \n",
    "    heat_idx_threshold=None, # Heat Index Threshold\n",
    "    one_in_x=2, # One-in-X\n",
    "    percentile=None, # Likeliness\n",
    "    season=\"summer\",\n",
    "    export_method=\"calculate\",  # off-ramp, full calculate, both\n",
    "    separate_files=True, # Toggle to determine whether or not the user wants to separate climate variable information into separate files\n",
    "    file_format=\"NetCDF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befaee12-c451-4827-a783-8bf6ca9257bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e6b5b8-ce77-4202-8f8f-73a6b2debc10",
   "metadata": {},
   "source": [
    "### Appendix: Table Generation Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da27397-aaf4-47f5-a871-71f48ec32341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params dict\n",
    "table_vars = {\n",
    "    'Likely summer day high': {\n",
    "        'variable': 'Air Temperature at 2m',\n",
    "        'metric_calc': 'max',\n",
    "        'season': 'summer',\n",
    "        'percentile': 50,\n",
    "        'heat_idx_threshold': None,\n",
    "        'one_in_x': None,\n",
    "    },\n",
    "    'Likely summer night low': {\n",
    "        'variable': 'Air Temperature at 2m',\n",
    "        'metric_calc': 'min',\n",
    "        'season': 'summer',\n",
    "        'percentile': 50,\n",
    "        'heat_idx_threshold': None,\n",
    "        'one_in_x': None,\n",
    "    },\n",
    "    'Likely winter day high': {\n",
    "        'variable': 'Air Temperature at 2m',\n",
    "        'metric_calc': 'max',\n",
    "        'season': 'winter',\n",
    "        'percentile': 50,\n",
    "        'heat_idx_threshold': None,\n",
    "        'one_in_x': None,\n",
    "    },\n",
    "    'Likely winter night low': {\n",
    "        'variable': 'Air Temperature at 2m',\n",
    "        'metric_calc': 'min',\n",
    "        'season': 'winter',\n",
    "        'percentile': 50,\n",
    "        'heat_idx_threshold': None,\n",
    "        'one_in_x': None,\n",
    "    },\n",
    "    '1-in-2 year maximum': {\n",
    "        'variable': 'Air Temperature at 2m',\n",
    "        'metric_calc': 'max',\n",
    "        'season': 'all',\n",
    "        'percentile': None,\n",
    "        'heat_idx_threshold': None,\n",
    "        'one_in_x': 2,\n",
    "    },\n",
    "    '1-in-10 year maximum': {\n",
    "        'variable': 'Air Temperature at 2m',\n",
    "        'metric_calc': 'max',\n",
    "        'season': 'all',\n",
    "        'percentile': None,\n",
    "        'heat_idx_threshold': None,\n",
    "        'one_in_x': 10,\n",
    "    },\n",
    "    '1-in-10 year minimum': {\n",
    "        'variable': 'Air Temperature at 2m',\n",
    "        'metric_calc': 'min',\n",
    "        'season': 'all',\n",
    "        'percentile': None,\n",
    "        'heat_idx_threshold': None,\n",
    "        'one_in_x': 10,\n",
    "    },\n",
    "    'High/Extreme Heat Index': {\n",
    "        'variable': 'NOAA Heat Index',\n",
    "        'metric_calc': 'max',\n",
    "        'season': 'all',\n",
    "        'percentile': None,\n",
    "        'heat_idx_threshold': 91,\n",
    "        'one_in_x': None,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3092d8-d6d2-4313-8f9d-09c920befdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from climakitae.explore import warming_levels as WarmingLevels\n",
    "from climakitae.core.data_interface import DataParameters\n",
    "from climakitae.core.data_load import load\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "loc_idx = 10\n",
    "suppress_output = True\n",
    "\n",
    "# Create empty df and instantiate variables\n",
    "df = pd.DataFrame(columns=table_vars.keys())\n",
    "lat, lon = example_locs.iloc[loc_idx] # Oakland teehee\n",
    "months_map = {\n",
    "    \"winter\": [12, 1, 2],\n",
    "    \"summer\": [6, 7, 8],\n",
    "    \"all\": np.arange(1, 13)\n",
    "}\n",
    "warming_levels = ['0.0', '1.5', '2.0', '3.0', '4.0'] # 0.0 = Historical Period (1980-2010)\n",
    "\n",
    "# Create each column in the table, which is the historical period (1980-2010) and each WL (1.5, 2.0, 3.0, 4.0).\n",
    "for warming_level in warming_levels:\n",
    "    \n",
    "    metrics = []\n",
    "    preloaded_data_by_season = {}\n",
    "    \n",
    "    if warming_level != '0.0':\n",
    "    \n",
    "        # Retrieving warming level data once for each season so that it's not repeated constantly\n",
    "        wl = WarmingLevels()\n",
    "        wl.wl_params.timescale = \"hourly\"\n",
    "        wl.wl_params.downscaling_method = \"Dynamical\"\n",
    "        # wl.wl_params.variable_type = \"Derived Index\" if variable == \"NOAA Heat Index\" else \"Variable\"\n",
    "        wl.wl_params.variable_type = \"Variable\"\n",
    "        wl.wl_params.variable = \"Air Temperature at 2m\"\n",
    "        wl.wl_params.latitude = (lat - 0.02, lat + 0.02)\n",
    "        wl.wl_params.longitude = (lon - 0.02, lon + 0.02)\n",
    "        wl.wl_params.warming_levels = [\n",
    "            warming_level\n",
    "        ]  # Calvin- default, only allow for 1 warming level to be passed in.\n",
    "        wl.wl_params.units = \"degF\"\n",
    "        wl.wl_params.resolution = \"3 km\"\n",
    "        wl.wl_params.anom = \"No\"  # Q: When do we want this anomaly to be 'Yes'?\n",
    "\n",
    "        print(f\"\\nRetrieving all warming level data by season to be cached and used in `cava_data`...\\n\")\n",
    "\n",
    "        for season in months_map.keys():\n",
    "\n",
    "            # Calculating warming levels by season\n",
    "            wl.wl_params.months = months_map[season]\n",
    "\n",
    "            print(f\"\\nRetrieving warming level data for {warming_level}°C in season {season}...\\n\") \n",
    "\n",
    "            wl.calculate()\n",
    "    \n",
    "            # Appending data to cached data variable\n",
    "            preloaded_data_by_season[season] = wl.sliced_data[warming_level]      \n",
    "    \n",
    "    else: \n",
    "        \n",
    "        # Retrieving time-based data once for each season so that it's not repeated constantly\n",
    "        selections = DataParameters()\n",
    "        selections.data_type = \"Gridded\"\n",
    "        selections.downscaling_method = \"Dynamical\"\n",
    "        selections.scenario_historical = [\"Historical Climate\"]\n",
    "        selections.scenario_ssp = ssp_data=[\"SSP3-7.0\"]\n",
    "        selections.timescale = \"hourly\"\n",
    "        selections.variable = \"Air Temperature at 2m\"\n",
    "        selections.variable_type = \"Variable\"\n",
    "        selections.latitude = (\n",
    "            lat - 0.02,\n",
    "            lat + 0.02,\n",
    "        )\n",
    "        selections.longitude = (lon - 0.02, lon + 0.02)\n",
    "        selections.time_slice = (1980, 2010)\n",
    "        selections.resolution = \"3 km\"\n",
    "        selections.units = 'degF'\n",
    "\n",
    "        print(f\"\\nRetrieving all time-based data by season to be cached and used in `cava_data`...\\n\")\n",
    "        \n",
    "        data = load(selections.retrieve(), progress_bar=True)\n",
    "\n",
    "        for season in months_map.keys():\n",
    "\n",
    "            # Appending data to cached data variable\n",
    "            preloaded_data_by_season[season] = data.sel(time=data.time.dt.month.isin(months_map[season]))\n",
    "        \n",
    "    # Calculate each variable in the table\n",
    "    for key in table_vars:\n",
    "        params = table_vars[key]\n",
    "        \n",
    "        wl_or_hist_str = \"Historical Period (1980-2010)\" if warming_level == '0.0' else warming_level + '°C'\n",
    "        print(f\"\\nRetrieving {key} for Warming Level {wl_or_hist_str}...\\n\")\n",
    "\n",
    "        # Suppress outputs of `cava_data` function\n",
    "        if suppress_output:\n",
    "            \n",
    "            with contextlib.redirect_stdout(io.StringIO()):\n",
    "            \n",
    "                data = cava_data(\n",
    "                    example_locs.iloc[loc_idx: loc_idx + 1],\n",
    "                    time_start_year=1980, # For historical period\n",
    "                    time_end_year=2010, # For historical period\n",
    "                    units=\"degF\",\n",
    "                    downscaling_method=\"Dynamical\",  # default for now ## mandatory\n",
    "                    approach=\"warming_level\" if warming_level != '0.0' else \"time\",  \n",
    "                    warming_level=warming_level,\n",
    "                    wrf_bc=False,\n",
    "                    historical_data=\"Historical Climate\",  # or \"historical reconstruction\"\n",
    "                    ssp_data=[\"SSP3-7.0\"],\n",
    "                    variable=params['variable'],  ## mandatory, must eventually accept temp, precip, or heat index\n",
    "                    metric_calc=params['metric_calc'],\n",
    "                    heat_idx_threshold=params['heat_idx_threshold'], # Heat index\n",
    "                    one_in_x=params['one_in_x'], # Thresholds tools freq. counts\n",
    "                    percentile=params['percentile'],\n",
    "                    season=params['season'],\n",
    "                    export_method='None',  # off-ramp, full calculate, both\n",
    "                    separate_files=True, # Toggle to determine whether or not the user wants to separate climate variable information into separate files\n",
    "                    file_format=\"NetCDF\",\n",
    "                    preloaded_data=preloaded_data_by_season,\n",
    "                )\n",
    "\n",
    "        # Retrieve data and average across simulation dimension\n",
    "        val = data[0].mean(dim='simulation').item()\n",
    "        \n",
    "        # Add val to metrics to be added into row\n",
    "        metrics.append(val)\n",
    "        \n",
    "    # Create dictionary of values to be input into DataFrame\n",
    "    df.loc[warming_level] = pd.Series(dict(zip(table_vars.keys(), metrics)))\n",
    "    \n",
    "# Make slight modifications to DataFrame\n",
    "df = df.T.rename(columns={'0.0': 'Hist. Period (1980-2010)'})\n",
    "    \n",
    "# Write out dataframe\n",
    "df.to_csv(f\"final_table_{loc_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5ca85-3abd-42ba-a2a8-2a80e07107f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the table\n",
    "oakland_df = df\n",
    "oakland_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566c9ef-fbea-40d2-ac74-953a5e1ea109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360748d-32c0-47f8-99b1-08c3ecba0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_history: {\n",
    "#     metric_applied, \n",
    "#     threshold_applied,\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
