{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ef497a-dcb7-4b23-aa33-2b7690294144",
   "metadata": {},
   "source": [
    "# Vulnerability Assessment Pilot\n",
    "This notebook demonstrates on-going development of climate adaptation vulnerability assessment (CAVA) support using climate data in the Analytics Engine. \n",
    "\n",
    "To execute a given 'cell' of this notebook, place the cursor in the cell and press the 'play' icon, or simply press shift+enter together. Some cells will take longer to run, and you will see a [$\\ast$] to the left of the cell while AE is still working.\n",
    "\n",
    "**Intended Application**: As a user, I want to **<span style=\"color:#FF0000\">access climate projections data for my vulnerability assessment report</span>** by:\n",
    "1. Retrieve data metrics required for planning needs\n",
    "\n",
    "**Runtime**: With the default settings, this notebook takes approximately **less than 10 minutes** to run from start to finish. Modifications to selections may increase the runtime. <br>*This notebook is currently in progress, runtime will change as improvements and further analyses are added.*\n",
    "\n",
    "### Step 0: Set-up\n",
    "\n",
    "First, we'll import the Python library [climakitae](https://github.com/cal-adapt/climakitae), our AE toolkit for climate data analysis, along with this specific functions from that library that we'll use in this notebook, as well as any other necessary Python libraries to aid in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d6530-a94d-416e-81a3-2fac5e79bf72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from climakitae.explore.vulnerability import cava_data\n",
    "from climakitae.explore.vulnerability_table import create_vul_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b50c3-5e8c-4f4c-b7e2-1839ae0c462f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import locations\n",
    "Now we'll read in point-based locations that we want to retrieve data for. For custom inputs, there are two options: (1) Input a single pair of latitude - longitude values; and (2) Import a csv file of locations that will each run. In the code below we show what each option looks like. \n",
    "\n",
    "Functionality to assess over a gridded area (region) is in the works as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bed4b-a58d-4d9b-9a06-adfb5fb89717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select a single custom location\n",
    "# your_lat = LAT\n",
    "# your_lon = LON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435c50f-dec5-4440-9bd6-e5207a317f92",
   "metadata": {},
   "source": [
    "To import your own custom locations, we recommend putting your csv file in the same folder as this notebook for ease:\n",
    "1. Drag and drop a csv file into the file tree on the left hand side; or\n",
    "2. Use the `upload` button (the \"up arrow\" symbol next to the large blue plus symbol above the file tree). \n",
    "\n",
    "<span style=\"color:#FF0000\">**Formatting note**</span>: For the code cells below to work, there must be **2 columns labeled `lat` and `lon`**. Functionality to accept different labeling is forthcoming!\n",
    "\n",
    "In the cell below, we read the csv file in. We extracted three random locations from the HadISD station list as an example here -- you'll want to replace with your own locations file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7366d-562b-4921-8c70-ae76a91a206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dummy locations from `stations_csv` file\n",
    "from climakitae.core.paths import stations_csv_path\n",
    "from climakitae.util.utils import read_csv_file\n",
    "example_locs = read_csv_file(stations_csv_path, index_col=0)[['LAT_Y', 'LON_X']].rename(columns={'LAT_Y': 'lat', 'LON_X': 'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a24db2-dc22-41b9-a259-682781a0b0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select a location from the location list\n",
    "one_loc = example_locs.loc[example_locs.index == 0]\n",
    "loc_lat = one_loc.lat.values[0]\n",
    "loc_lon = one_loc.lon.values[0]\n",
    "print(loc_lat, loc_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bafbc5-2695-422e-a6b7-4795aeb418ad",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve metric data\n",
    "\n",
    "The `cava_data` funciontality is designed to provide flexibility over customizable metric calculation. There are 4 customizable metrics that can be built with this functionality:\n",
    "1. Likely seasonal event occurence (e.g., \"likely summer night low temperature\")\n",
    "2. 1-in-X temperature events (e.g., \"1-in-10 year maximum temperature\")\n",
    "3. High/Extreme Heat Index events (e.g., \"how many days per year does the Heat Index exceed 90°F\")\n",
    "4. 1-in-X precipitation events (e.g., \"1-in-100 year, 24 hour precipitation *in progress*)\n",
    "\n",
    "Below is a table outlining all avaialble arguments to the `cava_data` function. The \"Required\" flag notes whether the argument must be passed to start generating data. Input options for each argument is provided, as well as whether a setting is required for any of the required selections. We provide multiple examples of working with the `cava_data` function with multiple configurations.\n",
    "\n",
    "| Argument | Options | Argument required for | Notes |\n",
    "|----------|---------|-----------------------|-------|\n",
    "|input_locations | Pass a location via csv. | All |*In progress direct input*|\n",
    "|variable | \"Air Temperature at 2m\", \"NOAA Heat Index\"| All |*In progress \"Precipitation (total)\"* |\n",
    "|approach | \"time\", \"warming_level\" | All | |\n",
    "|downscaling_method | \"Dynamical\", \"Statistical\"| All | *In progress Statistical*|\n",
    "|time_start_year | Numerical (min is 1981) | Required for **approach=time** | |\n",
    "|time_end_year | Numerical (max is 2100) | Required for **approach=time**| |\n",
    "|historical_data| \"Historical Climate\", \"Historical Reconstruction\" | Required for **approach=time**| *In progress Historical Reconstruction*|\n",
    "|ssp_data | \"[SSP2-4.5]\", \"[SSP3-7.0]\", \"[SSP5-8.5]\" | Required for **approach=time** | Dynamical only has SSP3-7.0, Statisical has all 3|\n",
    "|warming_level| \"1.5\", \"2.0\", \"3.0\" | Required for **approach=warming_level**| |\n",
    "|metric_calc| \"max\", \"min\" | Required for 1-in-X temp, Heat Index, likely seasonal event | |\n",
    "|heat_idx_threshold | Numerical | Required for Heat Index | |\n",
    "|one_in_x | Numerical | Required for 1-in-X temp| |\n",
    "|percentile | Numerical (0-100) | Required for likely seasonal event |   |\n",
    "|season| \"summer\", \"winter\", \"all\" | Required for likely seasonal event| Default set to \"all\"|\n",
    "|units | Temp/Heat Index: \"degF\", \"degC\", \"K\". Precip: \"mm\", \"inches\" | Optional | Default for temp/heat index is DegF. *In progress Precip*|\n",
    "|wrf_bc| True, False | Optional| Option to select only the 4 bias-adjusted WRF models. Only applicable for **downscaling_method=\"Dynamical\"**. Default set to True |\n",
    "|export_method| \"off-ramp\", \"calculate\", \"both\" | Optional | Default set to \"both\" |\n",
    "|file_format | \"NetCDF\", \"csv\" | Optional | Default set to \"NetCDF\" |\n",
    "|separate_files | True, False | Optional | Option to export separate files if multiple points are passed. Default set to True|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0c405-6996-4823-8af4-f2bda7b0b980",
   "metadata": {},
   "source": [
    "#### Example: Likely seasonal event\n",
    "Example scenario: I want to calculate \"likely summer day high temperature for 2030-2050, where likely is the 75th percentile, in Celsius, using all available WRF data (bias-adjusted and non-bias-adjusted), and export only the calculated metric data\". I would input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedeb1ca-c401-46ce-ae60-943cae75126d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = cava_data(\n",
    "    ## Set-up\n",
    "    example_locs.iloc[:1],\n",
    "    time_start_year=2030, \n",
    "    time_end_year=2050,\n",
    "    downscaling_method=\"Dynamical\",  # default for now\n",
    "    approach=\"time\",  \n",
    "    ssp_data=[\"SSP3-7.0\"],\n",
    "    wrf_bc=False, # return all WRF models\n",
    "    \n",
    "    ## Likely seaonal event specific arguments\n",
    "    variable=\"Air Temperature at 2m\", \n",
    "    metric_calc=\"max\", # daily high temperature\n",
    "    percentile=75, # likeliness percentile\n",
    "    season=\"summer\", # season\n",
    "    units=\"degC\", # change units\n",
    "    \n",
    "    ## Export\n",
    "    export_method=\"calculate\",  # export only calculated metric data\n",
    "    file_format=\"NetCDF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c2c7b-fbe6-4242-be12-2e1fecec1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "test = xr.open_dataset('likely_seasonal_summer_max_2030 to 2050_3543424N_-11905524W.nc')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f215a2e-5098-455d-8e29-3a9e82fc695b",
   "metadata": {},
   "source": [
    "#### Example: 1-in-X event\n",
    "Example scenario: I want to calculate \"1-in-10 year maximum temperature, in Fahrenheit, for 2070-2090, using WRF data, and export both the raw and calculated metric data.\" I would input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb333d9-23db-44c1-a664-985f9e9a79be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cava_data(\n",
    "    ## Set-up\n",
    "    example_locs.iloc[:1],\n",
    "    time_start_year=2070,\n",
    "    time_end_year=2090,\n",
    "    downscaling_method=\"Dynamical\",  # default for now \n",
    "    approach=\"time\",  \n",
    "    ssp_data=[\"SSP3-7.0\"],\n",
    "    \n",
    "    ## 1-in-X event specific arguments\n",
    "    variable=\"Air Temperature at 2m\",\n",
    "    metric_calc=\"max\", # daily maximum temperature\n",
    "    one_in_x=10, # One-in-X\n",
    "    units=\"degF\", # change units\n",
    "    \n",
    "    ## Export\n",
    "    export_method=\"both\",\n",
    "    file_format=\"NetCDF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437119b2-9c7d-423e-b597-c389fe52cec2",
   "metadata": {},
   "source": [
    "#### Example: Heat Index\n",
    "Example scenario: I want to calculate \"the number of days per year that the Heat Index exceeds 90°F between 2030-2060, and export only the raw data\". I would input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3e5f8-1e2b-43a2-b7c0-5129af840331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = cava_data(\n",
    "    ## Set-up\n",
    "    example_locs.iloc[:1],\n",
    "    time_start_year=2030,\n",
    "    time_end_year=2060,\n",
    "    downscaling_method=\"Dynamical\",  # default for now\n",
    "    approach=\"time\",  \n",
    "    ssp_data=[\"SSP3-7.0\"],\n",
    "    \n",
    "    ## Heat Index specific arguments\n",
    "    variable=\"NOAA Heat Index\", \n",
    "    metric_calc=\"max\", # daily maximum\n",
    "    heat_idx_threshold=90, # Heat Index Threshold\n",
    "    units=\"degF\", # change units\n",
    "    \n",
    "    ## Export\n",
    "    export_method=\"off-ramp\",\n",
    "    file_format=\"NetCDF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2078977e-8c4f-477e-978a-a4198f56e5ce",
   "metadata": {},
   "source": [
    "#### Example: Global Warming Level approach\n",
    "Example scenario: I want to calculate \"likely winter day high temperature with a 2°C warming level, where likely is the 60th percentile, in Celsius, using WRF data, and export both the raw and calculated metric data\". I would input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe8ee8-d252-47ed-9b7e-37befd903723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = cava_data(\n",
    "    ## Set-up\n",
    "    example_locs.iloc[:1],\n",
    "    downscaling_method=\"Dynamical\",  # default for now\n",
    "    approach=\"warming_level\",\n",
    "    warming_level=\"2.0\",\n",
    "    \n",
    "    ## Likely seaonal event specific arguments\n",
    "    variable=\"Air Temperature at 2m\", \n",
    "    metric_calc=\"max\", # daily high temperature\n",
    "    percentile=60, # likeliness percentile\n",
    "    season=\"winter\", # season\n",
    "    units=\"degC\", # change units\n",
    "    \n",
    "    ## Export\n",
    "    export_method=\"both\",\n",
    "    file_format=\"NetCDF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befaee12-c451-4827-a783-8bf6ca9257bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e6b5b8-ce77-4202-8f8f-73a6b2debc10",
   "metadata": {},
   "source": [
    "### Appendix: Table Generation Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c558433-b9c2-4b3a-b001-cce58c9067e0",
   "metadata": {},
   "source": [
    "Below, you'll find code that generates a table with different climate data metrics used in a CAVA Report. Feel free to run it and check it out! It is still very much in progress. **This will take 30+ min. to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35d388-1989-4716-8c9f-d78f435c9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "percentile = 50\n",
    "heat_idx_threshold = 80\n",
    "one_in_x = 10 # currently, only can do `one_in_x` for one value at a time\n",
    "df = create_vul_table(example_locs.iloc[[10]], percentile, heat_idx_threshold, one_in_x)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
