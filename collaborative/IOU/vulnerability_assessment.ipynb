{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ef497a-dcb7-4b23-aa33-2b7690294144",
   "metadata": {},
   "source": [
    "# Vulnerability Assessment Pilot\n",
    "This notebook demonstrates on-going development of climate adaptation vulnerability assessment (CAVA) support using climate data in the Analytics Engine. \n",
    "\n",
    "To execute a given 'cell' of this notebook, place the cursor in the cell and press the 'play' icon, or simply press shift+enter together. Some cells will take longer to run, and you will see a [$\\ast$] to the left of the cell while AE is still working.\n",
    "\n",
    "**Intended Application**: As a user, I want to **<span style=\"color:#FF0000\">access climate projections data for my vulnerability assessment report</span>** by:\n",
    "1. Retrieve data metrics required for planning needs\n",
    "\n",
    "**Runtime**: With the default settings, this notebook takes approximately **less than 10 minutes** to run from start to finish. Modifications to selections may increase the runtime. <br>*This notebook is currently in progress, runtime will change as improvements and further analyses are added.*\n",
    "\n",
    "### Step 0: Set-up\n",
    "\n",
    "First, we'll import the Python library [climakitae](https://github.com/cal-adapt/climakitae), our AE toolkit for climate data analysis, along with this specific functions from that library that we'll use in this notebook, as well as any other necessary Python libraries to aid in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d6530-a94d-416e-81a3-2fac5e79bf72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "import pandas as pd\n",
    "\n",
    "from climakitae.explore.vulnerability import cava_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b50c3-5e8c-4f4c-b7e2-1839ae0c462f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import locations\n",
    "Now we'll read in point-based locations that we want to retrieve data for. For custom inputs, there are two options: (1) Input a single pair of latitude - longitude values; and (2) Import a csv file of locations that will each run. In the code below we show what each option looks like. \n",
    "\n",
    "Functionality to assess over a gridded area (region) is in the works as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bed4b-a58d-4d9b-9a06-adfb5fb89717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select a single custom location\n",
    "# your_lat = LAT\n",
    "# your_lon = LON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435c50f-dec5-4440-9bd6-e5207a317f92",
   "metadata": {},
   "source": [
    "To import your own custom locations, we recommend putting your csv file in the same folder as this notebook for ease:\n",
    "1. Drag and drop a csv file into the file tree on the left hand side; or\n",
    "2. Use the `upload` button (the \"up arrow\" symbol next to the large blue plus symbol above the file tree). \n",
    "\n",
    "<span style=\"color:#FF0000\">**Formatting note**</span>: For the code cells below to work, there must be **2 columns labeled `lat` and `lon`**. Functionality to accept different labeling is forthcoming!\n",
    "\n",
    "In the cell below, we read the csv file in. We extracted three random locations from the HadISD station list as an example here -- you'll want to replace with your own locations file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83d9d2-f753-4a7d-ba0b-cb30dc514b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## import an example csv file of multiple locations\n",
    "example_locs = pd.read_csv('hadisd_stations.csv', index_col=0)[['lat', 'lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a24db2-dc22-41b9-a259-682781a0b0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select a location from the location list\n",
    "one_loc = example_locs.loc[example_locs.index == 0]\n",
    "loc_lat = one_loc.lat.values[0]\n",
    "loc_lon = one_loc.lon.values[0]\n",
    "print(loc_lat, loc_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a18588-8941-416f-b641-5dcd7d342884",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve metric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ad41b-da88-47b2-825b-97c4249b7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cava_data(\n",
    "    example_locs.iloc[[0]],\n",
    "    time_start_year=1990,\n",
    "    time_end_year=2010,\n",
    "    units=\"degF\",\n",
    "    downscaling_method='Dynamical', \n",
    "    historical_data='Historical Climate',\n",
    "    ssp_data=['SSP 3-7.0 -- Business as Usual'],\n",
    "    variable=\"Dummy\",\n",
    "    raw_export=\"offramp\",\n",
    ")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
