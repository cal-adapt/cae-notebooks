{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4488d5-cdcf-4202-93d9-8cbc2ef6b16d",
   "metadata": {},
   "source": [
    "# Bias adjust model output with respect to observations\n",
    "\n",
    "In this notebook, we go over the steps required to bias adjust model data to a station, <b>thereby providing localized data which is appropriate for making projections at a given station</b>. We choose to bias adjust with a method called <i>quantile delta mapping</i> (QDM). QDM is chosen here because it better preserves changes in individual quantiles, rather than (say) only applying a adjustment to the mean. \n",
    "\n",
    "**Intended Application**: As a user, I want to **<span style=\"color:#FF0000\">understand how projections data is localized to a weather station</span>**.\n",
    "\n",
    "**Runtime**: With the default settings, this notebook takes approximately **2 minutes** to run from start to finish. Modifications to selections may increase the runtime. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2d148-0675-4fcd-aa24-817e12c8dc58",
   "metadata": {},
   "source": [
    "## Step 0: Set-up\n",
    "Load in the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f2d26-0947-4510-892c-3a1d24b5cf79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "import climakitaegui as ckg\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from climakitae.util.utils import read_csv_file\n",
    "\n",
    "from xclim.core.units import convert_units_to\n",
    "from xsdba import Grouper\n",
    "from xsdba.adjustment import QuantileDeltaMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c16897-f76c-49ad-b160-d82fad315777",
   "metadata": {},
   "source": [
    "## Step 1: Read in the station data\n",
    "Open the HadISD dataset for Sacramento Executive Airport (KSAC) temperatures and do some processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174849d-b0ba-4a47-b2c2-edecdf7ac2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import stations names and coordinates file\n",
    "stations = \"data/hadisd_stations.csv\"\n",
    "stations_df = read_csv_file(stations)\n",
    "my_station = 'KSAC'\n",
    "station_id = str(stations_df[stations_df['ID'] == my_station]['station id'].values[0])\n",
    "\n",
    "filepaths = [\n",
    "    \"s3://cadcat/hadisd/HadISD_{}.zarr\".format(s_id)\n",
    "    for s_id in [station_id]\n",
    "]\n",
    "\n",
    "obs_ds = xr.open_mfdataset(\n",
    "    filepaths,\n",
    "    engine=\"zarr\",\n",
    "    consolidated=False,\n",
    "    parallel=True,\n",
    "    backend_kwargs=dict(storage_options={\"anon\": True}),\n",
    ")\n",
    "\n",
    "obs_ds = obs_ds.tas\n",
    "obs_ds = convert_units_to(obs_ds, \"degF\")\n",
    "obs_ds = obs_ds.convert_calendar(\"noleap\")\n",
    "# need to unchunk for bias adjustment\n",
    "obs_ds = obs_ds.chunk(dict(\n",
    "    time=-1)).compute()\n",
    "\n",
    "# extract coordinates\n",
    "lat0 = obs_ds.latitude.values\n",
    "lon0 = obs_ds.longitude.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d829895-be77-4aad-9611-b7bc3fff2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the timeframe to match the length of the model data (ends in 2014)\n",
    "obs_ds = obs_ds.loc[(obs_ds.time.dt.year >= 1981) & (obs_ds.time.dt.year <= 2014)]\n",
    "\n",
    "# Inspect the observations data\n",
    "obs_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e1fb5-9a0c-49a2-a611-eaba245f9e2a",
   "metadata": {},
   "source": [
    "## Step 2: Read in the model output\n",
    "Here we specifically pick CESM2 because it is known to have a strong warm bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4711d-d57a-470e-8e02-79a3a9900260",
   "metadata": {},
   "outputs": [],
   "source": [
    "selections = ckg.Select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c6804-f9a8-4046-9a73-689d685a8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "selections.scenario_historical=['Historical Climate']\n",
    "selections.scenario_ssp=['SSP 3-7.0']\n",
    "selections.append_historical = True\n",
    "selections.area_average = 'No'\n",
    "selections.time_slice = (1981, 2060)\n",
    "selections.resolution = '3 km'\n",
    "selections.timescale = 'hourly'\n",
    "selections.variable = 'Air Temperature at 2m'\n",
    "selections.units = 'degF'\n",
    "selections.area_subset = 'CA counties'\n",
    "selections.cached_area = ['Sacramento County']\n",
    "\n",
    "wrf_ds = selections.retrieve()\n",
    "\n",
    "# Select just CESM2 simulation \n",
    "cesm_sim_name = [sim for sim in wrf_ds.simulation.values if \"cesm2\" in sim.lower()]\n",
    "wrf_ds = wrf_ds.sel(simulation = cesm_sim_name).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39af68e-73dc-438f-9b99-2bcd289f0a77",
   "metadata": {},
   "source": [
    "Extract the WRF grid cell closest to the station and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2c139-2a9e-4310-9d63-7a2d29f71f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from climakitae.util.utils import get_closest_gridcell\n",
    "\n",
    "# convert calendar\n",
    "wrf_ds = wrf_ds.convert_calendar(\"noleap\")\n",
    "\n",
    "# extract closest grid cell\n",
    "wrf_ds = get_closest_gridcell(wrf_ds, lat0, lon0)\n",
    "\n",
    "# need to unchunk for bias adjustment\n",
    "wrf_ds = wrf_ds.chunk(dict(time=-1)).compute()\n",
    "\n",
    "# do some renaming for plotting ease later\n",
    "wrf_ds.attrs['physical_variable'] = wrf_ds.name\n",
    "wrf_ds.name = 'Raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2669bc09-abbe-4313-9aca-20d31aa7283c",
   "metadata": {},
   "source": [
    "## Step 3: Inspect the model data and observations\n",
    "Here we show record-mean daily-mean temperatures for the observations and raw WRF data to get a sense of the bias in the WRF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58f045-45d9-42ed-ba6a-e33e164e6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ds(ds, obs_ds=obs_ds, projected_ceil=2060):\n",
    "    \n",
    "    proj_floor = str(projected_ceil-29)\n",
    "    proj_ceil = str(projected_ceil)\n",
    "    \n",
    "    hist_ds = ds.sel(time=slice(str(obs_ds.time.values[0]),\n",
    "            str(obs_ds.time.values[-1]))).groupby(\n",
    "            'time.dayofyear').mean()    \n",
    "    ssp_ds = ds.sel(time=slice(proj_floor,proj_ceil)).groupby(\n",
    "            'time.dayofyear').mean()    \n",
    "    obs_ds = obs_ds.groupby(\n",
    "        'time.dayofyear').mean()\n",
    "    \n",
    "    hist_ds = hist_ds.rename(dict(dayofyear = 'Day of Year'))\n",
    "    ssp_ds = ssp_ds.rename(dict(dayofyear = 'Day of Year'))\n",
    "    obs_ds = obs_ds.rename(dict(dayofyear = 'Day of Year'))\n",
    "    \n",
    "    return hist_ds, ssp_ds, obs_ds\n",
    "\n",
    "def compare_raw_and_obs(ds, obs_ds=obs_ds, ylim=(None,None), \n",
    "                        width=700, height=300): \n",
    "    \n",
    "    hist_gp, ssp_gp, obs_gp = group_ds(ds, obs_ds)\n",
    "    \n",
    "    hist_pl = hist_gp.hvplot(label='Historical raw',c='royalblue')    \n",
    "    ssp_pl = ssp_gp.hvplot(label='Projected raw',c='goldenrod')    \n",
    "    obs_pl = obs_gp.hvplot(label='Observations',c='k')\n",
    "   \n",
    "    pl = obs_pl * hist_pl * ssp_pl\n",
    "    pl.opts(ylim=ylim, width=width, height=height, legend_position='right',\n",
    "           toolbar='below', ylabel=obs_ds.units,title='Record-mean Daily-mean '\n",
    "            +ds.attrs['physical_variable'])\n",
    "    \n",
    "    return pl\n",
    "\n",
    "compare_raw_and_obs(wrf_ds, obs_ds=obs_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f7cda-d22d-4225-9360-5e49c8cfc331",
   "metadata": {},
   "source": [
    "## Step 4: Perform the bias adjustment procedure\n",
    "The next cells define and perform the two operations needed for bias adjustment:\n",
    "1. Create the training set, which finds the adjustment factors between the observations and raw model historical data. Note that the raw model output used for training needs to be from the same time period of the observations.\n",
    "2. Apply these adjustment factors to the raw model historical and projected data.\n",
    "\n",
    "All training and adjustment is performed on rolling 90-day windows centered on each day of the year (i.e., +/- 45 days) to allow for seasonal adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba490b-8657-43b4-89f4-ff530dd2152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 90\n",
    "def do_QDM(obs, ds, nquantiles=20, \n",
    "           group='time.dayofyear', window=window, \n",
    "           kind=\"+\"):\n",
    "    \n",
    "    group = Grouper(group, window=window)\n",
    "\n",
    "    ds.attrs['variable'] = ds.name\n",
    "    ds.name = 'Raw' \n",
    "    \n",
    "    QDM = QuantileDeltaMapping.train(obs, ds.sel(\n",
    "        time=slice(str(obs_ds.time.values[0]),\n",
    "        str(obs_ds.time.values[-1]))), \n",
    "        nquantiles=nquantiles, group=group, kind=kind)\n",
    "    \n",
    "    ds_adj = QDM.adjust(ds).compute()\n",
    "    \n",
    "    QDM_ds = QDM.ds.rename(dict(\n",
    "        dayofyear = 'Day of Year', \n",
    "        quantiles='Quantile'))    \n",
    "    \n",
    "    ds_adj.name = 'Adjusted' \n",
    "    ds_adj = xr.merge([ds, ds_adj])\n",
    "    \n",
    "    return QDM_ds,ds_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a3967-d206-4e22-abf8-331a0d54bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adj_factors, adj_ds = do_QDM(obs_ds,wrf_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025cbb5-cb5a-4225-a801-bc48e6cb3432",
   "metadata": {},
   "source": [
    "## Step 5: Visualize the bias adjustment results\n",
    "### Step 5a. Inspect the raw historical WRF quantiles and the adjustment factor for each quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46428dc1-31fb-460b-b672-4360673c8f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "from climakitae.util.colormap import read_ae_colormap\n",
    "\n",
    "raw_cmap = read_ae_colormap(cmap='ae_orange', cmap_hex=True)\n",
    "af_cmap = read_ae_colormap(cmap='ae_diverging', cmap_hex=True)\n",
    "\n",
    "hover_temp = HoverTool(description='Custom Tooltip', \n",
    "        tooltips=[('Quantile', '@Quantile'), \n",
    "        ('Day of Year', '@{Day_of_Year}'),\n",
    "                 ('Temperature (degF)', '@hist_q')])\n",
    "hover_adj = HoverTool(description='Custom Tooltip', \n",
    "        tooltips=[('Quantile', '@Quantile'), \n",
    "        ('Day of Year', '@{Day_of_Year}'),\n",
    "                 ('Adjustment (degF)', '@af')])\n",
    "\n",
    "raw_temp_qs = adj_factors['hist_q'].hvplot.quadmesh(\n",
    "    x='Quantile',y='Day of Year',z='hist_q').opts(\n",
    "    tools=[hover_temp], width=425, height=300,\n",
    "    cmap=raw_cmap, clabel=\"degF\", \n",
    "    title = \"Temperature quantiles by day of year\")\n",
    "adjf_temp = adj_factors['af'].hvplot.quadmesh(\n",
    "    x='Quantile',y='Day of Year',z='af').opts(\n",
    "    tools=[hover_adj], width=425, height=300,\n",
    "    cmap=af_cmap, clabel=\"degF\",\n",
    "    title=\"Adjustment factors for each quantile\")\n",
    "\n",
    "raw_and_af = raw_temp_qs + adjf_temp\n",
    "raw_and_af.opts(title=\"Raw historical quantiles\"\n",
    "                + \" and computed adjustment factors\",\n",
    "               toolbar='below')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ec48b-50fc-4c12-ad23-17e45f7c7392",
   "metadata": {},
   "source": [
    "As expected, adjustment factors here tend to be negative, which is consistent with the known warm bias in the CESM2 global climate model. Now we will compare the raw and adjusted results for the historical and projected model data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f119f57-248e-497f-b1ab-745d555ee6fb",
   "metadata": {},
   "source": [
    "### Step 5b: Directly compare the raw and adjusted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be530b15-581f-486f-9d2c-3a3b0ebe4b33",
   "metadata": {},
   "source": [
    "First we define a function to make comparisons easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308a7e8-9de4-42a7-9e08-6e9e3eb92d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_comparison_plot(hist_ds, ssp_ds, obs_ds=None, \n",
    "                         width=475, height=300, title=\"\",ylim=(None,None)):\n",
    "    \n",
    "    y_str = hist_ds.physical_variable+' ('+hist_ds.attrs['units']+')'\n",
    "    \n",
    "    pl_historical = hist_ds.Raw.hvplot(\n",
    "        color=\"royalblue\", label='Historical '+hist_ds.Raw.name) \n",
    "    pl_historical *= hist_ds.Adjusted.hvplot(\n",
    "        color=\"goldenrod\", line_width=2,\n",
    "        label='Historical '+hist_ds.Adjusted.name)    \n",
    "    if obs_ds is not None:\n",
    "        pl_historical *= obs_ds.hvplot(\n",
    "            color='k',line_width=1, label=\"Observations\")        \n",
    "    pl_historical.opts(\n",
    "        legend_position='top_left', width=width, \n",
    "        height=height, title=title, ylabel=y_str, ylim=ylim)\n",
    "    \n",
    "    pl_ssp = ssp_ds.Raw.hvplot(\n",
    "        color=\"royalblue\", label='Projected '+ssp_ds.Raw.name) \n",
    "    pl_ssp *= ssp_ds.Adjusted.hvplot(\n",
    "        color=\"goldenrod\", line_width=2,label='Projected ' \n",
    "        +ssp_ds.Adjusted.name)    \n",
    "    pl_ssp.opts(\n",
    "        legend_position='top_left', width=width, \n",
    "        height=height, title=title, ylabel=y_str,\n",
    "        ylim=ylim)\n",
    "    \n",
    "    return pl_historical + pl_ssp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c8595-0fc7-48d3-97d4-fc05cb071adc",
   "metadata": {},
   "source": [
    "#### 1. Record-mean daily-mean raw and adjusted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e14df-0283-4ff1-a351-cccdf09dedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_gp, ssp_gp, obs_gp = group_ds(adj_ds, obs_ds) \n",
    "\n",
    "make_comparison_plot(hist_gp, ssp_gp, obs_ds=obs_gp\n",
    "                    ).opts(title=\"Record-mean Daily-mean \"\n",
    "                          + \"Raw and Adjusted Output \"\n",
    "                          + \"for Historical and Projected \"\n",
    "                          + \"Time Periods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463578b3-7537-4afc-8cb8-5a18caf79ac0",
   "metadata": {},
   "source": [
    "#### 2. Annual mean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b1ba2-e73c-4f04-b188-96d93d19c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_gp(ds, obs_ds=obs_ds, projected_ceil=2060):\n",
    "    \n",
    "    proj_floor = str(projected_ceil-29)\n",
    "    proj_ceil = str(projected_ceil)    \n",
    "    hist_ds = ds.sel(time=slice(str(\n",
    "            obs_ds.time.values[0]),\n",
    "            str(obs_ds.time.values[-1]))).groupby(\n",
    "            'time.year').mean()    \n",
    "    ssp_ds = ds.sel(time=slice(proj_floor,\n",
    "            proj_ceil)).groupby('time.year').mean()    \n",
    "    obs_ds = obs_ds.groupby('time.year').mean()    \n",
    "    hist_ds = hist_ds.rename(dict(year = 'Year'))\n",
    "    ssp_ds = ssp_ds.rename(dict(year = 'Year'))\n",
    "    obs_ds = obs_ds.rename(dict(year = 'Year'))    \n",
    "    return hist_ds, ssp_ds, obs_ds\n",
    "\n",
    "ann_hist, ann_ssp, ann_obs = ann_gp(adj_ds, obs_ds=obs_ds)\n",
    "make_comparison_plot(ann_hist, ann_ssp, obs_ds=ann_obs,\n",
    "                    ylim=(57,68)).opts(shared_axes=False, \n",
    "                    title=\"Annual Mean Raw and Adjusted Output \"\n",
    "                    + \"for Historical and Projected Time Periods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61140d8a-f241-4e1a-80a1-1439c69c2885",
   "metadata": {},
   "source": [
    "#### 3. Zoom in on the hourly time series by sampling some weather extremes\n",
    "Define a function to identify extremes in the timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa65402-3029-44a6-9065-3bb7c9b6f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_extremes(ds, obs_ds, projected_ceil=2060, window=72):\n",
    "    \n",
    "    window = window\n",
    "    proj_floor = str(projected_ceil-29)\n",
    "    proj_ceil = str(projected_ceil)    \n",
    "    hist_ds = ds.sel(time=slice(str(\n",
    "        obs_ds.time.values[0]),\n",
    "        str(obs_ds.time.values[-1])))    \n",
    "    hist_max = hist_ds.isel(time=slice(\n",
    "        hist_ds.Raw.argmax().values-window,\n",
    "        hist_ds.Raw.argmax().values+window))\n",
    "    hist_min = hist_ds.isel(time=slice(\n",
    "        hist_ds.Raw.argmin().values-window,\n",
    "        hist_ds.Raw.argmin().values+window))\n",
    "    \n",
    "    ssp_ds = ds.sel(time=slice(proj_floor,\n",
    "            proj_ceil))\n",
    "    ssp_max = ssp_ds.isel(time=slice(\n",
    "        ssp_ds.Raw.argmax().values-window,\n",
    "        ssp_ds.Raw.argmax().values+window))\n",
    "    ssp_min = ssp_ds.isel(time=slice(\n",
    "        ssp_ds.Raw.argmin().values-window,\n",
    "        ssp_ds.Raw.argmin().values+window))    \n",
    "\n",
    "    return hist_min, hist_max, ssp_min, ssp_max\n",
    "hist_min, hist_max, ssp_min, ssp_max = sel_extremes(adj_ds, obs_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218c075-d536-4f34-9db1-5f752d8e1226",
   "metadata": {},
   "source": [
    "##### Plot record maxima for raw and adjusted historical and projected data\n",
    "You will see a repeated warning regarding \"non-standard calendar\" -- don't worry about this! This just means that the data specifically had leap days removed in order to downscale. Removing leap days in bias adjustment is the standard best practice for consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd1a82-e56c-4e12-a1c4-aa40db18c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_comparison_plot(hist_max, ssp_max, ylim=(55, 130),\n",
    "                    ).opts(shared_axes=False, \n",
    "                    title=\"Maximum hourly temperature +/- 72 hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e91102-0927-4359-9df1-454ead1f39e2",
   "metadata": {},
   "source": [
    "##### Plot record minima for raw and adjusted historical and projected data\n",
    "You'll see the same \"non-standard calendar\" warning again - you can safely ignore this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bfefa-77c0-4f11-9282-d3baad809b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_comparison_plot(hist_min, ssp_min, ylim=(-5, 53),\n",
    "                    ).opts(shared_axes=False, \n",
    "                    title=\"Minimum hourly temperature +/- 72 hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da36cf-a665-4cb7-85df-ef5c7971cfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
