{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d144d7c0-02c8-4b37-a357-a9c9f3112f08",
   "metadata": {},
   "source": [
    "## Calculating a Typical Meteorological Year\n",
    "\n",
    "This notebook walks through the process of calculating a [Typical Meteorological Year](https://nsrdb.nrel.gov/data-sets/tmy), an hourly dataset used for applications in energy and building systems modeling. Because this represents average rather than extreme conditions, an TMY dataset is not suited for designing systems to meet the worst-case conditions occurring at a location. \n",
    "\n",
    "The TMY methodology here mirrors that of the Sandia/NREL TMY3 methodology, and uses historic and projected downscaled climate data available through the Cal-Adapt: Analytics Engine catalog. As this methodology heavily weights the solar radiation input data, be aware that the final selection of \"typical\" months may not be typical for other variables. \n",
    "\n",
    "The Analytics Engine at present has an *Average Meteorological Year* functionality. The methods shown throughout this notebook will soon replace the underlying backend `climakitae` code for the AMY in order to better address our user needs, i.e., we are working to replace the AMY with the TMY methods. We provide this walkthrough to demonstrate confidence in the \"AMY to TMY\" conversion process for our users in the meantime. \n",
    "\n",
    "<span style=\"color:#FF0000\">**Note**: <span style=\"color:#000000\"> At present, one of the core variables (direct normal irradiance) required to calculate a TMY is not currently available in the Cal-Adapt: Analytics Engine catalog but is coming soon. Until DNI is available, the resulting TMY files produced in this notebook may not accurately reflect typical conditions. This notebook will be updated once DNI is available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a4e19-0c14-4bb8-b410-68f93cc7a2a4",
   "metadata": {},
   "source": [
    "### Step 0: Set-up\n",
    "\n",
    "Import the [climakitae](https://github.com/cal-adapt/climakitae) library and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915116c8-7f12-473e-baa2-656349be1070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "from tqdm.auto import tqdm  # Progress bar\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from climakitae.data_export import write_tmy_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7680e83-1ae9-4c60-8dcf-e8223c77b23c",
   "metadata": {},
   "source": [
    "To use climakitae, load a new application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab208581-4d91-4a03-a0d7-bc9ada719cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app = ck.Application()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd29b6-4bd4-4e3e-864e-688480d8edb1",
   "metadata": {},
   "source": [
    "### Step 1: Grab and process all required input data\n",
    "\n",
    "The [TMY3 method](https://www.nrel.gov/docs/fy08osti/43156.pdf) selects a \"typical\" month based on ten daily variables: max, min, and mean air and dew point temperatures, max and mean wind speed, global irradiance and direct irradiance. Some of these variables are already available in the Analytics Engine data catalog, and some we will need to calculate ourselves.  \n",
    "\n",
    "#### Step 1a: Select location of interest\n",
    "TMYs are usually calculated for a specific location of interest, like a building or power plant. Here, we will use a known weather station location, via their latitude and longitude to extract the data that we need to calculate the TMY.  In the example below, we will look specifically at Los Angeles International Airport, but will note in the code below how you can provide your own location coordinates too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a86a0-7a14-47c7-bf89-ee5c76a34aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in station file of CA HadISD stations\n",
    "stn_file = pkg_resources.resource_filename(\"climakitae\", \"data/hadisd_stations.csv\")\n",
    "stn_file = pd.read_csv(stn_file, index_col=[0])\n",
    "stn_file.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e25d5-a9da-4605-837d-2e93b0f77c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grab airport\n",
    "station_name = \"Los Angeles International Airport\"\n",
    "one_station = stn_file.loc[stn_file['station'] == station_name]\n",
    "stn_lat = one_station.LAT_Y.item()\n",
    "stn_lon = one_station.LON_X.item()\n",
    "stn_lat, stn_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba66963-c12f-4b47-8e37-b532fe8e38a0",
   "metadata": {},
   "source": [
    "Alternatively, you may want to provide your own location instead of one of the HadISD stations above. If so, uncomment the cell below by removing the `#` symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7f107-2221-4e95-be18-8e2db5dc3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "## provide your own location, via latitude and longitude coordinates\n",
    "# stn_lat = YOUR_LAT_HERE\n",
    "# stn_lon = YOUR_LON_HERE\n",
    "# station_name = 'YOUR_STATION_NAME_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15867d87-1951-4ec5-a503-35a61516810f",
   "metadata": {},
   "source": [
    "#### Step 1b: Variables in catalog\n",
    "When selecting data, there are several considerations to be aware of. The recommended minimum input of data is 15-20 years worth of daily data. First, we will pre-load some data options to ensure that the same constraints are applied to every variable we retrieve from the catalog and calculate. For example, we will process the data for our designated station location (latitude, and longitude) at 45 km over the 1990-2020 period. For data post-2014, we will utilize SSP 3-7.0, although scenario selection in the near-future is relatively independent. If calculating a TMY for the far-future, **carefully consider which scenario SSP to include**, as there will be **significant** differences present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57645bd8-517c-4de8-95fa-a565b66d0cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# default selections applicable to all variables selected\n",
    "app.selections.data_type = \"Gridded\"\n",
    "app.selections.area_average = \"Yes\"\n",
    "app.selections.scenario_historical = [\"Historical Climate\"]\n",
    "app.selections.scenario_ssp = [\"SSP 3-7.0 -- Business as Usual\"] # Important based on time period considered!!\n",
    "app.selections.time_slice = (1990, 2020)\n",
    "app.selections.timescale = \"daily\"\n",
    "app.selections.resolution = \"45 km\"\n",
    "app.selections.cached_area = ['coordinate selection']\n",
    "app.selections.latitude = (stn_lat-0.2, stn_lat+0.2)\n",
    "app.selections.longitude = (stn_lon-0.2, stn_lon+0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0799c331-5024-484d-beb2-cf97333aed9b",
   "metadata": {},
   "source": [
    "Now that we have set up default settings, let's start retrieving data! First, retrieve min, max, and mean air temperature: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41675b1e-23a0-4522-96c6-88edde5fdfea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max air temp\n",
    "app.selections.variable = \"Maximum air temperature at 2m\"\n",
    "app.selections.units = \"degC\"\n",
    "max_airtemp_data = app.retrieve()\n",
    "\n",
    "# min air temp\n",
    "app.selections.variable = \"Minimum air temperature at 2m\"\n",
    "app.selections.units = \"degC\"\n",
    "min_airtemp_data = app.retrieve()\n",
    "\n",
    "# mean air temperature\n",
    "app.selections.variable = \"Air Temperature at 2m\" \n",
    "app.selections.units = \"degC\"\n",
    "mean_airtemp_data = app.retrieve()\n",
    "mean_airtemp_data.name = \"Mean air temperature at 2m\" # rename for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fff96-9508-4435-932b-bce39a02427a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:09:40.599835Z",
     "iopub.status.busy": "2023-05-11T19:09:40.599455Z",
     "iopub.status.idle": "2023-05-11T19:09:44.067646Z",
     "shell.execute_reply": "2023-05-11T19:09:44.066937Z",
     "shell.execute_reply.started": "2023-05-11T19:09:40.599805Z"
    }
   },
   "source": [
    "Retrieve max and mean wind speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee63c6e-48b0-47bd-9903-2d4862c91ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max wind speed\n",
    "app.selections.variable = \"Maximum wind speed at 10m\"\n",
    "app.selections.units = \"m s-1\"\n",
    "max_windspd_data = app.retrieve()\n",
    "\n",
    "# mean wind speed\n",
    "app.selections.variable = \"Mean wind speed at 10m\"\n",
    "app.selections.units = \"m s-1\"\n",
    "mean_windspd_data = app.retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc631d7-c1fa-4149-9444-f59364393e1e",
   "metadata": {},
   "source": [
    "#### Step 1c: Variables that need to be calculated\n",
    "Next, we will need to retrieve **hourly** data from the catalog to calculate the following variables, as they are not natively within the Analytics Engine data catalog. \n",
    "- Max, min, and mean dew point temperature\n",
    "- Global horizontal irradiance\n",
    "- Direct normal irradiance **-- coming to the AE catalog soon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54795e50-1c27-499e-887b-b59a4396206e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# switch to hourly timescale\n",
    "app.selections.timescale = \"hourly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e36017-8660-497a-9b37-0b0e06c24b16",
   "metadata": {},
   "source": [
    "Next, calculate max, min, and mean dew point temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31903320-2bcc-4093-9085-0ea4ec34c4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dew point temperature\n",
    "app.selections.variable = \"Dew point temperature\"\n",
    "app.selections.units = \"degC\"\n",
    "dewpt_data = app.retrieve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5808cd-56c9-42e7-808c-c2147ae4a1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_dewpt_data = dewpt_data.resample(time=\"1D\").max() # daily max dewpoint temp\n",
    "max_dewpt_data.name = \"Daily max dewpoint temperature\" # rename for clarity\n",
    "\n",
    "min_dewpt_data = dewpt_data.resample(time=\"1D\").min() # daily min dewpoint temp\n",
    "min_dewpt_data.name = \"Daily min dewpoint temperature\" # rename for clarity\n",
    "\n",
    "mean_dewpt_data = dewpt_data.resample(time=\"1D\").mean() # daily mean dewpoint temp\n",
    "mean_dewpt_data.name = \"Daily mean dewpoint temperature\" # rename for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421571f-fcac-44fa-aedb-b3f8e77bfa3c",
   "metadata": {},
   "source": [
    "Next, retrieve global horizontal irradiance. GHI is within the Analytics Enginge catalog at daily resolutions, but for the TMY methodology, we need to calculate the total accumulated GHI received over the course of the day, so we will retrieve hourly data instead and calculate the necessary information below. The same process is repeated for the direct normal irradiance (once the data is in the AE catalog). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adc629-3205-412d-9274-2c447ce21621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global irradiance\n",
    "app.selections.variable = \"Instantaneous downwelling shortwave flux at bottom\"\n",
    "global_irradiance_data = app.retrieve()\n",
    "global_irradiance_data.name = \"Global horizontal irradiance\" # rename for clarity\n",
    "total_ghi_data = global_irradiance_data.resample(time=\"1D\").sum() # total global horizontal irradiance (accumulation of hourly data over a 24-hour period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fd1f3-fbee-4dd6-9ad9-61a9c925cd25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ONCE IN CATALOG\n",
    "\n",
    "# # direct normal irradiance\n",
    "# app.selections.variable = \"VARIABLE_NAME_HERE\"\n",
    "# direct_irradiance_data = app.retrieve()\n",
    "# direct_irradiance_data.name = \"Direct normal irradiance\" # rename for clarity\n",
    "# total_dni_data = direct_irradiance_data.resample(time=\"1D\").sum() # total direct normal irradiance (accumulation of hourly data over a 24-hour period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2ea23-b6f9-4665-be6e-0dc5bf5da726",
   "metadata": {},
   "source": [
    "#### Step 1d: Load all variables\n",
    "Now that we have all of our data retrieved and calculated, it is time to actually load the data into memory. Previously, xarray has lazily loaded the data, but we will actually grab it now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806e4f2-2828-4e1a-9f22-0ae1aac9dfca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_vars = xr.merge([max_airtemp_data.squeeze(), min_airtemp_data.squeeze(), mean_airtemp_data.squeeze(),\n",
    "                     max_dewpt_data.squeeze(), min_dewpt_data.squeeze(), mean_dewpt_data.squeeze(),\n",
    "                     max_windspd_data.squeeze(), mean_windspd_data.squeeze(),\n",
    "                     total_ghi_data.squeeze()]) #, total_dni_data.squeeze()]) # uncomment once DNI in catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f1e1f-c0da-405b-848d-8f584c3fa804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load all indices in\n",
    "all_vars = all_vars.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65ebb8-f730-4ab3-9eb4-4642624b4a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccfed5a-4a71-4ff3-be45-d20565d44cf4",
   "metadata": {},
   "source": [
    "### Step 2: Calculate cumultative distribution functions\n",
    "\n",
    "For the TMY, the cumulative distribution function gives the proportion of values that are less than or equal to a specified value of the index. In this case, we want to identify months that are as close to the long-term climatology for each variable as possible, indicating months that are \"typical\".  \n",
    "\n",
    "#### Step 2a: Calculate long-term climatology CDFs for each index\n",
    "First, we need to calculate the long-term climatology for each index for each month so we can establish the baseline pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e54317-35e5-4465-93a7-9cd4772f11a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cdf(da): \n",
    "    \"\"\"Compute the cumulative density function for an input DataArray\"\"\"\n",
    "    da_np = da.values # Get numpy array of values\n",
    "    num_samples = 1024 # Number of samples to generate\n",
    "    count, bins_count = np.histogram( # Create a numpy histogram of the values \n",
    "        da_np, bins = np.linspace(\n",
    "            da_np.min(), # Start at the minimum value of the array \n",
    "            da_np.max(), # End at the maximum value of the array \n",
    "            num_samples\n",
    "        )\n",
    "    )\n",
    "    cdf_np = np.cumsum(count/sum(count)) # Compute the CDF \n",
    "    \n",
    "    # Turn the CDF array into xarray DataArray \n",
    "    # New dimension is the bin values \n",
    "    cdf_da = xr.DataArray( \n",
    "        [bins_count[1:],cdf_np],\n",
    "        dims=[\"data\",\"bin_number\"],\n",
    "        coords = {\n",
    "            \"data\":[\"bins\",\"probability\"],\n",
    "        }\n",
    "    )\n",
    "    cdf_da.name = da.name\n",
    "    return cdf_da\n",
    "\n",
    "def get_cdf_by_sim(da): \n",
    "    # Group the DataArray by simulation\n",
    "    return da.groupby(\"simulation\").apply(compute_cdf)\n",
    "\n",
    "def get_cdf_by_mon_and_sim(da): \n",
    "    # Group the DataArray by month in the year \n",
    "    return da.groupby(\"time.month\").apply(get_cdf_by_sim)\n",
    "\n",
    "def get_cdf(ds): \n",
    "    \"\"\"Get the cumulative density function. \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    ds: xr.Dataset\n",
    "        Input data to compute CDF for\n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "    \"\"\"\n",
    "    return ds.apply(get_cdf_by_mon_and_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b852f3a-5b9e-42b8-9224-ee5c17341456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_climatology = get_cdf(all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77894a-c554-4407-8153-41ab7115687c",
   "metadata": {},
   "source": [
    "Next, we set up a handy plotting function so that we can view the CDF patterns for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24608790-baed-408f-897f-2d2c2a034ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_one_var_cdf(cdf_da): \n",
    "    \"\"\"Plot CDF for a single variable \n",
    "    Written to function for the unique configuration of the CDF DataArray object\n",
    "    Silences an annoying hvplot warning \n",
    "    Will show every simulation together on the plot \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    cdf: xr.DataArray \n",
    "       Cumulative density function for a single variable \n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    panel.layout.base.Column\n",
    "        Hvplot lineplot \n",
    "        \n",
    "    \"\"\"\n",
    "    prob_da = cdf_da.sel(data=\"probability\",drop=True).rename(\"probability\") # Grab only probability da \n",
    "    bins_da = cdf_da.sel(data=\"bins\",drop=True).rename(\"bins\") # Grab just bin values\n",
    "    ds = xr.merge([prob_da,bins_da]) # Merge the two to form a single Dataset object\n",
    "    cdf_pl = ds.hvplot(\n",
    "        \"bins\",\"probability\", \n",
    "        by=\"simulation\", # Simulations should all be displayed together \n",
    "        widget_location=\"bottom\",\n",
    "        grid=True,\n",
    "        xlabel=\"{0} ({1})\".format(var,cdf_da.attrs[\"units\"]), \n",
    "        xlim=(bins_da.min().item(), bins_da.max().item()), # Fix the x-limits for all months\n",
    "        ylabel=\"Probability (0-1)\", \n",
    "    )\n",
    "    return cdf_pl "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af453d-6f91-4668-804f-7264d2929e58",
   "metadata": {},
   "source": [
    "In the plot below, we'll display maximum air temperature to assess the climatological CDF pattern, but you can modify the variable here to one of your choosing to see the pattern too! Also select a different month by moving the slider bar to see the pattern throughout the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca17cbe-1b58-4767-978c-ddf91056e45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose your desired variable\n",
    "var = \"Maximum air temperature at 2m\"\n",
    "\n",
    "# Make the plot\n",
    "cdf_plot = plot_one_var_cdf(cdf_climatology[var])\n",
    "display(cdf_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84c83b-e764-4bdd-8a6f-8ab67016ca97",
   "metadata": {},
   "source": [
    "#### Step 2b: Calculate CDFs for each index for all months\n",
    "\n",
    "Next, we will calculate CDF for each month and each variable, for which we ultimatley will compare against climatology. For the individual months, we must also exclude the period of time during a major volcanic eruption (Pinatubo: June 1991 to December 1994) as the aerosols have an impact on solar variables. The cells below functions exlude this data from our data next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db16c3-26be-411a-a409-da1b6985958f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cdf_monthly(ds):\n",
    "    \"\"\"Get the cumulative density function by unique mon-yr combos\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    ds: xr.Dataset\n",
    "        Input data to compute CDF for\n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "    \"\"\"\n",
    "    def get_cdf_mon_yr(da): \n",
    "        return da.groupby(\"time.year\").apply(get_cdf_by_mon_and_sim)\n",
    "    return ds.apply(get_cdf_mon_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826631ec-f25b-42dc-9928-6a0d5ed4f376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_monthly = get_cdf_monthly(all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f5728-de7b-4d21-8622-e39437b64dbd",
   "metadata": {},
   "source": [
    "Now we'll remove the volcanic years: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabb491-0c8b-48a7-b519-bf135fceaf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the years for the Pinatubo eruption \n",
    "cdf_monthly = cdf_monthly.where(\n",
    "    (~cdf_monthly.year.isin([1991,1992,1993,1994])), \n",
    "    np.nan, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f526746-efce-48ec-ae3c-e86359097ac2",
   "metadata": {},
   "source": [
    "Like the climatology CDF figure above, let's check out the individual months next. You can modify the variable, and month-year to display too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e582a-e24f-41bc-8da7-6c8567338240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose your desired variable\n",
    "var = \"Maximum air temperature at 2m\"\n",
    "\n",
    "# Make the plot\n",
    "cdf_plot_mon_yr = plot_one_var_cdf(cdf_monthly[var])\n",
    "display(cdf_plot_mon_yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad80428-e476-408a-927a-ddb33f801c37",
   "metadata": {},
   "source": [
    "### Step 3: Compare climatology CDF to monthly CDF for each variable\n",
    "\n",
    "Now that we hvae the distributions for the long-term climatology of our 30-year period, and the corresponding distribution for each month in that 30-year period, we need to assess how each individual month compares to the long-term climatology. In essence, we are looking for the individual months that best capture the climatology distribution. \n",
    "\n",
    "#### Step 3a: Calculate the Finkelstein-Schafer statistic \n",
    "The [Finkelstein-Schafer statistic](https://academic.oup.com/biomet/article-abstract/58/3/641/233677) determines the absolute difference between the long-term climatology and candidate CDF profiles, and considers the number of days within each month. We will use a handy function `fs_statistic` to calculate this below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b931f7-6733-415c-8f6d-1d44a976910d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fs_statistic(cdf_climatology, cdf_month):\n",
    "    \"\"\"\n",
    "    Calculates the Finkelstein-Schafer statistic:\n",
    "    Absolute difference between long-term climatology and candidate CDF, divided by number of days in month\n",
    "    \"\"\"\n",
    "    days_per_mon = xr.DataArray(\n",
    "        data=[31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31], \n",
    "        coords={\"month\":np.arange(1,13)}\n",
    "    )\n",
    "    fs_stat = abs(cdf_monthly - cdf_climatology).sel(data=\"probability\") / days_per_mon\n",
    "    return fs_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab26fd-1c1c-4122-9158-4f35035dfe6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_vars_fs = fs_statistic(cdf_climatology, cdf_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85fb8c2-2e5f-48eb-bfea-9fe0d3fc37e2",
   "metadata": {},
   "source": [
    "#### Step 3b: Weight the F-S statistic\n",
    "\n",
    "Next, we weight the F-S statistic results based on the input variables. The [TMY3](https://www.nrel.gov/docs/fy08osti/43156.pdf) method places a higher weight to the solar variables (global irradiance and direct irradiance), which we follow here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e4fd1-6297-4321-9186-ae5e57e5254b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weighted_fs(da_fs):\n",
    "    \"\"\"Weights the F-S statistics based on TMY3 methodology\"\"\"\n",
    "    weights_per_var = {\n",
    "        'Maximum air temperature at 2m':1/20,\n",
    "        'Minimum air temperature at 2m':1/20,\n",
    "        'Mean air temperature at 2m':2/20,\n",
    "        'Daily max dewpoint temperature':1/20,\n",
    "        'Daily min dewpoint temperature':1/20,\n",
    "        'Daily mean dewpoint temperature':2/20,\n",
    "        'Maximum wind speed at 10m':1/20,\n",
    "        'Mean wind speed at 10m':1/20,\n",
    "        'Global horizontal irradiance':5/20\n",
    "        # 'Direct normal irradiance':5/20 ## uncomment once in catalog\n",
    "    }\n",
    "\n",
    "    for var, weight in weights_per_var.items(): \n",
    "        # Multiply each variable by it's appropriate weight \n",
    "        da_fs[var] = da_fs[var]*weight \n",
    "    return da_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48c015-b629-4504-8913-02b8ec9544df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weighted_fs = compute_weighted_fs(all_vars_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711568f-3622-4103-89e9-a908d545a569",
   "metadata": {},
   "source": [
    "#### Step 3c: Select candidate months for consideration\n",
    "Once weighted, we select the top candidate months for each month that have lowest weighted sums, meaning that these candidate months are the closest to the long-term climatology for that month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145ea68-735c-46c7-8f5e-bc314c900248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sum \n",
    "weighted_fs_sum = weighted_fs.to_array().sum(dim=[\"variable\",\"bin_number\"]).drop([\"data\"])\n",
    "\n",
    "# Pass the weighted F-S sum data for simplicity\n",
    "ds = weighted_fs_sum\n",
    "\n",
    "df_list = []\n",
    "num_values = 1 # Selecting the top value for now, persistence statistics calls for top 5\n",
    "for sim in ds.simulation.values: \n",
    "    for mon in ds.month.values:\n",
    "        da_i = ds.sel(month=mon, simulation=sim)\n",
    "        top_xr = da_i.sortby(da_i, ascending=True)[:num_values].expand_dims([\"month\",\"simulation\"])\n",
    "        top_df_i = top_xr.to_dataframe(name=\"top_values\")\n",
    "        df_list.append(top_df_i)\n",
    "        \n",
    "# Concatenate list together for all months and simulations\n",
    "top_df = pd.concat(df_list).drop(columns=[\"top_values\"]).reset_index()\n",
    "top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddeab6-c43b-42ca-ad8e-396cb90fce49",
   "metadata": {},
   "source": [
    "The data table above represents the ideal months that represent the long term climatology based on the 10 indices for the 4 simulations in the Analytics Engine catalog. Meaning, for a \"typical\" meteorological year, CESM2 data for Jan will come from Jan 2003, data for Feb will come from 1996, and so on. In the next step, we will generate the resulting \"TMY\" file that is commonly used in such applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd2214b-0368-49a6-bf71-f17916a7f860",
   "metadata": {},
   "source": [
    "### Step 4: Generate the TMY data outputs\n",
    "\n",
    "Generally, the following data is outputted using the TMY months:\n",
    "- Date & time (UTC)\n",
    "- Air temperate at 2m [°C]\n",
    "- Dew point temperature [°C]\n",
    "- Relative humidity [%]\n",
    "- Global horizontal irradiance [W/m2]\n",
    "- Direct normal irradiance [W/m2] -- ***coming soon to AE***\n",
    "- Diffuse horizontal irradiance [W/m2]\n",
    "- Downwelling infrared radiation [W/m2]\n",
    "- Wind speed at 10m [m/s]\n",
    "- Wind direction at 10m [°]\n",
    "- Surface air pressure [Pa]\n",
    "\n",
    "The following function will retrieve all of this data for the designated TMY month and concatenate it together into a pandas dataframe so that we can export it as a csv file. We'll do this next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cb538-f892-42cc-b6cf-b5cfa05c7f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_tmy_data(top_df): \n",
    "    \"\"\"Generate typical meteorological year data \n",
    "    Ouput will be a list of dataframes per simulation. \n",
    "    Print statements throughout the function indicate to the user the progress of the computation. \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    top_df: pd.DataFrame \n",
    "        Table with column values month, simulation, and year \n",
    "        Each month-sim-yr combo represents the top candidate that has the lowest weighted sum from the FS statistic \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    dict of str:pd.DataFrame \n",
    "        Dictionary in the format of {simulation:TMY corresponding to that simulation} \n",
    "    \n",
    "    \"\"\"\n",
    "    ## ================== GET DATA FROM CATALOG ==================\n",
    "    vars_and_units = {\n",
    "        'Air Temperature at 2m':'degC',\n",
    "        'Dew point temperature':'degC',\n",
    "        'Relative humidity':'[0 to 100]', \n",
    "        'Instantaneous downwelling shortwave flux at bottom':'W m-2',\n",
    "        # 'direct irradiance here':'W m-2', ## uncomment once in catalog \n",
    "        'Shortwave surface downward diffuse irradiance':'W m-2',\n",
    "        'Instantaneous downwelling longwave flux at bottom':'W m-2',\n",
    "        'Wind speed at 10m':'m s-1',\n",
    "        'Wind direction at 10m':'degrees',\n",
    "        'Surface Pressure':'Pa' # Pa\n",
    "    }\n",
    "    \n",
    "    # Set up shared catalog access settings\n",
    "    app.selections.data_type = \"Gridded\"\n",
    "    app.selections.area_average = \"No\"\n",
    "    app.selections.scenario_historical = [\"Historical Climate\"]\n",
    "    app.selections.scenario_ssp = [\"SSP 3-7.0 -- Business as Usual\"] # Important based on time period considered!!\n",
    "    app.selections.timescale = \"hourly\"\n",
    "    app.selections.resolution = \"45 km\"\n",
    "    app.selections.cached_area = ['coordinate selection']\n",
    "    app.selections.latitude = (stn_lat-0.2, stn_lat+0.2)\n",
    "    app.selections.longitude = (stn_lon-0.2, stn_lon+0.2)\n",
    "    app.selections.time_slice = (1990, 2020)\n",
    "\n",
    "    # Loop through each variable and grab data from catalog \n",
    "    all_vars_list = []\n",
    "    print(\"STEP 1: RETRIEVING HOURLY DATA FROM CATALOG\\n\")\n",
    "    for var, units in vars_and_units.items(): \n",
    "        print(\"Retrieving data for {0}\".format(var), end=\"... \")\n",
    "        app.selections.variable = var # Set variable\n",
    "        app.selections.units = units # Set units  \n",
    "        data_by_var = app.retrieve() # Retrieve data from catalog \n",
    "\n",
    "        # Drop unwanted coords\n",
    "        data_by_var = data_by_var.squeeze().drop(['lakemask','landmask','x','y','Lambert_Conformal'])\n",
    "\n",
    "        all_vars_list.append(data_by_var) # Append to list \n",
    "        print(\"complete!\")\n",
    "\n",
    "    # Merge data from all variables into a single xr.Dataset object \n",
    "    all_vars_ds = xr.merge(all_vars_list)\n",
    "\n",
    "\n",
    "    ## ================== CONSTRUCT TMY ==================\n",
    "    print(\"\\nSTEP 2: CALCULATING TYPICAL METEOROLOGICAL YEAR PER MODEL SIMULATION\\nProgress bar shows code looping through each month in the year.\\n\")\n",
    "    tmy_df_all = {}\n",
    "    for sim in all_vars_ds.simulation.values: \n",
    "        df_list = []\n",
    "        print(\"Calculating TMY for simulation: {0}\".format(sim))\n",
    "        for mon in tqdm(np.arange(1,13,1)): \n",
    "            # Get year corresponding to month and simulation combo \n",
    "            year = top_df.loc[(top_df[\"month\"] == mon) & (top_df[\"simulation\"] == sim)].year.item()\n",
    "\n",
    "            # Select data for unique month, year, and simulation\n",
    "            data_at_stn_mon_sim_yr = all_vars_ds.sel(simulation=sim, time=\"{0}-{1}\".format(mon, year)).expand_dims(\"simulation\")\n",
    "\n",
    "            # Reformat as dataframe \n",
    "            df_by_mon_sim_yr = data_at_stn_mon_sim_yr.to_dataframe()\n",
    "            df_by_mon_sim_yr = df_by_mon_sim_yr.reset_index()\n",
    "\n",
    "            # Reformat time index to remove year\n",
    "            df_by_mon_sim_yr[\"time\"] = pd.to_datetime(df_by_mon_sim_yr[\"time\"].values).strftime(\"%m-%d %H:%M:%S\")\n",
    "            df_list.append(df_by_mon_sim_yr)\n",
    "\n",
    "        # Concatenate all DataFrames together \n",
    "        tmy_df_by_sim = pd.concat(df_list)\n",
    "        tmy_df_all[sim] = tmy_df_by_sim\n",
    "        \n",
    "    return tmy_df_all # Return dict of TMY by simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792e895-ac9f-4bcf-8c56-9fa0c9e6597a",
   "metadata": {},
   "source": [
    "In the next cell, we will run the `generate_tmy_data` function which will retrieve, subset, and format the data for each month according to the TMY months for all requested variables. We have included print statements so you can watch the progress for each variable in each month as it builds. \n",
    "\n",
    "<span style=\"color:#FF0000\">**Note**: <span style=\"color:#000000\"> This will take time! On the Analytics Engine JupyterHub, this takes approximately 20 minutes. Progress bars will indicate the status of generating the TMY data for each simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e87db-afc8-4bb2-a653-1f735b02449b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmy_data_to_export = generate_tmy_data(top_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25572b6-2e07-442f-9ea3-90825943ad54",
   "metadata": {},
   "source": [
    "Let's observe what the TMY data looks like for one of the simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272fe2e0-7f10-4e8a-9c2e-fde2cd9f7cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulation = \"WRF_CESM2_r11i1p1f1\"\n",
    "tmy_data_to_export[simulation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951a416-b2bf-4924-84b2-f5fd409913bc",
   "metadata": {},
   "source": [
    "Next, we visualize the TMY data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ceebfa-a927-43e3-8bb9-28ee700d1c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmy_data_to_export[simulation].plot(x='time',y=['Air Temperature at 2m',\n",
    "                                                'Dew point temperature',\n",
    "                                                'Relative humidity',\n",
    "                                                'Instantaneous downwelling shortwave flux at bottom',\n",
    "                                                'Shortwave surface downward diffuse irradiance',\n",
    "                                                'Instantaneous downwelling longwave flux at bottom',\n",
    "                                                'Wind speed at 10m', 'Wind direction at 10m', 'Surface Pressure'], \n",
    "                                    title='Typical Meteorological Year ({})'.format(simulation),\n",
    "                                    subplots=True, figsize=(10,8), legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab490aa2-3b4e-428a-8740-1f174b7c55f5",
   "metadata": {},
   "source": [
    "Lastly, let's export the TMY data below as csv files. There will be a file per simulation downloaded. When utilizing TMY data in your own workflows, we recommend that **all simulations are considered** in your analyses, especially for future scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30451d-0345-45ce-bd73-65aa70be2f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sim, tmy in tmy_data_to_export.items(): \n",
    "    filename = 'TMY_{0}_{1}'.format(station_name.replace(\" \", \"_\"), sim).lower()\n",
    "    write_tmy_file(filename, tmy_data_to_export[sim], location_name=station_name, file_ext=\"epw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cfd211-2223-47b7-9bbb-e465180a39c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
