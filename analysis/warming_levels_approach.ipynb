{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7837b7-5c51-484f-8ec6-d905bfb8d30c",
   "metadata": {},
   "source": [
    "Exploring the Differences Between a Traditional SSP Framework and a Global Warming Levels Approach# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b837a2-9471-412d-82ac-d014829e42a2",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the different scientific procedures that go behind two major approaches towards understanding regional global warming today:\n",
    "1. Traditional global warming approach using SSP's (Shared Socioeconomic Pathways)\n",
    "    - We will reference this approach as the **Traditional SSP Approach** throughout this notebook.\n",
    "2. New global warming approach using Warming Levels\n",
    "    - We will reference this approach as the **New GWL Approach** throughout this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1451baf-6ac9-4213-91e6-547f5dcf3f25",
   "metadata": {},
   "source": [
    "From this notebook, we will understand:\n",
    "- The different approaches towards understanding global warming levels\n",
    "- Statistical findings to back our conclusions using extreme heat days as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca1027-cf39-4e14-a5bc-8e3cb1ca46a8",
   "metadata": {},
   "source": [
    "**Intended Application:** As a user, I want to  **<span style=\"color:#FF0000\">understand the differences between a traditional SSP approach and the new Global Warming Levels framework with respect to extreme event planning.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a93c3b-f6a3-40a0-a2dc-a6d907535c95",
   "metadata": {},
   "source": [
    "**Runtime**: With the default settings, this notebook takes approximately **40 minutes** to run from start to finish. Modifications to selections may increase the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0eb87-5be0-4447-8c02-722dc6476412",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dab5f1-134e-4371-b848-522c37aac44f",
   "metadata": {},
   "source": [
    "Import libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb17d4-0dac-4dad-ab1e-8efc5d506220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import climakitae as ck\n",
    "from climakitaegui.explore import warming_levels\n",
    "from climakitaegui.explore.warming import fit_models_and_plots\n",
    "from climakitae.explore.threshold_tools import get_exceedance_count\n",
    "from climakitae.util.utils import get_closest_gridcell, add_dummy_time_to_wl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274cd9b-6a58-4ad0-aa4e-d85b590810c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Explore and Calculate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539acd2-be4a-4b95-98ff-6cd35c75829f",
   "metadata": {},
   "source": [
    "Now, let's launch a toolkit to view localized projections under varying levels of warming. We are going to pre-select specific selections that will effectively showcase the differences between the Traditional SSP approach and the New GWL approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b9916-3812-4f82-9a4c-b8766d451a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = warming_levels()\n",
    "wl.choose_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069a8ba-9e13-4522-b745-46a3683b4c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting a specific latitude and longitude of interest:\n",
    "my_lat, my_lon = 32.89, -117.235\n",
    "\n",
    "# Specifying a range that will result in the nearest gridcell being included:\n",
    "wl.wl_params.latitude=(32.87, 32.91)\n",
    "wl.wl_params.longitude=(-117.25, -117.21)\n",
    "\n",
    "# Setting a few other parameters to extract warming levels:\n",
    "wl.wl_params.variable=\"Maximum air temperature at 2m\"\n",
    "wl.wl_params.units=\"degF\"\n",
    "wl.wl_params.timescale=\"daily\"\n",
    "wl.wl_params.resolution='3 km'\n",
    "wl.wl_params.downscaling_method=\"Statistical\"\n",
    "wl.wl_params.anom=\"No\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126830a-c919-4af0-818f-2936daff2712",
   "metadata": {},
   "source": [
    "Depending on the parameters, this calculate step <span style=\"color:red\">**can take up to ~45 min. to complete!**</span>. If you were to select the hybrid-statistically downscaled data on the highest resolution (which is what we have selected above), this will take the longest, as it will deal with the largest amount of data and number of simulations. We are currently developing data optimization techniques to speed this up, but for now, when you run this cell, feel free to leave for a bit and come back in ~45 min. to check on how it's doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92539b-4d1a-454b-bb9c-d6d003d12957",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wl.calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76e369-5af3-4933-8429-e54fd070f0f1",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Disclaimer:**</span> We recognize that some of the following analyses, conclusions, and figures are dependent on the data parameters specified above to an extent. So, you may get different results and figures based on different data parameters you select above, but you should be able to arrive at the same conclusions we arrive at at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbab622-480a-4798-bfab-f3dd5964832a",
   "metadata": {},
   "source": [
    "### (Optional): Visualize the regional response at a series of global warming levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e52d73-e43b-4648-aef5-695983433db4",
   "metadata": {},
   "source": [
    "This next visualize step is optional, in case you want to go directly to extracting the data. You can use the following drop down menu to visualize a specific global warming level reached for a scenario of interest. Scenarios shown are Shared Socioeconomic Pathways ([SSPs](https://www.sciencedirect.com/science/article/pii/S0959378016300681)): ranging from low (SSP 1-1.9) to high (SSP 5-8.5) emissions trajectories. \n",
    "\n",
    "To learn more about the data available on the Analytics Engine, [see our data catalog](https://analytics.cal-adapt.org/data/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af9117-68d1-4a07-b494-4b2370e4ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a256127-20db-401b-b645-7b670ad6aa64",
   "metadata": {},
   "source": [
    "## Step 1: Extract warming level data using the traditional SSP framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19605c7-7e83-465e-ba81-4dc211c096b3",
   "metadata": {},
   "source": [
    "Now, we will extract warming level data using the traditional SSP framework, to examine what that process would look like and what data we can generate.\n",
    "\n",
    "**For this example, we will select 30-year slices centered around 2040, or the average year that SSP 3-7.0 simulations will reaches 2ËšC** above pre-industrial levels, according to the IPCC weighted census projection.\n",
    "\n",
    "We can begin by going back to our `warming_levels()` object from the beginning, and accessing the original catalog data, via `wl.catalog_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac55d5b-e6ed-4d4e-b4c2-64d56dcdc669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing our catalog data and selecting on the SSP3-7.0 scenario\n",
    "time_horizon = wl.catalog_data.sel(scenario=\"Historical + SSP 3-7.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33578dc4-b533-4ec8-aac9-f99a6e38f663",
   "metadata": {},
   "source": [
    "We'll need to extract the gridcell of interest once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131bb93a-d6e5-4ff7-a1c9-9424ba4dd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = time_horizon.sel(lat=my_lat,lon=my_lon,method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d6251-4ff7-4c08-b563-cfe37dd49331",
   "metadata": {},
   "source": [
    "And then, we will extract the time slice for our time of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea0814-2480-4119-aadd-33a18353d652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the original time window from the beginning\n",
    "ssp_data = time_horizon.sel(time=slice(str(2040-wl.wl_params.window),str(2040+(wl.wl_params.window-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38584a-7ce5-4d91-806f-72b5483fda96",
   "metadata": {},
   "source": [
    "Now, we can load in the data and use a similar process to generate and examine the data needed for the new Global Warming Level framework as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecad0d4-820a-4a39-b172-f510871e2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into memory-- may take up to ~10 min.\n",
    "ssp_data = ck.load(ssp_data, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd326c-bb6a-4da9-a436-8aa5c57c1cf5",
   "metadata": {},
   "source": [
    "## Step 2: Extract warming level data using new GWL method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9653fb-e680-42f6-8bc6-9760405ac977",
   "metadata": {},
   "source": [
    "Let's extract warming level data using the new GWL method. **We will once again extract 30-year slices for each simulation, but now around each of the different warming levels that it reaches above pre-industrial levels.** For example, `ACCESS-CM2` has a simulation `r4i1p1f1` that will reach the following levels of warming at these estimated dates:\n",
    "\n",
    "| Warming Level | Date |\n",
    "| :-: | :-: |\n",
    "| 1.5 | 2023-09-16 |\n",
    "| 2.0 | 2034-02-15 |\n",
    "| 3.0 | 2052-02-15 |\n",
    "| 4.0 | 2066-03-16 |\n",
    "\n",
    "So, in `wl.sliced_data`, we will be able to access 30-year slices of warming for each of the warming levels that all the simulations reach (not all simulations reach all levels of warming).\n",
    "\n",
    "We'll first take a closer look at 2ËšC warming in `wl.sliced_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc2f96-e3aa-4dae-a104-7b664c7667ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_degrees = wl.sliced_data['2.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b75d28-ba53-46c9-90a7-e8ffd8e9b397",
   "metadata": {},
   "source": [
    "Let's once again limit ourselves to only the nearest gridcell to our location of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c09d59-cffa-498d-a308-8dccbe5ececf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "two_degrees = two_degrees.sel(lat=my_lat, lon=my_lon, method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab4cdf9-f2c6-4beb-a6e7-83b927587673",
   "metadata": {},
   "source": [
    "Now, let's assign `gwl_data` to `two_degrees` for usage later in our notebook. We don't need to write the warming level data into memory here because it was already read into memory in the first step of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18764d19-a713-44e2-9fa3-83c3c8d14059",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwl_data = two_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b9d7f-936c-480a-886f-536d4def1b01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Calculate Exceedences of 115ËšF using these two approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e87e53-808e-495e-aadf-2b915d931840",
   "metadata": {},
   "source": [
    "Now, we can examine how these two approaches compare when it comes to calculating the number of future days that exceed 115ËšF. Using a function from `threshold_tools`, we'll be able to count number of days exceeding 115ËšF warming grouped by year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4738667-1281-429b-9268-fbddf9221a1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Traditional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a23f4b-bb62-4bbb-a089-d412c9ce1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cd5c5-be63-49b9-9efb-948447984b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding the exceedance count for our data from the SSP approach.\n",
    "time_period_dist = get_exceedance_count(ssp_data, threshold_value)\n",
    "n_samples = len(time_period_dist.time) * len(time_period_dist.simulation)\n",
    "print('Sample size: ' + str(n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a40f2-1158-4e30-9fb1-5a5a1eb1082f",
   "metadata": {},
   "source": [
    "Note this sample size we've printed above-- this will become relevant later.\n",
    "\n",
    "Now, let's create a visualization to illustrate the number of excessive heating days by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599459cc-7990-43ae-985c-ec5197bb01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution of excessive heating by original SSP method\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(time_period_dist.values.flatten())\n",
    "plt.title('Counting Number of Excessive Heating Days by Year')\n",
    "plt.xlabel('Number of excessive heating days')\n",
    "plt.ylabel('Number of years');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95e840-c070-4af2-931c-9ec87da29f05",
   "metadata": {},
   "source": [
    "### New Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0dfcd2-40fe-4d6d-a892-696c8172cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the time index into dummy time-series for counting\n",
    "two_degs = add_dummy_time_to_wl(gwl_data)\n",
    "gwl_dist = get_exceedance_count(two_degs, threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e5392-0f27-4769-99e4-efe8e54544c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 30 * len(gwl_dist.all_sims)\n",
    "print('Sample size: ' + str(n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7ca4a-706a-4c83-8ae9-daf809fb1f44",
   "metadata": {},
   "source": [
    "Let's take a look at how this distribution breaks down as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be67eb-4ce4-491f-a7a0-345ba8560044",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(gwl_dist.values.flatten());\n",
    "plt.title('Counting Number of Excessive Heating Days by Year')\n",
    "plt.xlabel('Number of excessive heating days grouped by year')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d5a70-d8c9-4b41-ba08-952916e6d7d8",
   "metadata": {},
   "source": [
    "**One important thing to note:** Notice how in the two graphs (and in the calculated sample sizes) is that the counts of excessive heating days by year is much higher in the new framework than the original SSP framework. Why does this occur?\n",
    "\n",
    "The new GWL framework will ***include all simulations that reach a specified amount of warming regardless of when they reach that level of warming, rather than the SSP framework, which will preliminarily subset a portion of simulations that follow a given SSP trajectory.*** Because of this change, we are able to include more simulations into our calculations and projections for future climate.\n",
    "\n",
    "We will examine further on the effects of including more simulations into a given area's future climate projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a4a38-96ee-4705-9821-596d156958cf",
   "metadata": {},
   "source": [
    "To resume our comparisons, let's overlay the two distributions together to visually compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae612d1e-a411-4fce-8080-0e66f5600c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the two approaches together\n",
    "plt.figure(figsize=(6,3))\n",
    "\n",
    "counts_gwl, bins_gwl = np.histogram(gwl_dist)\n",
    "plt.hist(bins_gwl[:-1], bins_gwl, weights=counts_gwl, lw=3, fc=(1, 0, 0, 0.5), label='New GWL approach')\n",
    "\n",
    "counts_trad, bins_trad = np.histogram(time_period_dist)\n",
    "plt.hist(bins_trad[:-1], bins_trad, weights=counts_trad, lw=3, fc=(0, 0, 1, 0.5), label='Traditional approach')\n",
    "\n",
    "plt.title('Counting number of excessive heating days by year')\n",
    "plt.xlabel('Number of excessive heating days grouped by year')\n",
    "plt.ylabel('Number of years')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a17d8-c8a1-4be6-9987-88cbbdf8b4b1",
   "metadata": {},
   "source": [
    "Now, we can clearly see a difference between the two distributions, mainly based on the counts of excessive heating days by year. **But, what is the significance in having such different distributions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d4e78-6087-402c-bc68-7840c9cbae04",
   "metadata": {},
   "source": [
    "We will be able to see the shortcomings of using the traditional approach over the new GWL approach through two methods:\n",
    "1. Examining tail-end events.\n",
    "    - Viewing log-plots\n",
    "    - Comparing confidence intervals\n",
    "2. Examining the shortcomings of trying to bootstrap to mitigate lower sampling of yearly excessive heating days with the traditional approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc675a-053e-4c29-91e9-62f7ca7ba615",
   "metadata": {},
   "source": [
    "## Step 4: Examining the Significance of Differences Between Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774aada2-a799-4f16-9f0c-014bb2a2a8fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1. Examining Tail-End Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043dfd7e-04c0-4bec-ac2a-a35f82f31189",
   "metadata": {},
   "source": [
    "First, we will examine a log-plot to compare both distributions' tail-end behavior more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5302c374-5b5c-436e-8acd-874579546572",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log-scaled plot with horizontal shift (log(x+1))\n",
    "plt.figure(figsize=(6,3))\n",
    "gwl_dist_log = np.log1p(gwl_dist)\n",
    "time_period_log = np.log1p(time_period_dist)\n",
    "gwl_dist_log.plot.hist(lw=3, fc=(1, 0, 0, 0.5), label='New GWL Method', bins=np.linspace(0, gwl_dist_log.max().round().item(), 7))\n",
    "time_period_log.plot.hist(lw=3, fc=(0, 0, 1, 0.5), label='Trad. SSP Method', bins=np.linspace(0, gwl_dist_log.max().round().item(), 7))\n",
    "\n",
    "plt.title('Comparing log-scales of excessive warming days by different methods')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c585fa-f22d-4522-9972-611b95bcf8a8",
   "metadata": {},
   "source": [
    "Clearly, we can still see the differences between the log-scaled versions of these two distributions. However, if we continue further and fit `pearson3` models to both of these distributions, we'll be able to quantitative discern the differences between the distributions and their confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85371dea-c527-4ae0-bb70-58c4e0ff13e0",
   "metadata": {},
   "source": [
    "#### Fitting `pearson3` distributions to new and traditional methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc3ec6-f5d9-46ad-beb0-fc24c308b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing `pearson3` model fitting function and `threshold_tools` to use distribution on our data.\n",
    "from scipy.stats import pearson3\n",
    "from climakitae.explore import threshold_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c240b3-bfac-4dc9-90fe-b403c432fc11",
   "metadata": {},
   "source": [
    "To begin, we're going to **remove 0's from both distributions** to examine and fit extreme values more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e13c8-7c2a-401a-b8e1-11da1f52406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 0's to examine extreme values\n",
    "gwl_dist_vals = gwl_dist.to_numpy().flatten()\n",
    "gwl_dist_vals = gwl_dist_vals[gwl_dist_vals > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72148a-9f47-4d8c-b3b9-a18984bd8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period_vals = time_period_dist.to_numpy().flatten()\n",
    "time_period_vals = time_period_vals[time_period_vals > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b56fd-2a08-4724-961b-fbd00bf173f7",
   "metadata": {},
   "source": [
    "Now, we're going to fit the datasets to separate `pearson3` distributions, and overlaying the respective distributions and their datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf19b8b-b98a-469c-944d-0951a882720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params, trad_params = fit_models_and_plots(np.log1p(gwl_dist_vals), np.log1p(time_period_vals), 'pearson3');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d8ce1-b887-42f6-a7af-51ea8dcb91a8",
   "metadata": {},
   "source": [
    "We can see that there is significant overlap between the two probability distributions of Extreme Heat Days counts, but it is also clear that there is a difference between the two distributions' confidence intervals. **Because the 95% confidence interval of the Log of Extreme Heat Days is a smaller range using the New GWL method than with the Traditional SSP method, we can also derive more confidence in our ability to predict extreme heat day counts for the future.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d5919-3ac3-4752-ae31-dd8867739850",
   "metadata": {},
   "source": [
    "### 4.2. Examining Bootstrapped Approach for Traditional Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0de57e-a9b6-4d07-83e0-649b069ec87d",
   "metadata": {},
   "source": [
    "Another way of approaching the issue of having less simulations using the traditional method vs. the new method is to bootstrap from the simulations generated by the traditional method to match the number of simulations used for the new method. What we will demonstrate is that because of these **tail-end events, this method of bootstrapping will do more harm than good in predicting extreme heating events**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58797621-2cad-467a-99df-7e9d48b44a58",
   "metadata": {},
   "source": [
    "We will begin by conducting one basic bootstrap of the traditional SSP data and examining how that distributions compares with the new GWL framework distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3368f-d496-45ef-8798-e2638524a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing one bootstrapped distribution\n",
    "flat_new = gwl_dist_vals.flatten()\n",
    "r = np.random.RandomState(100)\n",
    "bootstrapped = r.choice(time_period_vals.flatten(), size=len(flat_new), replace=True)\n",
    "\n",
    "# Show percentage of sampling a distribution with excessive heating days\n",
    "heat_wave_days = 10\n",
    "bootstrap_prob = len(bootstrapped[bootstrapped > heat_wave_days]) / len(bootstrapped)\n",
    "new_prob = len(flat_new[flat_new > heat_wave_days]) / len(flat_new)\n",
    "# bootstrap_prob = np.percentile(bootstrapped, 95)\n",
    "# orig_prob = np.percentile(gwl_dist_vals.flatten(), 95)\n",
    "\n",
    "print(\"Bootstrapped probability of a future year with > 10 excessive heating days:\", bootstrap_prob)\n",
    "print(\"Warming Level probability of a future year with > 10 excessive heating days:\", new_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce1b4b-443b-41f4-a8e4-6ad536aaf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating figure to show results\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(bootstrapped, lw=3, fc=(0, 0, 1, 0.5), label='Bootstrap')\n",
    "plt.hist(gwl_dist_vals, lw=3, fc=(1, 0, 0, 0.5), label='New Method')\n",
    "plt.title('Comparing Bootstrap vs. New GWL method for Predicting heat waves')\n",
    "plt.axvline(x=10, c='black', label='10 excessive heating days')\n",
    "plt.xlim(left=8)\n",
    "plt.ylim(top=20)\n",
    "plt.xlabel('Number of Excessive Heat Days per year')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.savefig('compare_bootstrap.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685b295-2c54-410e-b815-c9a251fb9a1d",
   "metadata": {},
   "source": [
    "Now, let's run 10,000 bootstraps to examine the shortcomings of bootstrapping over a larger sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bfaa67-4add-4395-b0c7-2550adf0df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we run bootstrap n=10000 times and calculate how many sampled distributions encapsulated extreme cases of heating > a given number of days.\n",
    "\n",
    "## Include 0 counts of heating days in the bootstrap\n",
    "heat_wave_days=10\n",
    "num_bootstraps=10000\n",
    "probs = []\n",
    "for _ in range(num_bootstraps):\n",
    "    bootstrapped = np.random.choice(time_period_dist.to_numpy().flatten(), size=len(gwl_dist.to_numpy().flatten()), replace=True)\n",
    "    prob_of_heat_wave = len(bootstrapped[bootstrapped > heat_wave_days]) / len(bootstrapped)\n",
    "    probs.append(prob_of_heat_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af231ea7-dfbf-43a9-905f-46794a74905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram figure for bootstraps\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(probs, label='Bootstrap probability', bins=20)\n",
    "plt.axvline(x=new_prob, c='r', label='New GWL probability')\n",
    "plt.title('Histogram of Probabilities of Excessive Heating with {} Bootstraps'.format(num_bootstraps))\n",
    "plt.legend()\n",
    "plt.xlabel('Yearly Proportion of Excessive Heating')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('bootstrap_fig.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c363132-d336-424e-9de6-b6773e1b6da1",
   "metadata": {},
   "source": [
    "From the figure, we can clearly see that the predicting the proportion of having a year with excessive heating with the new GWL framework is significantly higher than the proportion predicted using the bootstrapped framework. To examine how unlikely it is to have a bootstrapped year with a higher proportion of yearly excessive heating than the proportion calculated using the new GWL framework, we can fit a normal distribution to the bootstrapped distribution and see the likelihood of having values above the red line visualized above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c0ad3-cb5b-4b14-b279-5db5ba362019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting data to a normal distribution and seeing the significance of the new GWL framework proportion\n",
    "from scipy.stats import norm\n",
    "\n",
    "mu, std = norm.fit(probs)\n",
    "prob_of_occur = 1 - norm.cdf(new_prob, loc=mu, scale=std)\n",
    "print(\"Probability of having a year with a proportion of excessive heating days greater than what is calculated by the new GWL framework:\", '{:.20f}'.format(prob_of_occur))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a1452-eec4-4189-8316-c4369c3c5249",
   "metadata": {},
   "source": [
    "Clearly, the probability of finding years with higher excessive heating counts will be much lower in the bootstrapped distribution than the heating probability that the new GWL framework will present.\n",
    "\n",
    "This is a result of how bootstrapping does not sample extreme events well. By including more simulations with the new GWL framework, we are able to examine more simulations that cover greater amounts of extreme events, like excessive heating, in order to more accurately predict the likelihood of extreme weather events in the future. Because bootstrapping cannot sample from a distribution is does not include, **this bootstrapped approach on the simulations used from the SSP framework will result in an underconsideration of potential excessive heating (and other extreme events) in the future.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84501b9f-69b6-48ec-9781-c0be97358b87",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e905e6-73f9-4694-85be-5b1e27b06902",
   "metadata": {},
   "source": [
    "We can see that the new method of measuring GWLs is clearly more effective due to the tail-end events of extreme events occurring, through the usage of tail-end probabilities, confidence intervals, and bootstrapped probabilities. This is mainly due to the increased number of simulations that can be included using the New GWL framework over the Traditional SSP framework. As our global climate continues to heat, the likelihood of extreme events will continue to increase. **So, with the addition of more models and their respective simulations, we are able to more confidently understand measure the likelihood and severity of extreme events that a Traditional SSP framework may miss out on.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
