{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d144d7c0-02c8-4b37-a357-a9c9f3112f08",
   "metadata": {},
   "source": [
    "# Calculating a Typical Meteorological Year -- Methodology Walkthrough\n",
    "<br>This notebook walks through the process of calculating a [Typical Meteorological Year](https://nsrdb.nrel.gov/data-sets/tmy), a specific kind of `Climate Profile` hourly dataset used for applications in energy and building systems modeling. Because this represents average rather than extreme conditions, an TMY dataset is not suited for designing systems to meet the worst-case conditions occurring at a location. \n",
    "\n",
    "The TMY methodology here mirrors that of the Sandia/NREL TMY3 methodology, and uses historic and projected downscaled climate data available through the Cal-Adapt: Analytics Engine catalog. As this methodology heavily weights the solar radiation input data, be aware that the final selection of \"typical\" months may not be typical for other variables. \n",
    "\n",
    "**Intended Application** As a user, I want to <span style=\"color:#FF0000\">**generate a typical meteorological year file**</span> for a location of interest:\n",
    "- Understand the methods that are involved in generating a TMY dataset\n",
    "- Visualize the TMY dataset across all input variables\n",
    "- Export the TMY dataset for available models for input into my workflow\n",
    "\n",
    "**Note**: \n",
    "1. This notebook is a **full demonstration** of the Typical Meteorological Year methodology, for full transparency.\n",
    "2. For practical generation of a TMY dataset, a <span style=\"color:#FF0000\">**custom Climate Profile generation notebook**</span> is forthcoming, where a user only needs to provide the **location**, and **reference time period**. Stay tuned!\n",
    "\n",
    "**Runtime**: With the default settings, this notebook takes approximately **40+ minutes** to run from start to finish. Modifications to selections may increase the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a4e19-0c14-4bb8-b410-68f93cc7a2a4",
   "metadata": {},
   "source": [
    "### Step 0: Set-up\n",
    "\n",
    "Import the [climakitae](https://github.com/cal-adapt/climakitae) library and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915116c8-7f12-473e-baa2-656349be1070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from climakitae.util.utils import (\n",
    "    convert_to_local_time,\n",
    "    get_closest_gridcell,\n",
    ")\n",
    "from climakitae.core.data_export import write_tmy_file\n",
    "from climakitae.core.data_interface import get_data\n",
    "#from climakitaegui.explore.typical_meteorological_year import plot_one_var_cdf\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "from tqdm.auto import tqdm  # Progress bar\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd29b6-4bd4-4e3e-864e-688480d8edb1",
   "metadata": {},
   "source": [
    "### Step 1: Grab and process all required input data\n",
    "\n",
    "The [TMY3 method](https://www.nrel.gov/docs/fy08osti/43156.pdf) selects a \"typical\" month based on ten daily variables: max, min, and mean air and dew point temperatures, max and mean wind speed, global irradiance and direct irradiance.  \n",
    "\n",
    "#### Step 1a: Select location of interest\n",
    "TMYs are calculated for a specific location of interest, like a building or power plant. Here, we will use a known weather station location, via their latitude and longitude to extract the data that we need to calculate the TMY. In the example below, we will look specifically at Los Angeles International Airport, but will note in the code below how you can provide your own location coordinates too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93a86a0-7a14-47c7-bf89-ee5c76a34aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>station</th>\n",
       "      <th>city</th>\n",
       "      <th>ID</th>\n",
       "      <th>LAT_Y</th>\n",
       "      <th>LON_X</th>\n",
       "      <th>station id</th>\n",
       "      <th>elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>Bakersfield Meadows Field (KBFL)</td>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>KBFL</td>\n",
       "      <td>35.43424</td>\n",
       "      <td>-119.05524</td>\n",
       "      <td>72384023155</td>\n",
       "      <td>149.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>Blythe Asos (KBLH)</td>\n",
       "      <td>Blythe</td>\n",
       "      <td>KBLH</td>\n",
       "      <td>33.61876</td>\n",
       "      <td>-114.71451</td>\n",
       "      <td>74718823158</td>\n",
       "      <td>120.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>Burbank-Glendale-Pasadena Airport (KBUR)</td>\n",
       "      <td>Burbank</td>\n",
       "      <td>KBUR</td>\n",
       "      <td>34.19966</td>\n",
       "      <td>-118.36543</td>\n",
       "      <td>72288023152</td>\n",
       "      <td>222.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>Needles Airport (KEED)</td>\n",
       "      <td>Needles</td>\n",
       "      <td>KEED</td>\n",
       "      <td>34.76783</td>\n",
       "      <td>-114.61842</td>\n",
       "      <td>72380523179</td>\n",
       "      <td>270.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>Fresno Yosemite International Airport (KFAT)</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>KFAT</td>\n",
       "      <td>36.77999</td>\n",
       "      <td>-119.72016</td>\n",
       "      <td>72389093193</td>\n",
       "      <td>101.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state                                       station         city    ID  \\\n",
       "0    CA              Bakersfield Meadows Field (KBFL)  Bakersfield  KBFL   \n",
       "1    CA                            Blythe Asos (KBLH)       Blythe  KBLH   \n",
       "2    CA      Burbank-Glendale-Pasadena Airport (KBUR)      Burbank  KBUR   \n",
       "3    CA                        Needles Airport (KEED)      Needles  KEED   \n",
       "4    CA  Fresno Yosemite International Airport (KFAT)       Fresno  KFAT   \n",
       "\n",
       "      LAT_Y      LON_X   station id  elevation  \n",
       "0  35.43424 -119.05524  72384023155      149.3  \n",
       "1  33.61876 -114.71451  74718823158      120.4  \n",
       "2  34.19966 -118.36543  72288023152      222.7  \n",
       "3  34.76783 -114.61842  72380523179      270.6  \n",
       "4  36.77999 -119.72016  72389093193      101.9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in station file of CA HadISD stations\n",
    "stn_file = pkg_resources.resource_filename(\"climakitae\", \"data/hadisd_stations.csv\")\n",
    "stn_file = pd.read_csv(stn_file, index_col=[0])\n",
    "stn_file.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff7e25d5-a9da-4605-837d-2e93b0f77c45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35.43424, -119.05524)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab airport\n",
    "stn_name = \"Bakersfield Meadows Field (KBFL)\"\n",
    "stn_code = stn_file.loc[stn_file[\"station\"] == stn_name][\"station id\"].item()\n",
    "one_station = stn_file.loc[stn_file[\"station\"] == stn_name]\n",
    "stn_lat = one_station.LAT_Y.item()\n",
    "stn_lon = one_station.LON_X.item()\n",
    "stn_state = one_station.state.item()\n",
    "stn_lat, stn_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7bfcbd-eb4d-48fe-af35-1d81e842eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72384023155\n"
     ]
    }
   ],
   "source": [
    "print(stn_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba66963-c12f-4b47-8e37-b532fe8e38a0",
   "metadata": {},
   "source": [
    "Alternatively, you may want to provide your own location instead of one of the HadISD stations above. If so, uncomment the cell below by removing the `#` symbol and modifying the lines of code. Note, with custom locations, if an elevation is not provided, a default value of 0.0 m will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7f107-2221-4e95-be18-8e2db5dc3850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## provide your own location, via latitude and longitude coordinates\n",
    "# stn_lat = YOUR_LAT_HERE\n",
    "# stn_lon = YOUR_LON_HERE\n",
    "# stn_state = 'YOUR_STATE_HERE'\n",
    "# stn_name = 'YOUR_STATION_NAME_HERE'\n",
    "# stn_code = 'custom'\n",
    "# stn_elev = YOUR_ELEV_HERE # meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201db8a-27b5-483f-ae13-2391c5842554",
   "metadata": {},
   "source": [
    "#### Step 1b: Select time frame of interest\n",
    "The second required input for generating a TMY dataset is the **time frame of interest**. The recommended minimum number of input years for a TMY dataset is 15-20 years worth of daily data; we will use 30 years to represent a standard climatological period. For data post-2014, we will utilize SSP 3-7.0, although scenario selection in the near-future is relatively independent. If calculating a TMY for the far-future, **carefully consider which scenario SSP to include**, as there will be **significant** differences present. \n",
    "\n",
    "We will also process the data for our designated station location (latitude, and longitude) at 3 km over the <span style=\"color:#FF0000\">1990-2020 period</span> as an example. **Note**: An additional year (2021) is also loaded to pad the end of the dataset after converting to local time in the next few steps -- this is done for you when subsetting for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9616dce6-47e7-4919-a1b1-62dce7dc700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected reference period\n",
    "start_year = 1990\n",
    "end_year = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15867d87-1951-4ec5-a503-35a61516810f",
   "metadata": {},
   "source": [
    "#### Step 1c: Retrieve variables in catalog\n",
    "It is important to note that not all models in the Cal-Adapt: Analytics Engine have the solar variables critical for TMY file generation - in fact, only 4 do! We will carefully subset our variables to ensure that the same 4 models are selected for consistency. \n",
    "\n",
    "Lastly, because the dynamically downscaled WRF data in the Cal-Adapt: Analytics Engine is in UTC time, we'll convert to the timezone of the station we've selected. This is particularly important for the timing of solar radiation max and min, which is a critical piece of a TMY. The handy `convert_to_local_time` function corrects for this, and ensures that all data are within the same daily timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1efd48-d816-41d3-9c11-a2ac65699373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected models\n",
    "data_models = [\n",
    "    \"WRF_EC-Earth3_r1i1p1f1\",\n",
    "    \"WRF_MPI-ESM1-2-HR_r3i1p1f1\",\n",
    "    \"WRF_TaiESM1_r1i1p1f1\",\n",
    "    \"WRF_MIROC6_r1i1p1f1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0799c331-5024-484d-beb2-cf97333aed9b",
   "metadata": {},
   "source": [
    "Now that we have set up the model list, let's start retrieving data! We will need to calculate summary statistics and reduce to daily timescales for the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c91ab-8946-4bca-a0dc-12836581b722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# air temperature\n",
    "temp_data = get_data(\n",
    "    variable=\"Air Temperature at 2m\",\n",
    "    resolution=\"3 km\",\n",
    "    timescale=\"hourly\",\n",
    "    data_type=\"Gridded\",\n",
    "    units=\"degC\",\n",
    "    latitude=(stn_lat - 0.05, stn_lat + 0.05),\n",
    "    longitude=(stn_lon - 0.06, stn_lon + 0.06),\n",
    "    area_average=\"Yes\",\n",
    "    scenario=[\"Historical Climate\", \"SSP 3-7.0\"],\n",
    "    time_slice=(start_year, end_year + 1),\n",
    ")\n",
    "\n",
    "temp_data = convert_to_local_time(\n",
    "    temp_data, stn_lon, stn_lat\n",
    ")  # convert to local timezone, provide lon/lat because area average data lacks coordinates\n",
    "temp_data = temp_data.sel({\"time\": slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\")})\n",
    "temp_data = temp_data.sel(simulation=data_models)\n",
    "\n",
    "# max air temp\n",
    "max_airtemp_data = temp_data.resample(time=\"1D\").max()  # daily max air temp\n",
    "max_airtemp_data.name = \"Daily max air temperature\"  # rename for clarity\n",
    "\n",
    "# min air temp\n",
    "min_airtemp_data = temp_data.resample(time=\"1D\").min()  # daily min air temp\n",
    "min_airtemp_data.name = \"Daily min air temperature\"  # rename for clarity\n",
    "\n",
    "# mean air temp\n",
    "mean_airtemp_data = temp_data.resample(time=\"1D\").mean()  # daily mean air temp\n",
    "mean_airtemp_data.name = \"Daily mean air temperature\"  # rename for clarity\n",
    "mean_airtemp_data = mean_airtemp_data.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fff96-9508-4435-932b-bce39a02427a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T19:09:40.599835Z",
     "iopub.status.busy": "2023-05-11T19:09:40.599455Z",
     "iopub.status.idle": "2023-05-11T19:09:44.067646Z",
     "shell.execute_reply": "2023-05-11T19:09:44.066937Z",
     "shell.execute_reply.started": "2023-05-11T19:09:40.599805Z"
    }
   },
   "source": [
    "Retrieve and calculate max and mean wind speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee63c6e-48b0-47bd-9903-2d4862c91ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wind speed\n",
    "ws_data = get_data(\n",
    "    variable=\"Wind speed at 10m\",\n",
    "    resolution=\"3 km\",\n",
    "    timescale=\"hourly\",\n",
    "    data_type=\"Gridded\",\n",
    "    units=\"m s-1\",\n",
    "    latitude=(stn_lat - 0.05, stn_lat + 0.05),\n",
    "    longitude=(stn_lon - 0.06, stn_lon + 0.06),\n",
    "    area_average=\"Yes\",\n",
    "    scenario=[\"Historical Climate\", \"SSP 3-7.0\"],\n",
    "    time_slice=(start_year, end_year + 1),\n",
    ")\n",
    "\n",
    "ws_data = convert_to_local_time(\n",
    "    ws_data, stn_lon, stn_lat\n",
    ")  # convert to local timezone, provide lon/lat because area average data lacks coordinates\n",
    "ws_data = ws_data.sel(\n",
    "    {\"time\": slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\")}\n",
    ")  # your desired time slice in local time\n",
    "ws_data = ws_data.sel(simulation=data_models)\n",
    "\n",
    "# max wind speed\n",
    "max_windspd_data = ws_data.resample(time=\"1D\").max()  # daily max wind speed\n",
    "max_windspd_data.name = \"Daily max wind speed\"  # rename for clarity\n",
    "\n",
    "# mean wind speed\n",
    "mean_windspd_data = ws_data.resample(time=\"1D\").mean()  # daily mean wind speed\n",
    "mean_windspd_data.name = \"Daily mean wind speed\"  # rename for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5768520-77e1-45b3-92f8-ab7c3a9f7932",
   "metadata": {},
   "source": [
    "Retrieve and calculate max, min, and mean dew point temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54570e-f44b-4eeb-87f9-8d1128cbb1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dew point temperature\n",
    "dewpt_data = get_data(\n",
    "    variable=\"Dew point temperature\",\n",
    "    resolution=\"3 km\",\n",
    "    timescale=\"hourly\",\n",
    "    data_type=\"Gridded\",\n",
    "    units=\"degC\",\n",
    "    latitude=(stn_lat - 0.05, stn_lat + 0.05),\n",
    "    longitude=(stn_lon - 0.06, stn_lon + 0.06),\n",
    "    area_average=\"Yes\",\n",
    "    scenario=[\"Historical Climate\", \"SSP 3-7.0\"],\n",
    "    time_slice=(start_year, end_year + 1),\n",
    ")\n",
    "\n",
    "dewpt_data = convert_to_local_time(\n",
    "    dewpt_data, stn_lon, stn_lat\n",
    ")  # convert to local timezone, provide lon/lat because area average data lacks coordinates\n",
    "dewpt_data = dewpt_data.sel({\"time\": slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\")})\n",
    "dewpt_data = dewpt_data.sel(simulation=data_models)\n",
    "\n",
    "# max dew point\n",
    "max_dewpt_data = dewpt_data.resample(time=\"1D\").max()  # daily max dewpoint temp\n",
    "max_dewpt_data.name = \"Daily max dewpoint temperature\"  # rename for clarity\n",
    "\n",
    "# min dew point\n",
    "min_dewpt_data = dewpt_data.resample(time=\"1D\").min()  # daily min dewpoint temp\n",
    "min_dewpt_data.name = \"Daily min dewpoint temperature\"  # rename for clarity\n",
    "\n",
    "# mean dew point\n",
    "mean_dewpt_data = dewpt_data.resample(time=\"1D\").mean()  # daily mean dewpoint temp\n",
    "mean_dewpt_data.name = \"Daily mean dewpoint temperature\"  # rename for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421571f-fcac-44fa-aedb-b3f8e77bfa3c",
   "metadata": {},
   "source": [
    "Next, retrieve global horizontal irradiance. GHI is within the Analytics Engine catalog at daily resolutions, but for the TMY methodology, we need to calculate the total accumulated GHI received over the course of the day, so we will retrieve hourly data instead and calculate the necessary information below. The same process is repeated for the direct normal irradiance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adc629-3205-412d-9274-2c447ce21621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global irradiance\n",
    "global_irradiance_data = get_data(\n",
    "    variable=\"Instantaneous downwelling shortwave flux at bottom\",\n",
    "    resolution=\"3 km\",\n",
    "    timescale=\"hourly\",\n",
    "    data_type=\"Gridded\",\n",
    "    latitude=(stn_lat - 0.05, stn_lat + 0.05),\n",
    "    longitude=(stn_lon - 0.06, stn_lon + 0.06),\n",
    "    area_average=\"Yes\",\n",
    "    scenario=[\"Historical Climate\", \"SSP 3-7.0\"],\n",
    "    time_slice=(start_year, end_year + 1),\n",
    ")\n",
    "\n",
    "global_irradiance_data = convert_to_local_time(\n",
    "    global_irradiance_data, stn_lon, stn_lat\n",
    ")  # convert to local timezone, provide lon/lat because area average data lacks coordinates\n",
    "global_irradiance_data = global_irradiance_data.sel(\n",
    "    {\"time\": slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\")}\n",
    ")\n",
    "global_irradiance_data = global_irradiance_data.sel(simulation=data_models)\n",
    "\n",
    "global_irradiance_data.name = \"Global horizontal irradiance\"  # rename for clarity\n",
    "# total global horizontal irradiance (accumulation of hourly data over a 24-hour period)\n",
    "total_ghi_data = global_irradiance_data.resample(time=\"1D\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fd1f3-fbee-4dd6-9ad9-61a9c925cd25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# direct normal irradiance\n",
    "direct_irradiance_data = get_data(\n",
    "    variable=\"Shortwave surface downward direct normal irradiance\",\n",
    "    resolution=\"3 km\",\n",
    "    timescale=\"hourly\",\n",
    "    data_type=\"Gridded\",\n",
    "    latitude=(stn_lat - 0.05, stn_lat + 0.05),\n",
    "    longitude=(stn_lon - 0.06, stn_lon + 0.06),\n",
    "    area_average=\"Yes\",\n",
    "    scenario=[\"Historical Climate\", \"SSP 3-7.0\"],\n",
    "    time_slice=(start_year, end_year + 1),\n",
    ")\n",
    "\n",
    "direct_irradiance_data = convert_to_local_time(\n",
    "    direct_irradiance_data, stn_lon, stn_lat\n",
    ")  # convert to local timezone, provide lon/lat because area average data lacks coordinates\n",
    "direct_irradiance_data = direct_irradiance_data.sel(\n",
    "    {\"time\": slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\")}\n",
    ")\n",
    "direct_irradiance_data = direct_irradiance_data.sel(simulation=data_models)\n",
    "\n",
    "direct_irradiance_data.name = \"Direct normal irradiance\"  # rename for clarity\n",
    "# total direct normal irradiance (accumulation of hourly data over a 24-hour period)\n",
    "total_dni_data = direct_irradiance_data.resample(time=\"1D\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2ea23-b6f9-4665-be6e-0dc5bf5da726",
   "metadata": {},
   "source": [
    "#### Step 1d: Load all variables\n",
    "Now that we have all of our data retrieved and calculated, it is time to actually load the data into memory. Previously, xarray has lazily loaded the data, but we will actually grab it now. This will take approximately **7 minutes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806e4f2-2828-4e1a-9f22-0ae1aac9dfca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_vars = xr.merge(\n",
    "    [\n",
    "        max_airtemp_data.squeeze(),\n",
    "        min_airtemp_data.squeeze(),\n",
    "        mean_airtemp_data.squeeze(),\n",
    "        max_dewpt_data.squeeze(),\n",
    "        min_dewpt_data.squeeze(),\n",
    "        mean_dewpt_data.squeeze(),\n",
    "        max_windspd_data.squeeze(),\n",
    "        mean_windspd_data.squeeze(),\n",
    "        total_ghi_data.squeeze(),\n",
    "        total_dni_data.squeeze(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f1e1f-c0da-405b-848d-8f584c3fa804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load all indices in\n",
    "all_vars = all_vars.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65ebb8-f730-4ab3-9eb4-4642624b4a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccfed5a-4a71-4ff3-be45-d20565d44cf4",
   "metadata": {},
   "source": [
    "### Step 2: Calculate cumulative distribution functions\n",
    "\n",
    "For the TMY, the cumulative distribution function gives the proportion of values that are less than or equal to a specified value of the index. In this case, we want to identify months that are as close to the long-term climatology for each variable as possible, indicating months that are \"typical\".  \n",
    "\n",
    "#### Step 2a: Calculate long-term climatology CDFs for each index\n",
    "First, we need to calculate the long-term climatology for each index for each month so we can establish the baseline pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e54317-35e5-4465-93a7-9cd4772f11a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cdf(da):\n",
    "    \"\"\"Compute the cumulative density function for an input DataArray\"\"\"\n",
    "    da_np = da.values  # Get numpy array of values\n",
    "    num_samples = 1024  # Number of samples to generate\n",
    "    count, bins_count = np.histogram(  # Create a numpy histogram of the values\n",
    "        da_np,\n",
    "        bins=np.linspace(\n",
    "            da_np.min(),  # Start at the minimum value of the array\n",
    "            da_np.max(),  # End at the maximum value of the array\n",
    "            num_samples,\n",
    "        ),\n",
    "    )\n",
    "    cdf_np = np.cumsum(count / sum(count))  # Compute the CDF\n",
    "\n",
    "    # Turn the CDF array into xarray DataArray\n",
    "    # New dimension is the bin values\n",
    "    cdf_da = xr.DataArray(\n",
    "        [bins_count[1:], cdf_np],\n",
    "        dims=[\"data\", \"bin_number\"],\n",
    "        coords={\n",
    "            \"data\": [\"bins\", \"probability\"],\n",
    "        },\n",
    "    )\n",
    "    cdf_da.name = da.name\n",
    "    return cdf_da\n",
    "\n",
    "\n",
    "def get_cdf_by_sim(da):\n",
    "    # Group the DataArray by simulation\n",
    "    return da.groupby(\"simulation\").apply(compute_cdf)\n",
    "\n",
    "\n",
    "def get_cdf_by_mon_and_sim(da):\n",
    "    # Group the DataArray by month in the year\n",
    "    return da.groupby(\"time.month\").apply(get_cdf_by_sim)\n",
    "\n",
    "\n",
    "def get_cdf(ds):\n",
    "    \"\"\"Get the cumulative density function.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    ds: xr.Dataset\n",
    "        Input data to compute CDF for\n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "    \"\"\"\n",
    "    return ds.apply(get_cdf_by_mon_and_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b852f3a-5b9e-42b8-9224-ee5c17341456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_climatology = get_cdf(all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af453d-6f91-4668-804f-7264d2929e58",
   "metadata": {},
   "source": [
    "In the plot below, we'll display maximum air temperature to assess the climatological CDF pattern, but you can modify the variable here to one of your choosing to see the pattern too! Also select a different month by moving the slider bar to see the pattern throughout the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca17cbe-1b58-4767-978c-ddf91056e45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose your desired variable\n",
    "var = \"Daily max air temperature\"\n",
    "\n",
    "# Make the plot\n",
    "cdf_plot = plot_one_var_cdf(cdf_climatology, var)\n",
    "display(cdf_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84c83b-e764-4bdd-8a6f-8ab67016ca97",
   "metadata": {},
   "source": [
    "#### Step 2b: Calculate CDFs for each index for all months\n",
    "\n",
    "Next, we will calculate CDF for each month and each variable, for which we ultimately will compare against climatology. For the individual months, we must also exclude the period of time during a major volcanic eruption (Pinatubo: June 1991 to December 1994) as the aerosols have an impact on solar variables. The cells below functions exclude this data from our data next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db16c3-26be-411a-a409-da1b6985958f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cdf_monthly(ds):\n",
    "    \"\"\"Get the cumulative density function by unique mon-yr combos\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    ds: xr.Dataset\n",
    "        Input data to compute CDF for\n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def get_cdf_mon_yr(da):\n",
    "        return da.groupby(\"time.year\").apply(get_cdf_by_mon_and_sim)\n",
    "\n",
    "    return ds.apply(get_cdf_mon_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826631ec-f25b-42dc-9928-6a0d5ed4f376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_monthly = get_cdf_monthly(all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f5728-de7b-4d21-8622-e39437b64dbd",
   "metadata": {},
   "source": [
    "Now we'll remove the volcanic years: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabb491-0c8b-48a7-b519-bf135fceaf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the years for the Pinatubo eruption\n",
    "cdf_monthly = cdf_monthly.where(\n",
    "    (~cdf_monthly.year.isin([1991, 1992, 1993, 1994])), np.nan, drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f526746-efce-48ec-ae3c-e86359097ac2",
   "metadata": {},
   "source": [
    "Like the climatology CDF figure above, let's check out the individual months next. You can modify the variable, and month-year to display too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e582a-e24f-41bc-8da7-6c8567338240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose your desired variable\n",
    "var = \"Daily max air temperature\"\n",
    "\n",
    "# Make the plot\n",
    "cdf_plot_mon_yr = plot_one_var_cdf(cdf_monthly, var)\n",
    "display(cdf_plot_mon_yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad80428-e476-408a-927a-ddb33f801c37",
   "metadata": {},
   "source": [
    "### Step 3: Compare climatology CDF to monthly CDF for each variable\n",
    "\n",
    "Now that we have the distributions for the long-term climatology of our 30-year period, and the corresponding distribution for each month in that 30-year period, we need to assess how each individual month compares to the long-term climatology. In essence, we are looking for the individual months that best capture the climatology distribution. \n",
    "\n",
    "#### Step 3a: Calculate the Finkelstein-Schafer statistic \n",
    "The [Finkelstein-Schafer statistic](https://academic.oup.com/biomet/article-abstract/58/3/641/233677) determines the absolute difference between the long-term climatology and candidate CDF profiles, and considers the number of days within each month. We will use a handy function `fs_statistic` to calculate this below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b931f7-6733-415c-8f6d-1d44a976910d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fs_statistic(cdf_climatology, cdf_month):\n",
    "    \"\"\"\n",
    "    Calculates the Finkelstein-Schafer statistic:\n",
    "    Absolute difference between long-term climatology and candidate CDF, divided by number of days in month\n",
    "    \"\"\"\n",
    "    days_per_mon = xr.DataArray(\n",
    "        data=[31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "        coords={\"month\": np.arange(1, 13)},\n",
    "    )\n",
    "    fs_stat = abs(cdf_monthly - cdf_climatology).sel(data=\"probability\") / days_per_mon\n",
    "    return fs_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab26fd-1c1c-4122-9158-4f35035dfe6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_vars_fs = fs_statistic(cdf_climatology, cdf_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85fb8c2-2e5f-48eb-bfea-9fe0d3fc37e2",
   "metadata": {},
   "source": [
    "#### Step 3b: Weight the F-S statistic\n",
    "\n",
    "Next, we weight the F-S statistic results based on the input variables. The [TMY3](https://www.nrel.gov/docs/fy08osti/43156.pdf) method places a higher weight on the solar variables (global irradiance and direct irradiance), which we follow here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e4fd1-6297-4321-9186-ae5e57e5254b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weighted_fs(da_fs):\n",
    "    \"\"\"Weights the F-S statistics based on TMY3 methodology\"\"\"\n",
    "    weights_per_var = {\n",
    "        \"Daily max air temperature\": 1 / 20,\n",
    "        \"Daily min air temperature\": 1 / 20,\n",
    "        \"Daily mean air temperature\": 2 / 20,\n",
    "        \"Daily max dewpoint temperature\": 1 / 20,\n",
    "        \"Daily min dewpoint temperature\": 1 / 20,\n",
    "        \"Daily mean dewpoint temperature\": 2 / 20,\n",
    "        \"Daily max wind speed\": 1 / 20,\n",
    "        \"Daily mean wind speed\": 1 / 20,\n",
    "        \"Global horizontal irradiance\": 5 / 20,\n",
    "        \"Direct normal irradiance\": 5 / 20,\n",
    "    }\n",
    "\n",
    "    for var, weight in weights_per_var.items():\n",
    "        # Multiply each variable by it's appropriate weight\n",
    "        da_fs[var] = da_fs[var] * weight\n",
    "    return da_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48c015-b629-4504-8913-02b8ec9544df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weighted_fs = compute_weighted_fs(all_vars_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711568f-3622-4103-89e9-a908d545a569",
   "metadata": {},
   "source": [
    "#### Step 3c: Select candidate months for consideration\n",
    "Once weighted, we select the top candidate months for each month that have lowest weighted sums, meaning that these candidate months are the closest to the long-term climatology for that month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145ea68-735c-46c7-8f5e-bc314c900248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sum\n",
    "weighted_fs_sum = (\n",
    "    weighted_fs.to_array().sum(dim=[\"variable\", \"bin_number\"]).drop([\"data\"])\n",
    ")\n",
    "\n",
    "# Pass the weighted F-S sum data for simplicity\n",
    "ds = weighted_fs_sum\n",
    "\n",
    "df_list = []\n",
    "num_values = (\n",
    "    1  # Selecting the top value for now, persistence statistics calls for top 5\n",
    ")\n",
    "for sim in ds.simulation.values:\n",
    "    for mon in ds.month.values:\n",
    "        da_i = ds.sel(month=mon, simulation=sim)\n",
    "        top_xr = da_i.sortby(da_i, ascending=True)[:num_values].expand_dims(\n",
    "            [\"month\", \"simulation\"]\n",
    "        )\n",
    "        top_df_i = top_xr.to_dataframe(name=\"top_values\")\n",
    "        df_list.append(top_df_i)\n",
    "\n",
    "# Concatenate list together for all months and simulations\n",
    "top_df = pd.concat(df_list).drop(columns=[\"top_values\"]).reset_index()\n",
    "top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddeab6-c43b-42ca-ad8e-396cb90fce49",
   "metadata": {},
   "source": [
    "The data table above represents the ideal months that represent the long term climatology based on the 10 indices for the 4 simulations in the Analytics Engine catalog. Meaning, for a \"typical\" meteorological year, WRF_EC-Earth3 data for Jan will come from Jan 2017, data for Feb will come from 2018, and so on. In the next step, we will generate the resulting \"TMY\" file that is commonly used in such applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd2214b-0368-49a6-bf71-f17916a7f860",
   "metadata": {},
   "source": [
    "### Step 4: Generate the TMY data outputs\n",
    "\n",
    "Generally, the following data is outputted using the TMY months:\n",
    "- Date & time (UTC)\n",
    "- Air temperature at 2m [°C]\n",
    "- Dew point temperature [°C]\n",
    "- Relative humidity [%]\n",
    "- Global horizontal irradiance [W/m2]\n",
    "- Direct normal irradiance [W/m2]\n",
    "- Diffuse horizontal irradiance [W/m2]\n",
    "- Downwelling infrared radiation [W/m2]\n",
    "- Wind speed at 10m [m/s]\n",
    "- Wind direction at 10m [°]\n",
    "- Surface air pressure [Pa]\n",
    "\n",
    "The following function will retrieve all of this data for the designated TMY month and concatenate it together into a pandas dataframe so that we can export it as a csv file. We'll do this next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cb538-f892-42cc-b6cf-b5cfa05c7f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_tmy_data(top_df):\n",
    "    \"\"\"Generate typical meteorological year data\n",
    "    Output will be a list of dataframes per simulation.\n",
    "    Print statements throughout the function indicate to the user the progress of the computatioconvert_to_local_time   Parameters\n",
    "    -----------\n",
    "    top_df: pd.DataFrame\n",
    "        Table with column values month, simulation, and year\n",
    "        Each month-sim-yr combo represents the top candidate that has the lowest weighted sum from the FS statistic\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    dict of str:pd.DataFrame\n",
    "        Dictionary in the format of {simulation:TMY corresponding to that simulation}\n",
    "\n",
    "    \"\"\"\n",
    "    ## ================== GET DATA FROM CATALOG ==================\n",
    "    vars_and_units = {\n",
    "        \"Air Temperature at 2m\": \"degC\",\n",
    "        \"Dew point temperature\": \"degC\",\n",
    "        \"Relative humidity\": \"[0 to 100]\",\n",
    "        \"Instantaneous downwelling shortwave flux at bottom\": \"W/m2\",\n",
    "        \"Shortwave surface downward direct normal irradiance\": \"W/m2\",\n",
    "        \"Shortwave surface downward diffuse irradiance\": \"W/m2\",\n",
    "        \"Instantaneous downwelling longwave flux at bottom\": \"W/m2\",\n",
    "        \"Wind speed at 10m\": \"m s-1\",\n",
    "        \"Wind direction at 10m\": \"degrees\",\n",
    "        \"Surface Pressure\": \"Pa\",\n",
    "    }\n",
    "\n",
    "    # Loop through each variable and grab data from catalog\n",
    "    all_vars_list = []\n",
    "    print(\"STEP 1: RETRIEVING HOURLY DATA FROM CATALOG\\n\")\n",
    "    for var, units in vars_and_units.items():\n",
    "        print(f\"Retrieving data for {var}\", end=\"... \")\n",
    "        data_by_var = get_data(\n",
    "            variable=var,\n",
    "            resolution=\"3 km\",\n",
    "            timescale=\"hourly\",\n",
    "            data_type=\"Gridded\",\n",
    "            units=units,\n",
    "            latitude=(stn_lat - 0.05, stn_lat + 0.05),\n",
    "            longitude=(stn_lon - 0.06, stn_lon + 0.06),\n",
    "            area_average=\"No\",\n",
    "            scenario=[\"Historical Climate\", \"SSP 3-7.0\"],\n",
    "            time_slice=(start_year, end_year + 1),\n",
    "        )\n",
    "        data_by_var = convert_to_local_time(data_by_var)  # convert to local timezone.\n",
    "        data_by_var = data_by_var.sel(\n",
    "            {\"time\": slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\")}\n",
    "        )  # get desired time slice in local time\n",
    "        data_by_var = get_closest_gridcell(\n",
    "            data_by_var, stn_lat, stn_lon, print_coords=False\n",
    "        )  # retrieve only closest gridcell\n",
    "        data_by_var = data_by_var.sel(\n",
    "            simulation=data_models\n",
    "        )  # Subset for only the models that have solar variables\n",
    "\n",
    "        # Drop unwanted coords\n",
    "        data_by_var = data_by_var.squeeze().drop(\n",
    "            [\"lakemask\", \"landmask\", \"x\", \"y\", \"Lambert_Conformal\"]\n",
    "        )\n",
    "\n",
    "        all_vars_list.append(data_by_var)  # Append to list\n",
    "        print(\"complete!\")\n",
    "\n",
    "    # Merge data from all variables into a single xr.Dataset object\n",
    "    all_vars_ds = xr.merge(all_vars_list)\n",
    "\n",
    "    ## ================== CONSTRUCT TMY ==================\n",
    "    print(\n",
    "        \"\\nSTEP 2: CALCULATING TYPICAL METEOROLOGICAL YEAR PER MODEL SIMULATION\\nProgress bar shows code looping through each month in the year.\\n\"\n",
    "    )\n",
    "    tmy_df_all = {}\n",
    "    for sim in all_vars_ds.simulation.values:\n",
    "        df_list = []\n",
    "        print(f\"Calculating TMY for simulation: {sim}\")\n",
    "        for mon in tqdm(np.arange(1, 13, 1)):\n",
    "            # Get year corresponding to month and simulation combo\n",
    "            year = top_df.loc[\n",
    "                (top_df[\"month\"] == mon) & (top_df[\"simulation\"] == sim)\n",
    "            ].year.item()\n",
    "\n",
    "            # Select data for unique month, year, and simulation\n",
    "            data_at_stn_mon_sim_yr = all_vars_ds.sel(\n",
    "                simulation=sim, time=f\"{mon}-{year}\"\n",
    "            ).expand_dims(\"simulation\")\n",
    "\n",
    "            # Reformat as dataframe\n",
    "            df_by_mon_sim_yr = data_at_stn_mon_sim_yr.to_dataframe()\n",
    "            df_by_mon_sim_yr = df_by_mon_sim_yr.reset_index()\n",
    "\n",
    "            # Reformat time index to remove seconds\n",
    "            df_by_mon_sim_yr[\"time\"] = pd.to_datetime(\n",
    "                df_by_mon_sim_yr[\"time\"].values\n",
    "            ).strftime(\"%Y-%m-%d %H:%M\")\n",
    "            df_list.append(df_by_mon_sim_yr)\n",
    "\n",
    "        # Concatenate all DataFrames together\n",
    "        tmy_df_by_sim = pd.concat(df_list)\n",
    "        tmy_df_all[sim] = tmy_df_by_sim\n",
    "\n",
    "    return tmy_df_all  # Return dict of TMY by simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792e895-ac9f-4bcf-8c56-9fa0c9e6597a",
   "metadata": {},
   "source": [
    "In the next cell, we will run the `generate_tmy_data` function which will retrieve, subset, and format the data for each month according to the TMY months for all requested variables. We have included print statements so you can watch the progress for each variable in each month as it builds. \n",
    "\n",
    "<span style=\"color:#FF0000\">**Note**: <span style=\"color:#000000\"> This will take time! On the Analytics Engine JupyterHub, this takes approximately 22 minutes. Progress bars will indicate the status of generating the TMY data for each simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e87db-afc8-4bb2-a653-1f735b02449b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmy_data_to_export = generate_tmy_data(top_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25572b6-2e07-442f-9ea3-90825943ad54",
   "metadata": {},
   "source": [
    "Let's observe what the TMY data looks like for one of the simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272fe2e0-7f10-4e8a-9c2e-fde2cd9f7cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulation = \"WRF_MIROC6_r1i1p1f1\"\n",
    "tmy_data_to_export[simulation].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951a416-b2bf-4924-84b2-f5fd409913bc",
   "metadata": {},
   "source": [
    "Next, we visualize the TMY data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ceebfa-a927-43e3-8bb9-28ee700d1c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmy_data_to_export[simulation].plot(\n",
    "    x=\"time\",\n",
    "    y=[\n",
    "        \"Air Temperature at 2m\",\n",
    "        \"Dew point temperature\",\n",
    "        \"Relative humidity\",\n",
    "        \"Instantaneous downwelling shortwave flux at bottom\",\n",
    "        \"Shortwave surface downward direct normal irradiance\",\n",
    "        \"Shortwave surface downward diffuse irradiance\",\n",
    "        \"Instantaneous downwelling longwave flux at bottom\",\n",
    "        \"Wind speed at 10m\",\n",
    "        \"Wind direction at 10m\",\n",
    "        \"Surface Pressure\",\n",
    "    ],\n",
    "    title=f\"Typical Meteorological Year ({simulation})\",\n",
    "    subplots=True,\n",
    "    figsize=(10, 8),\n",
    "    legend=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab490aa2-3b4e-428a-8740-1f174b7c55f5",
   "metadata": {},
   "source": [
    "Lastly, let's export the TMY data below as csv files. There will be a file per simulation downloaded. When utilizing TMY data in your own workflows, we recommend that **all simulations are considered** in your analyses, especially for future scenarios. Note, if you are working with a custom location, please also provide the optional `stn_elev` argument to `write_tmy_file`; if no elevation value is provided, an elevation value of 0.0 is set as the default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388c1c3-f141-4ff4-8155-79fc606a0854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sim, tmy in tmy_data_to_export.items():\n",
    "    filename = \"TMY_{0}_{1}\".format(\n",
    "        stn_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"), sim\n",
    "    ).lower()\n",
    "    write_tmy_file(\n",
    "        filename,\n",
    "        tmy_data_to_export[sim],\n",
    "        (start_year, end_year),\n",
    "        stn_name,\n",
    "        stn_code,\n",
    "        stn_lat,\n",
    "        stn_lon,\n",
    "        stn_state,\n",
    "        file_ext=\"epw\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climakitae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
