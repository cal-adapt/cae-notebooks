{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c64909f",
   "metadata": {},
   "source": [
    "# Accessing quality-controlled historical weather station data\n",
    "\n",
    "The <span style=\"color:#FF0000\">[Historical Observations Data Platform](https://eaglerockanalytics.com/project/historical-observations-data-platform/)</span> is a cloud-based historical weather observations database that enables access to high-quality, open climate and weather data. The Platform responds to a broad-scale need to understand weather and climate information including the severity, duration, frequency, and rate of change over time of extreme weather events, as well as supporting projections downscaling efforts. The Platform implements stringent, customized Quality Assurance / Quality Control (QA/QC) protocols in line with international conventions, with updates relevant to the energy sector to accurate capture extremes. The Platform has sourced publicly accessible weather observation stations from 27 networks throughout western North America, with a total of **14,927 quality-controlled and standardized stations** spanning 1980-2022. \n",
    "\n",
    "For more information on the QA/QC and standardization process, please check out the open-access methods and code at the <span style=\"color:#FF0000\">[Historical Observations Data Platform code repository](https://github.com/Eagle-Rock-Analytics/historical-obs-platform)</span>. A station list of all available quality-controlled and standardized stations is available in <span style=\"color:#FF0000\">[climakitae](https://github.com/cal-adapt/climakitae/blob/data/add-hdp-stnlist/climakitae/data/historical_wx_stations.csv)</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc34b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4eb1c",
   "metadata": {},
   "source": [
    "First, open the catalog using `intake`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccad77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_esm_datastore(\"https://cadcat.s3.amazonaws.com/histwxstns/era-hdp-collection.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e64b5",
   "metadata": {},
   "source": [
    "Next, view the catalog in table format. You can inspect the first few rows by calling `.head()` on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access catalog as dataframe and inspect the first few rows\n",
    "cat_df = cat.df\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57cfbd5",
   "metadata": {},
   "source": [
    "View all the weather station networks by using the following code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all network options \n",
    "cat_df[\"network_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864dd8c",
   "metadata": {},
   "source": [
    "You can also filter the catalog to see all stations within a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_network = \"ASOSAWOS\"\n",
    "cat_df[cat_df[\"network_id\"] == my_network]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfe314",
   "metadata": {},
   "source": [
    "You can subset the catalog and read in the cloud-optimized data as `xarray.Dataset` objects using the method shown below. To change the data downloaded, simply modify the inputs in the dictionary `query`. These inputs must correspond to valid options in the catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your query here \n",
    "query = {\n",
    "    \"network_id\": \"ASOSAWOS\",  # Name of the network\n",
    "    \"station_id\": [\"ASOSAWOS_72288023152\",\"ASOSAWOS_72389093193\",\"ASOSAWOS_72297603166\",\"ASOSAWOS_72493023230\"] # List of stations to get data for \n",
    "}\n",
    "\n",
    "# Subset catalog \n",
    "cat_subset = cat.search(**query)\n",
    "\n",
    "# View the data you've selected before downloading\n",
    "cat_subset.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc9a9b",
   "metadata": {},
   "source": [
    "Then, you can download all the files. The files will be downloaded as a dictionary, in which each key is a string description of the data, and the item is the data object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6eaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset dictionary \n",
    "dsets = cat_subset.to_dataset_dict(\n",
    "    xarray_open_kwargs={'consolidated':False},\n",
    "    storage_options={'anon':True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21362aa5",
   "metadata": {},
   "source": [
    "To see all the string IDs for the Datasets in the dictionary, you can print them with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dsets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72e866",
   "metadata": {},
   "source": [
    "You can easily access the files in the dictionary using the following format: \n",
    "```\n",
    "dsets[<string ID of data>]\n",
    "```\n",
    "The string ID of the data is constructed using both the network ID and the station ID for each individual weather station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a single file\n",
    "ds = dsets[\"ASOSAWOS.ASOSAWOS_72389093193\"]\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69020ce",
   "metadata": {},
   "source": [
    "## Make a quick plot of the data \n",
    "`xarray` has some nice mapping features that enable you to quickly generate a plot for a single timestep. This lets you get a sense for the data you read in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_to_plot = \"tas\"\n",
    "ds.squeeze()[variable_to_plot].plot(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb215d-ab20-4bc5-bce8-4be8fc29c1f5",
   "metadata": {},
   "source": [
    "## Subset the historical weather stations for a region\n",
    "\n",
    "If you're interested in historical weather observation stations in a specific area, you can also subset the full archive of stations to identify those that you are interested in. We will read in the Historical Data Platform station list, which provides the coordinates, dates of coverage, source network, and *total number of observations* for each station. We'll soon be adding additional information like the state and common station identifiers!\n",
    "\n",
    "For this, we'll use an area shapefile; upload your own to see which stations are in your area! You can pass either a **web link to an open access shapefile**, or **upload your own shapefile** to your Hub instance too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f678f-6b2c-4fe5-bf2d-b4c3894ade33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Historical Data Platform station list\n",
    "import geopandas as gpd\n",
    "from climakitae.util.utils import read_csv_file, clip_gpd_to_shapefile\n",
    "\n",
    "hdp_stns = read_csv_file(\"data/historical_wx_stations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0d6d0-7139-4836-94fb-80efa9efb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of Interest shapefile\n",
    "roi = gpd.read_file(\"...\") # Replace this with your own shapefile!\n",
    "\n",
    "# If there are multiple polygons within the shapefile and you want to further subset, you will need to do so.\n",
    "# Example\n",
    "# roi = roi[roi[\"NAME\"] == \"SPECIFIC_AREA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b564c79-28e1-4a2f-9d10-4e693d092de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the stationlist to subset within your area of interest\n",
    "stns_within_area = clip_gpd_to_shapefile(hdp_stns, roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c24b2-f50e-43f4-a7e5-f4615e967248",
   "metadata": {},
   "source": [
    "This subset are the stations within the designated area from your submitted shapefile! You can easily export this list now for your own information, and use it to look up specific stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4386c14-98a7-40f9-8c5c-00e0250e4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the subset portion of station list\n",
    "stns_within_area.to_csv(\"subset_station_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7664d-cc10-4762-8205-d12371e6b626",
   "metadata": {},
   "source": [
    "Want a more interactive way to zoom in on an area? use `stns.explore()`! Note, it may take some time to load. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751f5d7-79d0-406f-8967-2cedd181a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stns_within_area.explore()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
