{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0892c866-e625-4ed9-a7a3-7437b0c71372",
   "metadata": {},
   "source": [
    "# Interactive data access and visualization\n",
    "\n",
    "## Step 0: Setup\n",
    "This cell imports the python library [climakitae](https://github.com/cal-adapt/climakitae), our AE toolkit for climate data analysis, and the python library [climakitaegui](https://github.com/cal-adapt/climakitaegui), which facilitates the generation of interactive panels and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703a0d0-82dc-41d1-8482-e0c7e824f5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "import climakitaegui as ckg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc6528-c111-480b-b014-dbffb11549c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Select data\n",
    "Now we can call `Select` to display an interface from which to select the data to examine. Execute the cell, and read on for more explanation. To learn more about the data available on the Analytics Engine, [see our data catalog](https://analytics.cal-adapt.org/data/). \n",
    "\n",
    "Along with settings regarding your climate variable, data resolution, location settings, and many other options, there are several high-level options you'll need to set when selecting your data. \n",
    "\n",
    "### 1) Select your data type\n",
    "#### Gridded\n",
    "Gridded (i.e. raster) climate data at various spatial resolutions.\n",
    "#### Stations\n",
    "Gridded (i.e. raster) climate data at unique grid cell(s) corresponding to the central coordinates of the selected weather station(s). \n",
    "- This data is bias-corrected (i.e localized) to the exact location of the weather station using the historical in-situ data from the weather station(s). \n",
    "- This data is currently only available for dynamically downscaled air temperature data. \n",
    "\n",
    "### 2) Select your scientific approach \n",
    "#### Time\n",
    "Retrieve the data using a traditional time-based approach that allows you to select historical data, future projections, or both, along with a time-slice of interest. \n",
    "- “Historical Climate” includes data from 1980-2014 simulated from the same GCMs used to produce the Shared Socioeconomic Pathways (SSPs). It will be automatically appended to a SSP time series when both are selected. Because this historical data is obtained through simulations, it represents average weather during the historical period and is not meant to capture historical timeseries as they occurred.\n",
    "- “Historical Reconstruction” provides a reference downscaled [reanalysis](https://www.ecmwf.int/en/about/media-centre/focus/2020/fact-sheet-reanalysis) dataset based on atmospheric models fit to satellite and station observations, and as a result will reflect observed historical time-evolution of the weather.\n",
    "- Future projections are available for [greenhouse gas emission scenario (Shared Socioeconomic Pathway, or SSP)](https://climatescenarios.org/primer/socioeconomic-development) SSP 3-7.0 through 2100 with the dynamically-downscaled General Circulation Models (GCMs).\n",
    "     - One GCM was additionally downscaled for two additional SSPs (SSP 5-8.5 and SSP 2-4.5)\n",
    "#### Warming Level\n",
    "Retrieve the data by future global warming levels, which will automatically retrieve all available model data for the historical+future period and then calculate the time window around which each simulation reaches the selected warming level.  \n",
    "- Because warming levels are defined based on amount of global mean temperature change, they can be used to compare possible outcomes across multiple scenarios or model simulations.\n",
    "- This approach includes all simulations that reach a specified amount of warming regardless of when they reach that level of warming, rather than the time-based appraoch, which will preliminarily subset a portion of simulations that follow a given SSP trajectory.\n",
    "    \n",
    "### 3) Select your downscaling method\n",
    "#### Dynamical\n",
    "[Dynamically downscaled](https://dept.atmos.ucla.edu/alexhall/downscaling-cmip6) WRF data, produced at hourly intervals. If you select 'daily' or 'monthly' for 'Timescale', you will receive an average of the hourly data. The spatial resolution options, on the other hand, are each the output of a different simulation, nesting to higher resolution over smaller areas.\n",
    "#### Statistical \n",
    "[Hybrid-statistically downscaled](https://loca.ucsd.edu) LOCA2-Hybrid data, available at daily and monthly timescales. Multiple LOCA2-Hybrid simulations are available (100+) at a fine spatial resolution of 3km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff8052-489f-4182-8dee-c165fd1b53a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selections = ckg.Select()\n",
    "selections.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0850bb-5ae1-47da-b228-ba6651438d4e",
   "metadata": {},
   "source": [
    "Nothing is required to enter these selections, besides moving on to Step 2.\n",
    "\n",
    "However, if you want to preview what has been selected, you can type \"selections\" alone in a new cell. This stores your selections behind-the-scenes.\n",
    "\n",
    "($+$ will create a new cell, following the currently selected) \n",
    "\n",
    "## Step 2: Retrieve data\n",
    "Call selections.retrieve(), to assign the subset/combo of data specified to a variable name of your choosing, in [xarray DataArray or Dataset](https://docs.xarray.dev/en/stable/user-guide/data-structures.html) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b6aec-9694-4ebd-a79b-7ffd439392b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_to_use = selections.retrieve()\n",
    "data_to_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021719d-ddc9-43bb-a4ee-ce5de5c1299c",
   "metadata": {},
   "source": [
    "You can preview the data in the retrieved, aggregated dataset when this is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ab298-4e2f-4a82-b225-afe618d54c35",
   "metadata": {},
   "source": [
    "Next, load the data into memory. This step may take a few minutes to compute, because the data is only loaded \"lazily\" until you output it (in visualize or export). This allows the previous steps to run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d12dc6-ad79-4b7d-837f-7d8fbe7128b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_to_use = ck.load(data_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0b7e0-6f30-4cf6-a1cd-9346c5b8df7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Visualize data\n",
    "Preview the data before doing further calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b186c-f71e-4aa1-be3e-b164b995338e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckg.view(data_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5dff22-886b-4502-b2e8-e7de9326d9ca",
   "metadata": {},
   "source": [
    "The data previewer is also customizable: Check out an example where the display colors and coordinates are modified in gridded data. If you selected station data above, uncomment the second line in the cell below and comment out the first by using the `#` character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01518678-0008-4313-8bfc-73ed547e89ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckg.view(data_to_use, lat_lon = False, cmap = 'viridis') # grided data (with x-y coordinates)\n",
    "# ckg.view(data_to_use, lat_lon = False, cmap = 'green') # station, or area-averaged data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971a5c0-d9b5-45f0-9b5a-9ee6eab91a5b",
   "metadata": {},
   "source": [
    "More plotting helper-functions will be forthcoming.\n",
    "\n",
    "See other notebooks for example analyses, or add your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25295014-dd9d-4dab-9ca4-3af7f13b80e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [insert your own code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38447d6-f0ae-46f2-aaf4-a322f250008e",
   "metadata": {},
   "source": [
    "You can load up another variable or resolution by modifying your selections and calling: next_data = selections.retrieve()\n",
    "\n",
    "If you do this a lot, and things are starting to get slow, you might want to try: data_to_use.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9688a2a-e72b-4239-b8fb-56ae8080bdc5",
   "metadata": {},
   "source": [
    "## Step 4: Export data\n",
    "\n",
    "To save data as a file, call `export` and input your desired\n",
    "1) data to export – an [xarray DataArray or Dataset](https://docs.xarray.dev/en/stable/user-guide/data-structures.html), as output by e.g. selections.retrieve()\n",
    "2) output file name (without file extension)\n",
    "3) file format (\"NetCDF\", \"Zarr\", or \"CSV\")\n",
    "\n",
    "We recommend NetCDF or Zarr, which suits data and outputs from the Analytics Engine well – they efficiently store large data containing multiple variables and dimensions. Metadata will be retained in these files.\n",
    "\n",
    "NetCDF or Zarr can be export locally (such as onto the JupyterHUB user partition). Optionally Zarr can be exported to an AWS S3 scratch bucket for storing very large exports.\n",
    "\n",
    "CSV can also store Analytics Engine data with any number of variables and dimensions. It works the best for smaller data with fewer dimensions. The output file will be compressed to ensure efficient storage. Metadata will be preserved in a separate file.\n",
    "\n",
    "CSV stores data in tabular format. Rows will be indexed by the index coordinate(s) of the DataArray or Dataset (e.g. scenario, simulation, time). Columns will be formed by the data variable(s) and non-index coordinate(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0110114-e2ec-45a4-8357-f486ff4b225e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ck.export(data_to_use, filename=\"my_filename1\", format=\"NetCDF\") # NetCDF4 export locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck.export(data_to_use, filename=\"my_filename2\", format=\"Zarr\") # Zarr export locally\n",
    "#ck.remove_zarr(\"my_filename2\") # helper function to delete Zarr directory tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck.export(data_to_use, filename=\"my_filename3\", format=\"Zarr\", mode=\"s3\") # Zarr export to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da81ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck.export(data_to_use, filename=\"my_filename4\", format=\"CSV\") # CSV export locally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
