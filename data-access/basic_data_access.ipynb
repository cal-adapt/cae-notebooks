{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811929f5-5aaf-4c4c-af1c-0c63bd51961e",
   "metadata": {},
   "source": [
    "# Basic data access \n",
    "This notebook showcases helper functions from `climakitae` that enable you to access and export the AE catalog data, while also allowing you to perform spatial subsetting and view the data options in an easy-to-use fashion. These functions could be easily implemented in a python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climakitae as ck \n",
    "from climakitae.new_core.user_interface import ClimateData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588887a8",
   "metadata": {},
   "source": [
    "## High-level details \n",
    "The AE data catalog has many different types of data. Our helper library `climakitae` attempts to make accessing and retrieveing this data intuitive, as well as simplify climate and statistical analysis with the data down the line, by performing some data transformations as the data is retrieved.<br><br> To retrieve the data, you'll need to make some selections as to your climate variable, data resolution, location settings, and many other options. There are also several high-level options you'll need to set when selecting your data, detailed below: \n",
    "\n",
    "### Data type: Gridded or Stations\n",
    "**Gridded**: Gridded (i.e. raster) climate data at various spatial resolutions.<br><br>\n",
    "**Stations**: Gridded (i.e. raster) climate data at unique grid cell(s) corresponding to the central coordinates of the selected weather station(s). \n",
    "- This data is bias-corrected (i.e localized) to the exact location of the weather station using the historical in-situ data from the weather station(s). \n",
    "- This data is currently only available for dynamically downscaled air temperature data. \n",
    "\n",
    "### Scientific approach: Time or Warming Level\n",
    "**Time**: Retrieve the data using a traditional time-based approach that allows you to select historical data, future projections, or both, along with a time-slice of interest. \n",
    "- “Historical Climate” includes data from 1980-2014 simulated from the same GCMs used to produce the Shared Socioeconomic Pathways (SSPs). It will be automatically appended to a SSP time series when both are selected. Because this historical data is obtained through simulations, it represents average weather during the historical period and is not meant to capture historical timeseries as they occurred.\n",
    "- “Historical Reconstruction” provides a reference downscaled [reanalysis](https://www.ecmwf.int/en/about/media-centre/focus/2020/fact-sheet-reanalysis) dataset based on atmospheric models fit to satellite and station observations, and as a result will reflect observed historical time-evolution of the weather.\n",
    "- Future projections are available for [greenhouse gas emission scenario (Shared Socioeconomic Pathway, or SSP)](https://climatescenarios.org/primer/socioeconomic-development) SSP 3-7.0 through 2100 with the dynamically-downscaled General Circulation Models (GCMs).\n",
    "     - One GCM was additionally downscaled for two additional SSPs (SSP 5-8.5 and SSP 2-4.5)<br>\n",
    "\n",
    "**Warming Level**: Retrieve the data by future global warming levels, which will automatically retrieve all available model data for the historical+future period and then calculate the time window around which each simulation reaches the selected warming level.  \n",
    "- Because warming levels are defined based on amount of global mean temperature change, they can be used to compare possible outcomes across multiple scenarios or model simulations.\n",
    "- This approach includes all simulations that reach a specified amount of warming regardless of when they reach that level of warming, rather than the time-based appraoch, which will preliminarily subset a portion of simulations that follow a given SSP trajectory.\n",
    "    \n",
    "### Downscaling method: Dynamical, Statistical, or both\n",
    "**Dynamical**: [Dynamically downscaled](https://dept.atmos.ucla.edu/alexhall/downscaling-cmip6) WRF data, produced at hourly intervals. If you select 'daily' or 'monthly' for 'Timescale', you will receive an average of the hourly data. The spatial resolution options, on the other hand, are each the output of a different simulation, nesting to higher resolution over smaller areas.<br><br>\n",
    "**Statistical**: [Hybrid-statistically downscaled](https://loca.ucsd.edu) LOCA2-Hybrid data, available at daily and monthly timescales. Multiple LOCA2-Hybrid simulations are available (100+) at a fine spatial resolution of 3km."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750153d-4aec-4011-8345-9ceb5d9e2fa8",
   "metadata": {},
   "source": [
    "## See the options in our data catalog\n",
    "The interface provides several methods to explore available data options. You can get a comprehensive overview or explore step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4da135-f64c-415e-a03b-0863cd67bd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the interface\n",
    "cd = ClimateData()\n",
    "\n",
    "# Get a comprehensive overview of all available options\n",
    "cd.show_all_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed137e-c478-4401-beeb-8bfd5d12f45f",
   "metadata": {},
   "source": [
    "## See the data options for a particular subset of inputs\n",
    "You can explore options step by step, building your query as you learn about available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c193f9f-c154-413f-92dc-084d2ea05ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore options step by step\n",
    "print(\"=== Available Catalogs ===\")\n",
    "cd.show_catalog_options()\n",
    "\n",
    "print(\"\\n=== Choose 'renewable energy generation' catalog and explore installations ===\")\n",
    "renewables_explorer = cd.catalog(\"renewable energy generation\")\n",
    "renewables_explorer.show_installation_options()\n",
    "\n",
    "print(\"\\n=== Choose 'pv_utility' installation and explore variables ===\")\n",
    "pv_explorer = renewables_explorer.installation(\"pv_utility\")\n",
    "pv_explorer.show_variable_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1e03c-a414-4b5b-94d3-1ec2b01573a1",
   "metadata": {},
   "source": [
    "You can also explore the climate data catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf820b0-9940-4ec9-b8d4-ad9e8cd4cb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=== Climate Data Catalog ===\")\n",
    "cd = ClimateData()\n",
    "data_explorer = cd.catalog(\"cadcat\")\n",
    "\n",
    "print(\"\\n=== WRF (Dynamical Downscaling) Variables ===\")\n",
    "wrf_explorer = data_explorer.activity_id(\"WRF\")\n",
    "wrf_explorer.show_variable_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cad5-89cd-4ec2-8b76-fca3f764e247",
   "metadata": {},
   "source": [
    "At any point in building your query, you can check what parameters you've set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae3993-ead4-49d8-87ad-066ec5c3181f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a partial query and check its state\n",
    "cd = ClimateData()\n",
    "partial_query = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .experiment_id(\"historical\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    ")\n",
    "\n",
    "# Check what we've built so far\n",
    "partial_query.show_query()\n",
    "\n",
    "# See what variable options are still available\n",
    "print(\"\\nAvailable variables for this query:\")\n",
    "partial_query.show_variable_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8260ed-adff-4c49-86ff-69ec207da04d",
   "metadata": {},
   "source": [
    "You can reset the interface to start a new query at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66582be5-eb9a-42b8-ae08-e96ffa671195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "print(\"Interface reset - ready for new query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501a518",
   "metadata": {},
   "source": [
    "## Retrieve data \n",
    "The ClimateData interface allows you to chain method calls to build readable queries, and then retrieve the data easily in your query. \n",
    "<br><br>\n",
    "Required components of the query depend on the data catalog you're interested in. In general, the required components for all catalogs are: \n",
    "- catalog \n",
    "- variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb1909",
   "metadata": {},
   "source": [
    "### Example 1: Future air temperature data \n",
    "You can retrieve data using a dictionary query, or by chaining operations to the ClimateData object. Either is valid and will result in the same output data, so just use whichever method is most intuitive to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd644bb",
   "metadata": {},
   "source": [
    "#### Method 1: Dictionary query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query \n",
    "climate_query_dict = {\n",
    "    \"catalog\": \"cadcat\", # Catalog name \n",
    "    \"activity_id\": \"WRF\", # Downscaling method \n",
    "    \"experiment_id\": \"ssp370\", # Simulation\n",
    "    \"table_id\": \"mon\", # Temporal resolution \n",
    "    \"grid_label\": \"d02\", # Grid resolution\n",
    "    \"variable_id\": \"t2\" # Variable name \n",
    "}\n",
    "\n",
    "# Load the query \n",
    "climate_query = ClimateData().load_query(climate_query_dict)\n",
    "\n",
    "# Retrieve the data\n",
    "climate_data = climate_query.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d827595",
   "metadata": {},
   "source": [
    "### Method 2: Chained operations\n",
    "\n",
    "This will return the same data as above, but by chaining operations instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "climate_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .experiment_id(\"ssp370\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d02\")\n",
    "    .variable(\"t2\")\n",
    ").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be7d28",
   "metadata": {},
   "source": [
    "### Example 2: Renewable energy model data \n",
    "Note that the renewables catalog has an additional query option: `installation`. This indicates the energy generation method, a parameter that is only applicable for this particular catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8436c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query \n",
    "renewables_query_dict = {\n",
    "    \"catalog\": \"renewable energy generation\", # Catalog name \n",
    "    \"experiment_id\": \"historical\", # Model name \n",
    "    \"table_id\": \"day\", # Temporal resolution \n",
    "    \"grid_label\": \"d03\", # Grid resolution\n",
    "    \"variable_id\": \"cf\", # Variable name \n",
    "    \"installation\": \"pv_utility\", # Renewables catalog only! \n",
    "    # \"source_id\": \"MPI-ESM1-2-HR\" # Optional: pick a simulation within the model \n",
    "}\n",
    "\n",
    "# Load the query \n",
    "renewables_query = ClimateData().load_query(renewables_query_dict)\n",
    "\n",
    "# Retrieve the data\n",
    "renewables_data = renewables_query.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0937d9",
   "metadata": {},
   "source": [
    "## Working with Processors\n",
    "You can further customize your data retrieval using `processors`, which perform operations on the data before it is returned to you. For example, two available processors are: \n",
    "\n",
    "- **`concat`** - Concatenate datasets along specified dimensions, default behavior is to concatenate on \"time\" using a historical+ssp approach.\n",
    "- **`filter_unbiased_models`** - Remove or include unbiased models (default: \"yes\" to remove)\n",
    "\n",
    "These two processors are run by default every time that you retrieve data. Examples of other available processors can be found in the `climakitae` library documentation, or in other example notebooks. <br><br>\n",
    "It's important to note that processors are applied as a **dictionary**. This enables you to add more than one processor to your chain of operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ace5a",
   "metadata": {},
   "source": [
    "### Example 3: Concatenation along a specified dimension\n",
    "By default, when historical data is retrieved in the same operation as future data, the historical data will be appended to the future data, giving a single timeseries. However, you can change this default behavior by setting the query to concatenate along the simulation \"`sim`\" dimension instead. This will return the historical and future data as separate simulations. Concatenating by `time` or by `sim` have unique benefits, and you'll need to decide which method is most appropriate for your analyses. \n",
    "\n",
    "In the returned data from the code below, future time periods for the historical simulation will be infilled with `NaN`, because the model has no data for that time period by definition. The same logic applies to the future simulations: any time in the past will be infilled with `NaN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_by_sim = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .experiment_id([\"historical\", \"ssp370\"]) # Retrieve historical and future data \n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    "    .variable(\"prec\") # Precipitation \n",
    "    .processes({\n",
    "        \"concat\": \"sim\"  # Concatenate along simulation dimension\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b20f1",
   "metadata": {},
   "source": [
    "## Exporting data  \n",
    "To save data as a file, call export and input your desired: \n",
    "1. data to export – an [xarray DataArray or Dataset](https://docs.xarray.dev/en/stable/user-guide/data-structures.html) (this is the default data type returned by `ClimateData.get()`)\n",
    "2. output file name (without file extension)\n",
    "3. file format (\"NetCDF\", \"Zarr\", or \"CSV\")\n",
    "\n",
    "We recommend NetCDF or Zarr, which suits data and outputs from the Analytics Engine well – they efficiently store large data containing multiple variables and dimensions. Metadata will be retained in these files.\n",
    "\n",
    "NetCDF or Zarr can be export locally (such as onto the JupyterHUB user partition). Optionally Zarr can be exported to an AWS S3 scratch bucket for storing very large exports.\n",
    "\n",
    "CSV can also store Analytics Engine data with any number of variables and dimensions. It works the best for smaller data with fewer dimensions. The output file will be compressed to ensure efficient storage. Metadata will be preserved in a separate file.\n",
    "\n",
    "CSV stores data in tabular format. Rows will be indexed by the index coordinate(s) of the DataArray or Dataset (e.g. scenario, simulation, time). Columns will be formed by the data variable(s) and non-index coordinate(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a subset of the data from example 3 \n",
    "data_to_export = concat_by_sim.sel(time=slice(\"2023\", \"2025\")) # Just grab a few years of data (2023-2025)\n",
    "ck.export(data_to_export, filename=\"my_filename1\", format=\"NetCDF\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climakitae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
