{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811929f5-5aaf-4c4c-af1c-0c63bd51961e",
   "metadata": {},
   "source": [
    "# Data Access Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abd63d-4e03-4634-a6a2-1fca9c967792",
   "metadata": {},
   "source": [
    "In this notebook, we’ll be walking through how to retrieve climate data from `climakitae` through a series of real-world analyses. These include visualizing time-series temperature data, retrieving warming-level data, and calculating 1-in-X metrics—all designed to help you get familiar with how `climakitae` works in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7abf7-66ba-44e6-afdc-6884fc1380ff",
   "metadata": {},
   "source": [
    "**Intended Application:** As a user, I want to **<span style=\"color:red\">understand how I can use `climakitae` for my own climate analyses.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f9736-8fef-40e5-8263-7968e5a43682",
   "metadata": {},
   "source": [
    "**Runtime**: ~20 min. to run through the whole notebook. Modifications to different queries may increase/decrease the overall runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import climakitae as ck "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588887a8",
   "metadata": {},
   "source": [
    "# High-level details \n",
    "The AE data catalog includes a wide range of climate datasets. Our helper library, `climakitae`, is designed to make accessing and retrieving this data intuitive, while also simplifying downstream climate and statistical analyses by applying key data transformations during retrieval. To get started, you'll need to make some selections to your climate variable, data resolution, location settings, and several other options.<br>\n",
    "\n",
    "**<span style=\"color:darkblue\">`ClimateData` is the main object we'll be using to interface with `climakitae`, consolidating ALL data access and processing functionality into one single entry point. We'll be using this class extensively throughout this notebook.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36490d-c19b-4b81-8447-8dd38b8c3ab9",
   "metadata": {},
   "source": [
    "# Data Selection Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750153d-4aec-4011-8345-9ceb5d9e2fa8",
   "metadata": {},
   "source": [
    "There are several methods to explore all the available data options in `climakitae`. You can get a comprehensive overview or explore step by step. The example below will show how you can instantiate the object and list how much verbosity of output you'd like from the `ClimateData` in `climakitae`.\n",
    "\n",
    "### Verbosity\n",
    "You can also choose the level of output `ClimateData` will provide for you. <br>\n",
    "`-2` : errors only  \n",
    "`-1` : warnings and errors  \n",
    "`0`  : info, warnings, and errors (default)  \n",
    "`1`  : debug, info, warnings, and errors (developers or debugging only, not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4da135-f64c-415e-a03b-0863cd67bd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the interface\n",
    "cd = ck.ClimateData(verbosity=-1) # only give warnings and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0cd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a comprehensive overview of all available options\n",
    "cd.show_all_options()\n",
    "\n",
    "# Or you can see specific categories by uncommenting any of the lines below:\n",
    "# cd.show_catalog_options()\n",
    "# cd.show_activity_id_options()\n",
    "# cd.show_institution_id_options()\n",
    "# cd.show_source_id_options()\n",
    "# cd.show_experiment_id_options()\n",
    "# cd.show_table_id_options()\n",
    "# cd.show_grid_label_options()\n",
    "# cd.show_variable_options()\n",
    "# cd.show_installation_options()\n",
    "# cd.show_processors()\n",
    "# cd.show_boundary_options()\n",
    "# cd.show_station_options()\n",
    "\n",
    "### This will be explored in more detail in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed137e-c478-4401-beeb-8bfd5d12f45f",
   "metadata": {},
   "source": [
    "## Data Selection Options for a particular set of inputs\n",
    "You can explore options step by step, building your query as you learn about available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c193f9f-c154-413f-92dc-084d2ea05ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore options step by step\n",
    "print(\"=== Available Catalogs ===\")\n",
    "cd.reset()\n",
    "cd.show_catalog_options()\n",
    "\n",
    "print(\"\\n=== Choose 'renewable energy generation' catalog and explore installations ===\")\n",
    "renewables_explorer = cd.catalog(\"renewable energy generation\")\n",
    "renewables_explorer.show_installation_options()\n",
    "\n",
    "print(\"\\n=== Choose 'pv_utility' installation and explore variables ===\")\n",
    "pv_explorer = renewables_explorer.installation(\"pv_utility\")\n",
    "pv_explorer.show_variable_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1e03c-a414-4b5b-94d3-1ec2b01573a1",
   "metadata": {},
   "source": [
    "You can also explore the climate data catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf820b0-9940-4ec9-b8d4-ad9e8cd4cb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=== Climate Data Catalog ===\")\n",
    "cd.reset()\n",
    "data_explorer = cd.catalog(\"cadcat\")\n",
    "\n",
    "print(\"\\n=== WRF (Dynamical Downscaling) Variables ===\")\n",
    "wrf_explorer = data_explorer.activity_id(\"WRF\")\n",
    "wrf_explorer.show_variable_options(show_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cad5-89cd-4ec2-8b76-fca3f764e247",
   "metadata": {},
   "source": [
    "At any point in building your query, you can check what parameters you've set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae3993-ead4-49d8-87ad-066ec5c3181f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a partial query and check its state\n",
    "partial_query = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .experiment_id(\"historical\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    ")\n",
    "\n",
    "# Check what we've built so far\n",
    "partial_query.show_query()\n",
    "\n",
    "# # See what variable options are still available\n",
    "print(\"\\nAvailable variables for this query:\")\n",
    "partial_query.show_variable_options(show_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea85cc-d0dd-4688-8b8b-7d3e02a6ff03",
   "metadata": {},
   "source": [
    "You can additionally make queries as chained commands (our recommended approach) or as dictionaries, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e1efe9-553f-4ac8-8bfe-749923318492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOMMENDED: Chained command example (we'll go through what the parameters mean further down in the notebook).\n",
    "cd.reset()\n",
    "climate_data = (cd\n",
    "    .catalog(\"cadcat\")       # Catalog name\n",
    "    .activity_id(\"WRF\")      # Downscaling method\n",
    "    .experiment_id(\"ssp370\") # SSP scenario\n",
    "    .institution_id(\"UCLA\")  # Institution name\n",
    "    .table_id(\"mon\")         # Data frequency\n",
    "    .grid_label(\"d02\")       # Grid resolution\n",
    "    .variable(\"t2\")          # Variable name\n",
    ").get()\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ffa5da-3943-4d0e-9e59-aae696fb14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary approach\n",
    "climate_query_dict = {\n",
    "    \"catalog\": \"cadcat\",\n",
    "    \"activity_id\": \"WRF\",\n",
    "    \"institution_id\": \"UCLA\",\n",
    "    \"experiment_id\": \"ssp370\",\n",
    "    \"table_id\": \"mon\", \n",
    "    \"grid_label\": \"d02\", \n",
    "    \"variable_id\": \"t2\" \n",
    "}\n",
    "\n",
    "# Load the query \n",
    "climate_query = ck.ClimateData(verbosity=-2).load_query(climate_query_dict)\n",
    "\n",
    "# Retrieve the data\n",
    "climate_data = climate_query.get()\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8260ed-adff-4c49-86ff-69ec207da04d",
   "metadata": {},
   "source": [
    "You can reset the interface to start a new query at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66582be5-eb9a-42b8-ae08-e96ffa671195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "print(\"Interface reset - ready for new query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89e35d-82d2-41f5-93f2-d63ea622e1ac",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc956b-6f80-450d-9af3-b9856eaeff4e",
   "metadata": {},
   "source": [
    "<h2 style=\"margin-bottom: 0;\">Exploring <code style=\"font-size:0.9em;\">cadcat</code> data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6237e62-c806-4f43-a649-855ca5784903",
   "metadata": {},
   "source": [
    "In the rest of this notebook, we’ll focus specifically on data available in the `cadcat` catalog, as more of `climakitae`'s functionality has been built to support this specific catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7f062-ba0b-4db8-9a96-96d30aeb5882",
   "metadata": {},
   "source": [
    "### Downscaling method: Dynamical or Statistical\n",
    "**Dynamical**: <a href=\"https://dept.atmos.ucla.edu/alexhall/downscaling-cmip6\" target=\"_blank\">Dynamically-downscaled</a> WRF data, produced at hourly intervals. If you select `daily` or `monthly` for `Timescale`, you will receive an average of the hourly data. The spatial resolution options, on the other hand, are each the output of a different simulation, nesting to higher resolution over smaller areas. \n",
    "- **WRF data uses the `UCLA` `institution_id`, which is what you'll see more of in the examples below.**<br>\n",
    "\n",
    "**Statistical**: <a href=\"https://loca.ucsd.edu\" target=\"_blank\">Hybrid-statistically downscaled</a> LOCA2-Hybrid data, available at daily and monthly timescales. Multiple LOCA2-Hybrid simulations are available (100+) at a fine spatial resolution of 3km.\n",
    "- **LOCA2 data uses the `UCSD` `institution_id`.**<br>\n",
    "\n",
    "\n",
    "### Scientific approach: Time or Warming Level\n",
    "You'll need to consider the approach you'll want to take when retrieving your data.<br>\n",
    "\n",
    "**Time**: We can retrieve the data using a traditional time-based approach that allows you to select historical data, future projections, or both, along with a time-slice of interest. \n",
    "- **Historical Climate** includes data from 1980-2014 simulated from the same GCMs used to produce the Shared Socioeconomic Pathways (SSPs). It will be automatically appended to a SSP time series when both are selected. Because this historical data is obtained through simulations, it represents average weather during the historical period and is not meant to capture historical timeseries as they occurred.\n",
    "- **Historical Reconstruction** provides a reference downscaled <a href=\"https://www.ecmwf.int/en/about/media-centre/focus/2020/fact-sheet-reanalysis\" target=\"_blank\">reanalysis</a> dataset based on atmospheric models fit to satellite and station observations, and as a result will reflect observed historical time-evolution of the weather.\n",
    "- Future projections are available for <a href=\"https://climatescenarios.org/primer/socioeconomic-development\" target=\"_blank\">greenhouse gas emission scenario (Shared Socioeconomic Pathway, or SSP)</a> SSP 2-4.5, SSP 3-7.0, and SSP 5-8.5 through 2100.\n",
    "\n",
    "**Warming Level**: Retrieve data based on future global warming levels. This method automatically gathers all available model data across the combined historical and future periods, then determines the time window during which each simulation reaches the selected warming level. \n",
    "- Because warming levels are defined by changes in global mean temperature, they allow for comparisons of potential outcomes across different scenarios and model simulations.\n",
    "- Unlike a time-based approach, which limits analysis to simulations following a specific SSP trajectory, this method includes all simulations that reach the specified amount of warming, regardless of when that warming occurs.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b6f58-e58a-4498-b3ae-604205547d28",
   "metadata": {},
   "source": [
    "You can read more about the different parameters available in a typical `ClimateData.get()` call below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615da20-081a-4901-9615-0461f15e7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "climate_data = (cd\n",
    "    .catalog(\"cadcat\")       # Catalog name, using `cadcat` from here on out for the notebook\n",
    "    .activity_id(\"WRF\")      # Downscaling method (WRF or LOCA)\n",
    "    .experiment_id(\"ssp370\") # SSP scenario (only used for time-based data)\n",
    "    .institution_id(\"UCLA\")  # Institution name (WRF -> UCLA, LOCA2 -> UCSD)\n",
    "    .table_id(\"mon\")         # Data frequency (`1hr` only available for WRF, `day` and `mon` available for both WRF and LOCA2\n",
    "    .grid_label(\"d02\")       # Grid resolution (d01=45km, d02=9km, d03=3km)\n",
    "    .variable(\"t2\")          # Variable name (t2 = Air Temperature at 2m)\n",
    ").get()\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072c6c8-bd43-441b-b630-e171f883972c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0937d9",
   "metadata": {},
   "source": [
    "# Working with Processors\n",
    "You can further customize your data retrieval using `processors`, which perform operations on the data before it is returned to you. The available processors are: \n",
    "\n",
    "- **`concat`** - Concatenate datasets along specified dimensions, default behavior is to concatenate on \"time\" by combining historical and SSP datasets.\n",
    "- **`filter_unadjusted_models`** - Remove or include unadjusted models (default: \"yes\" to remove).\n",
    "- **`update_attributes`** - Updates the attributes of your dataset based on the processors applied.\n",
    "- `time_slice` - Applies a time slice to the requested dataset.\n",
    "- `warming_level` - Applies a global warming level approach (as separate from the default time based approach). Please see our <a href=\"https://analytics.cal-adapt.org/guidance/using_in_decision_making/#how-should-a-user-choose-between-global-warming-levels-and-a-time-based-approach-to-planning?\" target=\"_blank\">guidance</a> on the use of global warming levels.\n",
    "- `clip` - Applies a spatial clipping to the requested dataset. Many types of spatial clipping are supported including point based, bounding box, user provided shape files, and built-in boundaries including states, CA counties, CA watersheds, CA electric and utilities areas, CA demand forecast zones, CA electric balancing authority areas, and CA census tracts.\n",
    "- `convert_units` - converts the units of your dataset.\n",
    "- `metric_calc` - applies metric calculations to your dataset such as min, max, mean, median, percentiles, and 1-in-X calculations. \n",
    "- `bias_adjust_model_to_station` - For working with gridded data bias adjusted to historical HADISD weather station data.\n",
    "- `export` - Exports your requested dataset to a range of file formats.\n",
    "\n",
    "The first three processors (bolded) are run by default every time that you retrieve data. Examples of other available processors can be found in the `climakitae` library documentation, or in other example notebooks. <br><br>\n",
    "It's important to note that processors are applied as a **dictionary**. This enables you to add more than one processor to your chain of operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96754193-6c30-4ece-b712-f3082b97cdd9",
   "metadata": {},
   "source": [
    "## Processor Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5c026-c842-4fa4-ab92-6d72069d10be",
   "metadata": {},
   "source": [
    "To bring cohesion between the processor examples we'll be looking at below, we'll be building towards a complete, realistic analysis using WRF data. Any dataset works, but for demonstration purposes it is useful to see how the puzzle pieces fit together using a consistent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ace5a",
   "metadata": {},
   "source": [
    "### Processor Example 1: Concatenation along a specified dimension\n",
    "By default, when historical data is retrieved in the same operation as future data, the historical data will be appended to the future data, giving a single timeseries. However, you can change this default behavior by setting the query to concatenate along the simulation `sim` dimension instead. This will return the historical and future data as separate simulations. Concatenating by `time` or by `sim` have unique benefits, and you'll need to decide which method is most appropriate for your analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default behavior of concatenating by `time`\n",
    "cd.reset()\n",
    "concat_by_time = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .experiment_id([\"historical\", \"ssp370\"]) # Retrieve historical and future data \n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    "    .variable(\"prec\") # Precipitation \n",
    "    .processes({\n",
    "        \"concat\": \"time\"  # Concatenate along time dimension\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "concat_by_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ee082-b776-40db-84c1-76b98f6a068c",
   "metadata": {},
   "source": [
    "In the output of the code below, the data is stacked along the `sim` dimension rather than the `time` dimension. As a result, future model projections contain `NaN` values for the historical period (1980–2015), while historical simulations contain `NaN` values for the future projection period (2015–2100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90a447-6fe7-4331-a3da-f0839d1a419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example behavior of concatenating by `sim`\n",
    "cd.reset()\n",
    "concat_by_sim = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .experiment_id([\"historical\", \"ssp370\"]) # Retrieve historical and future data \n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    "    .variable(\"prec\") # Precipitation \n",
    "    .processes({\n",
    "        # Concatenate along simulation dimension. You'll notice that the `sim` dim\n",
    "        # now has `historical` and `ssp370` simulations stacked ontop of each other\n",
    "        \"concat\": \"sim\" \n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "concat_by_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e25f1",
   "metadata": {},
   "source": [
    "### Processor Example 2: Filter Unadjusted Models (only for WRF data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528379db",
   "metadata": {},
   "source": [
    "By default, we filter out unadjusted WRF models. These datasets have not undergone bias correction, which can introduce systematic errors into analyses. To learn more about why bias correction matters, see the Cal-Adapt guidance on Using Climate Data in Decision Making (linked <a href=\"https://analytics.cal-adapt.org/guidance/using_in_decision_making/#the-analytics-engine-hosts-a-priori-bias-corrected-as-well-as-non-bias-corrected-wrf-data---which-one-should-a-user-choose?\" target=\"_blank\">here</a>).\n",
    "\n",
    "If you’d like to include all available models, you can disable this filter by passing `filter_unadjusted_models: False` to the processors. **However, we strongly recommend using only the adjusted WRF models for analysis, as the unadjusted models contain biases that have not been corrected.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ead1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "all_models = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        'filter_unadjusted_models': 'no'\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "# Here, you'll see that there are 8 WRF GCMs, versus the example above that concatenating by time, which only had 5 GCMs.\n",
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804314ce",
   "metadata": {},
   "source": [
    "### Processor Example 3: Time Slicing\n",
    "\n",
    "Assuming you don't want to do an analysis on the entire timeseries of data available, we provide a TimeSlice processor to subset the climate of interest into a smaller temporal subset. Just this time, we'll time slice some `LOCA2` data to see how those parameters look like. Below is an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383af656",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "time_slice = (2030, 2050)\n",
    "time_slicing = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"LOCA2\")    # Activity ID is LOCA2 \n",
    "    .institution_id(\"UCSD\")  # We'll commonly just be using the `UCSD` institution_id for LOCA2 data.\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"tasmax\") # Max daily temp at 2 meters\n",
    "    .processes({\n",
    "        \"time_slice\": time_slice\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "time_slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63d204",
   "metadata": {},
   "source": [
    "### Processor Example 4: Global Warming Levels (GWL)\n",
    "\n",
    "Another approach you can take for your analysis is to use Global Warming Levels instead of time, so that you can compare simulations based on when they reach a certain level of warming rather than what their warming is at a certain point in time. To learn more, you can check out our GWL methodology notebook <a href=\"https://github.com/cal-adapt/cae-notebooks/blob/main/analysis/warming_level_methods.ipynb\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrf_wl_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "            # \"warming_level_window\": 12, # Optional: specify the window size (in years) for the warming level calculation\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "wrf_wl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8d3a8",
   "metadata": {},
   "source": [
    "### Processor Example 5: Clipping to Boundaries\n",
    "\n",
    "Now, you are more likely to have a specific area of interest rather than conducting an analysis over the entire WRF/LOCA2 grid. Using `climakitae`, there are many options for clipping to boundaries. They include:\n",
    "#### Clipping to a user specified shape file:\n",
    "- `\"clip\": \"<path to geopandas readable shape file>\"`\n",
    "\n",
    "#### Clipping to user specified lat/lons\n",
    "- `\"clip\": (lat0, lon0)`\n",
    "- `\"clip\": [(lat0, lon0), (lat1, lon1), ..., (latN, lonN)]`\n",
    "\n",
    "#### Clipping to a HADISD station\n",
    "Use `ClimateData().show_station_options()` to see a list of all accepted stations. Please note that this method DOES NOT bias adjust your data using historical station data, it simply pulls the data from the nearest grid cell in the data you're requesting.  \n",
    "- `\"clip\": \"KBFL\"`\n",
    "- `\"clip\": \"Bakersfield Meadows Field (KBFL)\"`\n",
    "- `\"clip\": [\"KBFL\", \"KBLH\", \"KBUR\"]`\n",
    "\n",
    "#### Clipping to `climakitae` supported boundaries\n",
    "The supported boundary types can be seen with `ClimateData().show_boundary_options()`. To see a comprehensive list of the types you can use `ClimateData().show_boundary_options(\"<type>\")`. Please be advised that some of these lists (like census tracts) are immense and may be listed by their numerical code.  \n",
    "\n",
    "- `\"clip\": \"Los Angeles County\"`\n",
    "- `\"clip\": [\"Alameda County\", \"Los Angeles County\"]`\n",
    "- `\"clip\": {\"boundaries\": [\"Alameda County\", \"Los Angeles County\"], \"separated\" = True}`\n",
    "- `\"clip\": [\"Alameda County\", \"City and County of San Francisco - Hetch Hetchy Water and Power\"]`\n",
    "\n",
    "**Note: You may also clip to multiple boundaries at the same time.** In this case, the union is returned by default, enabling a clean and intuitive plotting experience (shown below). If you’d prefer to preserve location as a dimension for comparative analysis, you can use the approach demonstrated in the third bullet of *Clipping to `climakitae` support boundaries* above: pass a dictionary with a `boundaries` key containing your list of boundaries and set `separated: True`. This produces a new dimension named after the first boundary type in the list. For example, applying this approach to the scenario in bullet 4 would create a dimension called `county`, since a county is the first boundary specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at all HADISD station options\n",
    "cd.show_station_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97841200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at other boundaries that `climakitae` supports\n",
    "cd.show_boundary_options()\n",
    "cd.show_boundary_options(\"ca_counties\")\n",
    "cd.show_boundary_options(\"ious_pous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc8464-ace4-42f7-8b07-d762b5195fed",
   "metadata": {},
   "source": [
    "Now, let's clip our WRF WL data to a specific point (Downtown Los Angeles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_clipped_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": (34.05, -118.25)  # Clip to specified coordinates\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "wl_clipped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46807187-80b1-4418-be9b-ad6560d38171",
   "metadata": {},
   "source": [
    "Now, let's clip to multiple points at the same time and take a look at the resulting data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb58b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lons = [\n",
    "    (34.05, -118.25),  # Los Angeles, CA\n",
    "    (37.77, -122.42),  # San Francisco, CA\n",
    "]\n",
    "wl_couple_points = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": {\n",
    "            \"points\": lat_lons,  # Clip to specified coordinates\n",
    "            # Whether or not you want your clipped points to be in a separate dimension called `points`,\n",
    "            # or if you want gridded data returned with NaN everywhere except selected points.\n",
    "            \"separated\": True\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "wl_couple_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a75e8e-695f-4fd0-ab75-474848368f77",
   "metadata": {},
   "source": [
    "We can also input pairs of lats and lons as a bounding box for the data we're trying to retrieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6aa80-5676-47d6-9d55-eebea6844abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_lat_lons = (\n",
    "    (34.05, 37.77),\n",
    "    (-122.42, -118.25),\n",
    ")\n",
    "wl_box = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": box_lat_lons\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "wl_box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb05da-e9b7-4d18-922c-259474aeb2c3",
   "metadata": {},
   "source": [
    "We can additionally clip different boundaries together too. Below, we'll clip Alameda and Los Angeles Counties into one xr.DataArray and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e37ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_counties = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": [\"Alameda County\", \"Los Angeles County\"]\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "clip_counties.isel(sim=0, warming_level=0, time_delta=0).t2.plot(x='lon', y='lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e649a91",
   "metadata": {},
   "source": [
    "Now, we can separate the two clipped regions like we did before using the `separated: True` parameter to `clip`, and see that `county` now exists as a dimension on the resulting DataArray object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_counties_separated = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": {\n",
    "            \"boundaries\": [\"Alameda County\", \"Los Angeles County\"],\n",
    "            \"separated\": True\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "clip_counties_separated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cdacb",
   "metadata": {},
   "source": [
    "### Processor Example 6: Unit Conversion\n",
    "\n",
    "We can also pass in a processor to convert the units of our dataset. It's as simple as specifying the conversion you'd like to apply. If it fails, you'll be informed in the logs about available units to convert to and no unit conversion will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6246068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we'll take the temperature data that's natively in Kelvin to be returned in Fahrenheit instead\n",
    "degF_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": \"Los Angeles County\",\n",
    "        \"convert_units\": \"degF\" # This will convert from Kelvin to Fahrenheit\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "degF_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf697e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll see that the values are within the reasonable ranges of we'd see for Fahrenheit for Los Angeles County\n",
    "degF_data.mean(dim='time_delta').isel(sim=0, warming_level=0).t2.plot(x=\"lon\", y=\"lat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1044a6",
   "metadata": {},
   "source": [
    "### Processor Example 7: Metric Calculation\n",
    "\n",
    "Some basic metric calculations have also been built in as processors, so that you can save yourself a few steps of calculating common metrics on your resulting dataset.\n",
    "\n",
    "The basic options include: `min`, `mean`, `median`, `max`, and `percentiles` and are demonstrated below. \n",
    "\n",
    "1-in-X calculations have also been included in as a more complex metric calculation for this processor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed665d-b290-4a35-a778-a959cb7ed10a",
   "metadata": {},
   "source": [
    "#### Simple Metric Comparison Across Warming Levels\n",
    "\n",
    "Let's start with a simple metric comparison. We'll evaluate the min, mean, and max across three global warming levels, and then plot all those in a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ed48e-0666-43c3-adc3-35369beab38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['min', 'mean', 'max']\n",
    "data = []\n",
    "for metric in metrics:\n",
    "    data.append(\n",
    "        (cd.catalog(\"cadcat\")\n",
    "        .activity_id(\"WRF\")\n",
    "        .institution_id(\"UCLA\")\n",
    "        .table_id(\"day\")\n",
    "        .grid_label(\"d03\")\n",
    "        .variable(\"t2\")\n",
    "        .processes({\n",
    "            \"warming_level\": {\n",
    "                \"warming_levels\": [1.5, 2.0, 3.0],\n",
    "            },\n",
    "            \"clip\": \"Humboldt County\",\n",
    "            \"convert_units\": \"degF\",\n",
    "            \"metric_calc\": {\n",
    "                \"metric\": metric,\n",
    "                # NOTE: We have a `time_delta` dimension here because that's the time variable that's returned from a warming\n",
    "                # level approach of retrieving data. If this was a time-based approach, that dimension would be named `time`.\n",
    "                \"dim\": [\"time_delta\", \"sim\"]\n",
    "                # note: don't average over warming level\n",
    "            }\n",
    "        })\n",
    "        .get())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78c222-caf1-46af-a44b-959a3d4cf0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the 3 warming levels\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12), sharex=True, sharey=True)\n",
    "\n",
    "gwls = [1.5, 2.0, 3.0][::-1]  # Reverse for plotting\n",
    "for i, metric in enumerate(metrics):\n",
    "    for j, gwl in enumerate(gwls):\n",
    "        ax = axes[j, i]\n",
    "        data[i].isel(warming_level=len(gwls) - 1 - j).t2.plot.contourf(\n",
    "            ax=ax,\n",
    "            y=\"lat\",\n",
    "            x=\"lon\",\n",
    "            cbar_kwargs={\n",
    "                'label': 'Temperature (°F)',\n",
    "            }, \n",
    "            levels=100,\n",
    "            cmap='plasma',\n",
    "            vmin=0,\n",
    "            vmax=110\n",
    "        )\n",
    "        ax.set_title(f'{metric.capitalize()} at {gwl}°C Warming Level')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75a6b3-8460-4ab7-b9c7-5562e4b29bbd",
   "metadata": {},
   "source": [
    "#### Advanced Metric Comparison Across Warming Levels\n",
    "\n",
    "Now, let's try a slightly more advanced analysis. Let's defined a base level of warming of 1.2°C as our reference period, and then calculate the 90th, 95th, and 98th percentile temperatures within this reference period. \n",
    "\n",
    "Then, we'll get the temperature for three global warming levels (1.5, 2.0, 3.0) and count the average number of days per year above the 90th, 95th, and 98th percentile reference period temperature for each warming level for each individual GCM. Then we'll average the number of days across GCMs and plot the results in a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8363e54-c20c-4bb3-8af6-60726ddb09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first find the 90th, 95th, and 98th percentiles over Humboldt County for a 1.2°C reference warming level period.\n",
    "percentiles = [90, 95, 98]\n",
    "location = \"Humboldt County\"\n",
    "ref_percentiles = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.2],\n",
    "        },\n",
    "        \"clip\": location,\n",
    "        \"convert_units\": \"degF\",\n",
    "        \"metric_calc\": {\n",
    "            \"percentiles\": percentiles,\n",
    "            \"dim\": [\"time_delta\"]\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482fc76-2e5b-423d-b4fe-023616d62934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll get all the raw data from the future WLs and count the number of days each simulation is above the different 1.2°C WL percentiles.\n",
    "wrf_wl_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0],\n",
    "        },\n",
    "        \"clip\": location,\n",
    "        \"convert_units\": \"degF\",\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0d85b-4d4e-4887-8eba-35ae6ed1db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ref_percentiles)\n",
    "display(wrf_wl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d47fcf-4da9-450d-bda0-5f4c108358ca",
   "metadata": {},
   "source": [
    "First, we'll drop `EC-Earth3-Veg` from `wrf_wl_data`. This simulation reaches 1.2°C. of warming before a full warming-level (WL) slice can be constructed. Because the WRF dataset spans from 1981-2100 and we are querying for WL slices full of 30 years of data, any simulation that reaches a target before 1996 or after 2085 is excluded due to incomplete data. In this case, `EC-Earth3-Veg` reaches 1.2 °C in 1995, resulting in insufficient data to form a complete WL slice, so it's dropped from the resulting Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21461c-246b-4068-9ec2-5bb2b0ff5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping `EC-Earth3-Veg` by only keeping the other sims\n",
    "only_valid_wrf = wrf_wl_data.sel(sim=[\n",
    "    'WRF_UCLA_TaiESM1_ssp370_day_d03_r1i1p1f1',\n",
    "    # 'WRF_UCLA_EC-Earth3-Veg_ssp370_day_d03_r1i1p1f1',\n",
    "    'WRF_UCLA_MIROC6_ssp370_day_d03_r1i1p1f1',\n",
    "    'WRF_UCLA_EC-Earth3_ssp370_day_d03_r1i1p1f1',\n",
    "    'WRF_UCLA_MPI-ESM1-2-HR_ssp370_day_d03_r3i1p1f1'\n",
    "])\n",
    "\n",
    "# Creating a DataArray from the reference percentiles\n",
    "ref_percentile_da = ref_percentiles[[\"t2_p90\", \"t2_p95\", \"t2_p98\"]].isel(warming_level=0).to_array(dim=\"percentiles\").assign_coords(percentiles=percentiles)\n",
    "\n",
    "# Comparing the temperature values to the percentiles\n",
    "compared_da = (only_valid_wrf > ref_percentile_da).t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bfc1c2-1ccc-45e4-9e9e-ec674b19cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now, let's plot a comparison of the results\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12), sharex=True, sharey=True)\n",
    "\n",
    "# mask for the spatial coordinates so that we can preserve them after counting\n",
    "spatial_mask = ref_percentile_da.isel(percentiles=0, sim=0).notnull()\n",
    "\n",
    "gwls = [1.5, 2.0, 3.0][::-1]  # Reverse for plotting\n",
    "for i, metric in enumerate(percentiles):\n",
    "    for j, gwl in enumerate(gwls):\n",
    "        ax = axes[j, i]\n",
    "        \n",
    "        days_exceeding = (compared_da.isel(warming_level=len(gwls) - 1 - j).sel(percentiles=metric).mean(dim='sim')).sum(dim='time_delta', skipna=False) / 30\n",
    "\n",
    "        # preserve the masked county\n",
    "        days_exceeding = days_exceeding.where(spatial_mask)\n",
    "\n",
    "        # contour plot\n",
    "        days_exceeding.plot.contourf(\n",
    "            ax=ax,\n",
    "            y=\"lat\",\n",
    "            x=\"lon\",\n",
    "            cbar_kwargs={'label': 'Avg Days Per Year Above Reference'},\n",
    "            levels=100,\n",
    "            cmap='plasma',\n",
    "            vmin=0, vmax=99\n",
    "        )\n",
    "        ax.set_title(f'Avg Days / Year > {metric}th pctl T2 at {gwl}°C GWL')\n",
    "\n",
    "plt.suptitle(\"Average Number of Days Above Reference Percentile Temp for several Global Warming Levels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2e396",
   "metadata": {},
   "source": [
    "#### 1-in-X Metric Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f53f2",
   "metadata": {},
   "source": [
    "Finally, the last metric calculation that we provide out-of-the-box with the `ClimateData` object are 1-in-X calculations. Below demonstrates an example of how you could calculate the **Maximum 1-in-10 and 1-in-50 Daily Air Temperatures for WRF data over Alameda County for a 1.5°C warming world.**\n",
    "\n",
    "**Parameter options for 1-in-X calculations:**\n",
    "- `return_periods`: A list of return periods you're interested in calculating for your dataset\n",
    "- `distribution`: One of the following distribution types: `[\"gev\", \"gumbel\", \"weibull\", \"pearson3\", \"genpareto\", \"gamma\"]` (see more on scipy.stats documentation <a href=\"https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions\" style=\"color: blue;\" target=\"_blank\">here</a>).\n",
    "- `extremes_type`: `min` or `max`\n",
    "- `event_duration`: (# of time, scale of time), i.e. `(1, 'day')`\n",
    "- `block_size`: Block size in number of years, default is 1\n",
    "- `goodness_of_fit_test`:  # Whether or not you want to see the p-values from the fitted distributions used to calculate the resulting 1-in-X return values, default is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_periods = [10, 100]\n",
    "one_in_x_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [2.0]\n",
    "        },\n",
    "        \"clip\": \"Alameda County\", \n",
    "        \"convert_units\": \"degF\",\n",
    "        \"metric_calc\": {\n",
    "            \"one_in_x\": {\n",
    "                \"return_periods\": return_periods, # Looking at 1-in-10 and 1-in-100\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    .get())\n",
    "\n",
    "# Let's plot what the 1-in-X return values look like over Alameda County\n",
    "for x in return_periods:\n",
    "    fig,ax = plt.subplots()\n",
    "    one_in_x_data.mean(dim='sim').sel(one_in_x=x).return_values.plot(\n",
    "        cmap='plasma', \n",
    "        x='lon', \n",
    "        y='lat',\n",
    "        cbar_kwargs={'label': f'1-in-{x} year Daily Max Temperature (°F)'}\n",
    "    )\n",
    "    ax.set_title(f'1-in-{x} Year Daily Max Temp averaged \\nover all WRF sims for Alameda County')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df5827-549f-4c90-977c-79e63557c836",
   "metadata": {},
   "source": [
    "### Processor Example 9: Bias Adjust Model to Station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d818ce",
   "metadata": {},
   "source": [
    "In case you want to station bias correct gridded climate model data to historical observations from weather stations, you can pass in your desired weather station to the `bias_adjust_model_to_station` processor that we provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually bias adjust our climate data to KSAC (the SAC airport weather station).\n",
    "manual_bias_adjustment = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"1hr\")\n",
    "    .grid_label(\"d02\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"bias_adjust_model_to_station\": {\n",
    "            \"stations\": ['KSAC'],\n",
    "            \"historical_slice\": (1980, 2014), # You can specify what historical period to bias correct for.\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "manual_bias_adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581676cf",
   "metadata": {},
   "source": [
    "### Processor Example 10: Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f682b-3972-4235-b09c-1eab5017fdbf",
   "metadata": {},
   "source": [
    "Now that we’ve walked through the processors above, you want want to export the data to your local machine. The `export` processor makes this straightforward.\n",
    "\n",
    "In the example below, we take a small subset of data, apply a few processors, and then export the result using the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a5bd5-df65-4c4d-9a6b-dd28eb73bc2a",
   "metadata": {},
   "source": [
    "        filename (str, optional): Base output filename without extension.\n",
    "            Default: \"dataexport\"\n",
    "        file_format (str, optional): Output file format. Supported values:\n",
    "            \"NetCDF\", \"Zarr\", \"CSV\". Case-insensitive. Default: \"NetCDF\"\n",
    "        mode (str, optional): Storage location for Zarr files.\n",
    "            \"local\" saves to local filesystem, \"s3\" saves to AWS S3.\n",
    "            Default: \"local\"\n",
    "        separated (bool, optional): When exporting a collection of point datasets,\n",
    "            whether to create separate files for each point. If True, each dataset\n",
    "            gets its own file with either lat/lon or index suffix. If False, all\n",
    "            items are exported with the base filename (unique suffixes added if needed).\n",
    "            Ignored for single gridded datasets. Default: False\n",
    "        location_based_naming (bool, optional): When separated=True and\n",
    "            exporting point-based data, include lat/lon coordinates in filenames\n",
    "            (e.g., filename_34-0N_118-0W.nc). If False, uses index numbers\n",
    "            instead (e.g., filename_0.nc). Silently ignored for gridded datasets.\n",
    "            Default: False\n",
    "        export_method (str, optional): Controls what data to export. Options:\n",
    "            \"data\": Export all provided data (default)\n",
    "            \"raw\": Export only raw/unprocessed data\n",
    "            \"calculate\": Export only calculated/processed data\n",
    "            \"both\": Export both raw and calculated data to separate files\n",
    "            \"skip_existing\": Skip export if file already exists\n",
    "            \"none\": Skip export entirely\n",
    "            Default: \"data\"\n",
    "        raw_filename (str, optional): Custom filename for raw data when using\n",
    "            export_method=\"raw\" or \"both\". If not provided, uses\n",
    "            \"{filename}_raw\". Default: None\n",
    "        calc_filename (str, optional): Custom filename for calculated data when\n",
    "            using export_method=\"calculate\" or \"both\". If not provided, uses\n",
    "            \"{filename}_calc\".\n",
    "            Default: None\n",
    "        filename_template (str, optional): Custom template for generating filenames.\n",
    "            Supports placeholders: {filename}, {lat}, {lon}, {name}.\n",
    "            Lat/lon placeholders only populated for single-point data.\n",
    "            Example: \"{name}_data_{lat}N_{lon}W\".\n",
    "            Default: None\n",
    "        fail_on_error (bool, optional): If True, raise exceptions on export\n",
    "            errors. If False, log warnings and continue.\n",
    "            Default: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157320f-7c85-40a9-9259-f25f4f391133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's export all of Humboldt County's data into one file\n",
    "location = \"Humboldt County\"\n",
    "export_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.2],\n",
    "        },\n",
    "        \"clip\": location,\n",
    "        \"convert_units\": \"degF\",\n",
    "        \"export\": {\n",
    "            \"filename\": \"gridded_export_data\", # Filename that you want the data exported to\n",
    "            \"file_format\": \"NetCDF\" # File format - default is `NetCDF`, other options are `NetCDF`, `Zarr`, and `CSV`\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9720a-fd39-4830-ad10-78e6fe48e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lons = [\n",
    "    (34.05, -118.25),  # Los Angeles, CA\n",
    "    (37.77, -122.42),  # San Francisco, CA\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e81b62-1904-4995-997d-0e9238ccb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's export this list of `lat_lons` from before into separate files.\n",
    "export_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.2],\n",
    "        },\n",
    "        \"clip\": {\n",
    "            \"points\": lat_lons,\n",
    "            \"separated\": True,\n",
    "        },\n",
    "        \"convert_units\": \"degF\",\n",
    "        \"export\": {\n",
    "            \"separated\": True, # Whether or not you want different shapes (i.e. points, counties) to be separated into different files\n",
    "            \"location_based_naming\": True, # Whether or not you want the lat/lons of different points passed \n",
    "            \"filename\": \"point_export_data\", # Filename that you want the data exported to\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07912fa-0dc4-472f-a68a-181678d125d5",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c04a36",
   "metadata": {},
   "source": [
    "This notebook, together with `climakitae`, is intended to support and streamline your climate data analyses by providing practical examples and access to the datasets supported by Cal-Adapt: Analytics Engine, along with a suite of built-in data processors.\n",
    "\n",
    "**Some key highlights that are accessible with `climakitae:`**\n",
    "- Simplified access to a wide range of climate datasets\n",
    "- Flexible configuration of variables, spatial and temporal resolutions, and locations.\n",
    "- Built-in data transformations that reduce the need for manual pre-processing.\n",
    "- Integrated climate and statistical processors designed to streamline your climate analyses.\n",
    "\n",
    "We encourage you to explore these capabilities and experiment with different configurations to better understand how `climakitae` can support your analytical needs.\n",
    "\n",
    "If you encounter any issues while running this notebook, experience unexpected behavior in any of the processors, or have feedback or feature requests related to the `ClimateData` object, please submit an issue on our GitHub repository:\n",
    "https://github.com/cal-adapt/climakitae/issues.\n",
    "\n",
    "Your feedback is very valuable to us and helps guide continued development and improvement of the library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (climakitae)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
