{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811929f5-5aaf-4c4c-af1c-0c63bd51961e",
   "metadata": {},
   "source": [
    "# Data Access Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abd63d-4e03-4634-a6a2-1fca9c967792",
   "metadata": {},
   "source": [
    "In this notebook, we’ll be walking through how to retrieve climate data from `climakitae` through a series of real-world analyses. These include visualizing time-series temperature data, retrieving warming-level data, and calculating 1-in-X metrics—all designed to help you get familiar with how `climakitae` works in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7d3a6-1d86-4f2f-964d-3c00f46dffe8",
   "metadata": {},
   "source": [
    "**Intended Application:** As a user, I want to **<span style=\"color:red\">understand how new core in `climakitae` works and how I can use it for my own climate analyses.</span>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f9736-8fef-40e5-8263-7968e5a43682",
   "metadata": {},
   "source": [
    "**Runtime**: ~20 min. to run through the whole notebook. Modifications to different queries may increase/decrease the overall runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import climakitae as ck "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588887a8",
   "metadata": {},
   "source": [
    "# High-level details \n",
    "The AE data catalog has many different types of data. Our helper library `climakitae` attempts to make accessing and retrieving this data intuitive, as well as simplify climate and statistical analysis with the data down the line, by performing some data transformations as the data is retrieved.<br><br> To retrieve the data, you'll need to make some selections as to your climate variable, data resolution, location settings, and many other options. There are also several high-level options you'll need to set when selecting your data, detailed below: \n",
    "\n",
    "### Data type: Gridded or Stations\n",
    "**Gridded**: Gridded (i.e. raster) climate data at various spatial resolutions.<br><br>\n",
    "**Stations**: Gridded (i.e. raster) climate data at unique grid cell(s) corresponding to the central coordinates of the selected weather station(s). \n",
    "- This data is bias-corrected (i.e localized) to the exact location of the weather station using the historical in-situ data from the weather station(s). \n",
    "- This data is currently only available for dynamically downscaled air temperature data. \n",
    "\n",
    "### Scientific approach: Time or Warming Level\n",
    "**Time**: We can retrieve the data using a traditional time-based approach that allows you to select historical data, future projections, or both, along with a time-slice of interest. \n",
    "- **Historical Climate** includes data from 1980-2014 simulated from the same GCMs used to produce the Shared Socioeconomic Pathways (SSPs). It will be automatically appended to a SSP time series when both are selected. Because this historical data is obtained through simulations, it represents average weather during the historical period and is not meant to capture historical timeseries as they occurred.\n",
    "- **Historical Reconstruction** provides a reference downscaled <a href=\"https://www.ecmwf.int/en/about/media-centre/focus/2020/fact-sheet-reanalysis\" style=\"color: blue;\" target=\"_blank\">reanalysis</a> dataset based on atmospheric models fit to satellite and station observations, and as a result will reflect observed historical time-evolution of the weather.\n",
    "- Future projections are available for <a href=\"https://climatescenarios.org/primer/socioeconomic-development\" style=\"color: blue;\" target=\"_blank\">greenhouse gas emission scenario (Shared Socioeconomic Pathway, or SSP)</a> SSP 2-4.5, SSP 3-7.0, and SSP 5-8.5 through 2100.\n",
    "\n",
    "**Warming Level**: Retrieve data based on future global warming levels. This method automatically gathers all available model data across the combined historical and future periods, then determines the time window during which each simulation reaches the selected warming level. \n",
    "- Because warming levels are defined by changes in global mean temperature, they allow for comparisons of potential outcomes across different scenarios and model simulations.\n",
    "- Unlike a time-based approach, which limits analysis to simulations following a specific SSP trajectory, this method includes all simulations that reach the specified amount of warming, regardless of when that warming occurs.\n",
    "<br>\n",
    "### Downscaling method: Dynamical, Statistical, or both\n",
    "**Dynamical**: <a href=\"https://dept.atmos.ucla.edu/alexhall/downscaling-cmip6\" style=\"color: blue;\" target=\"_blank\">Dynamically-downscaled</a> WRF data, produced at hourly intervals. If you select `daily` or `monthly` for `Timescale`, you will receive an average of the hourly data. The spatial resolution options, on the other hand, are each the output of a different simulations, nesting to higher resolution over smaller areas.<br>\n",
    "\n",
    "**Statistical**: <a href=\"https://loca.ucsd.edu\" style=\"color: blue;\" target=\"_blank\">Hybrid-statistically downscaled</a> LOCA2-Hybrid data, available at daily and monthly timescales. Multiple LOCA2-Hybrid simulations are available (100+) at a fine spatial resolution of 3km."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36490d-c19b-4b81-8447-8dd38b8c3ab9",
   "metadata": {},
   "source": [
    "# Data Selection Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750153d-4aec-4011-8345-9ceb5d9e2fa8",
   "metadata": {},
   "source": [
    "There are several methods to explore all the available data options in `climakitae`. You can get a comprehensive overview or explore step by step.\n",
    "\n",
    "### Verbosity\n",
    "You can also choose the level of output `climakitae` will provide for you. <br>\n",
    "`-2` : errors only  \n",
    "`-1` : warnings and errors  \n",
    "`0`  : info, warnings, and errors (default)  \n",
    "`1`  : debug, info, warnings, and errors (developers or debugging only, not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4da135-f64c-415e-a03b-0863cd67bd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the interface\n",
    "cd = ck.ClimateData(verbosity=-1) # only give error messages, quiet output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0cd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a comprehensive overview of all available options\n",
    "cd.show_all_options()\n",
    "\n",
    "# Or you can see specific categories by uncommenting any of the lines below:\n",
    "# cd.show_catalog_options()\n",
    "# cd.show_activity_id_options()\n",
    "# cd.show_institution_id_options()\n",
    "# cd.show_source_id_options()\n",
    "# cd.show_experiment_id_options()\n",
    "# cd.show_table_id_options()\n",
    "# cd.show_grid_label_options()\n",
    "# cd.show_variable_options()\n",
    "# cd.show_installation_options()\n",
    "# cd.show_processors()\n",
    "# cd.show_boundary_options()\n",
    "# cd.show_station_options()\n",
    "\n",
    "### This will be explored in more detail in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed137e-c478-4401-beeb-8bfd5d12f45f",
   "metadata": {},
   "source": [
    "## Data Selection Options for a particular set of inputs\n",
    "You can explore options step by step, building your query as you learn about available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c193f9f-c154-413f-92dc-084d2ea05ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore options step by step\n",
    "print(\"=== Available Catalogs ===\")\n",
    "cd.reset()\n",
    "cd.show_catalog_options()\n",
    "\n",
    "print(\"\\n=== Choose 'renewable energy generation' catalog and explore installations ===\")\n",
    "renewables_explorer = cd.catalog(\"renewable energy generation\")\n",
    "renewables_explorer.show_installation_options()\n",
    "\n",
    "print(\"\\n=== Choose 'pv_utility' installation and explore variables ===\")\n",
    "pv_explorer = renewables_explorer.installation(\"pv_utility\")\n",
    "pv_explorer.show_variable_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1e03c-a414-4b5b-94d3-1ec2b01573a1",
   "metadata": {},
   "source": [
    "You can also explore the climate data catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf820b0-9940-4ec9-b8d4-ad9e8cd4cb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=== Climate Data Catalog ===\")\n",
    "cd.reset()\n",
    "data_explorer = cd.catalog(\"cadcat\")\n",
    "\n",
    "print(\"\\n=== WRF (Dynamical Downscaling) Variables ===\")\n",
    "wrf_explorer = data_explorer.activity_id(\"WRF\")\n",
    "wrf_explorer.show_variable_options(show_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cad5-89cd-4ec2-8b76-fca3f764e247",
   "metadata": {},
   "source": [
    "At any point in building your query, you can check what parameters you've set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae3993-ead4-49d8-87ad-066ec5c3181f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a partial query and check its state\n",
    "partial_query = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .experiment_id(\"historical\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    ")\n",
    "\n",
    "# Check what we've built so far\n",
    "partial_query.show_query()\n",
    "\n",
    "# # See what variable options are still available\n",
    "print(\"\\nAvailable variables for this query:\")\n",
    "partial_query.show_variable_options(show_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8260ed-adff-4c49-86ff-69ec207da04d",
   "metadata": {},
   "source": [
    "You can reset the interface to start a new query at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66582be5-eb9a-42b8-ae08-e96ffa671195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "print(\"Interface reset - ready for new query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501a518",
   "metadata": {},
   "source": [
    "# Retrieving data \n",
    "The `ClimateData` interface allows you to chain method calls to build readable queries, and then retrieve the data easily in your query. \n",
    "<br><br>\n",
    "Required components of the query depend on the data catalog you're interested in. In general, the required components for all queries are: \n",
    "- catalog\n",
    "- variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb1909",
   "metadata": {},
   "source": [
    "### Example 1: Future air temperature data \n",
    "You can retrieve data using a dictionary query, or by chaining operations to the `ClimateData` object. Either is valid and will result in the same output data, so just use whichever method is most intuitive to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d827595",
   "metadata": {},
   "source": [
    "#### Method 1: Chained operations (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "climate_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .experiment_id(\"ssp370\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d02\")\n",
    "    .variable(\"t2\")\n",
    ").get()\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd644bb",
   "metadata": {},
   "source": [
    "#### Method 2: Dictionary query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query \n",
    "climate_query_dict = {\n",
    "    \"catalog\": \"cadcat\", # Catalog name \n",
    "    \"activity_id\": \"WRF\", # Downscaling method \n",
    "    \"institution_id\": \"UCLA\", # Institution name\n",
    "    \"experiment_id\": \"ssp370\", # Simulation\n",
    "    \"table_id\": \"mon\", # Temporal resolution \n",
    "    \"grid_label\": \"d02\", # Grid resolution\n",
    "    \"variable_id\": \"t2\" # Variable name \n",
    "}\n",
    "\n",
    "# Load the query \n",
    "climate_query = ck.ClimateData(verbosity=-2).load_query(climate_query_dict)\n",
    "\n",
    "# Retrieve the data\n",
    "climate_data = climate_query.get()\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be7d28",
   "metadata": {},
   "source": [
    "### Example 2: Renewable energy model data \n",
    "Note that the renewables catalog has an additional query option: `installation`. This indicates the energy generation method, a parameter that is only applicable for this particular catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8436c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query \n",
    "renewables_query_dict = {\n",
    "    \"catalog\": \"renewable energy generation\", # Catalog name \n",
    "    \"experiment_id\": \"historical\", # Model name \n",
    "    \"table_id\": \"day\", # Temporal resolution \n",
    "    \"grid_label\": \"d03\", # Grid resolution\n",
    "    \"variable_id\": \"cf\", # Variable name \n",
    "    \"installation\": \"pv_utility\", # Renewables catalog only! \n",
    "    # \"source_id\": \"MPI-ESM1-2-HR\" # Optional: pick a simulation within the model \n",
    "}\n",
    "\n",
    "# Load the query \n",
    "renewables_query = ck.ClimateData(verbosity=-2).load_query(renewables_query_dict)\n",
    "\n",
    "# Retrieve the data\n",
    "renewables_data = renewables_query.get()\n",
    "renewables_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072c6c8-bd43-441b-b630-e171f883972c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0937d9",
   "metadata": {},
   "source": [
    "# Working with Processors\n",
    "You can further customize your data retrieval using `processors`, which perform operations on the data before it is returned to you. The available processors are: \n",
    "\n",
    "- **`concat`** - Concatenate datasets along specified dimensions, default behavior is to concatenate on \"time\" by combining historical and SSP datasets.\n",
    "- **`filter_unadjusted_models`** - Remove or include unadjusted models (default: \"yes\" to remove).\n",
    "- **`update_attributes`** - Updates the attributes of your dataset based on the processors applied.\n",
    "- `time_slice` - Applies a time slice to the requested dataset.\n",
    "- `warming_level` - Applies a global warming level approach (as separate from the default time based approach). Please see our guidance on the use of global warming levels.\n",
    "- `clip` - Applies a spatial clipping to the requested dataset. Many types of spatial clipping are supported including point based, bounding box, user provided shape files, and built-in boundaries including states, CA counties, CA watersheds, CA electric and utilities areas, CA demand forecast zones, CA electric balancing authority areas, and CA census tracts.\n",
    "- `convert_units` - converts the units of your dataset.\n",
    "- `metric_calc` - applies metric calculations to your dataset such as min, max, mean, median, percentiles, and 1-in-X calculations. \n",
    "- `bias_adjust_model_to_station` - For working with gridded data bias adjusted to historical HADISD weather station data.\n",
    "- `export` - Exports your requested dataset to a range of file formats.\n",
    "\n",
    "The first three processors (bolded) are run by default every time that you retrieve data. Examples of other available processors can be found in the `climakitae` library documentation, or in other example notebooks. <br><br>\n",
    "It's important to note that processors are applied as a **dictionary**. This enables you to add more than one processor to your chain of operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96754193-6c30-4ece-b712-f3082b97cdd9",
   "metadata": {},
   "source": [
    "## Processor Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5c026-c842-4fa4-ab92-6d72069d10be",
   "metadata": {},
   "source": [
    "To bring cohension between the processor examples we'll be looking at below, we'll be building towards a complete, realistic analysis using WRF data. Any dataset works, but for demonstration purposes it is useful to see how the puzzle pieces fit together using a consistent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ace5a",
   "metadata": {},
   "source": [
    "### Processor Example 1: Concatenation along a specified dimension\n",
    "By default, when historical data is retrieved in the same operation as future data, the historical data will be appended to the future data, giving a single timeseries. However, you can change this default behavior by setting the query to concatenate along the simulation `sim` dimension instead. This will return the historical and future data as separate simulations. Concatenating by `time` or by `sim` have unique benefits, and you'll need to decide which method is most appropriate for your analyses. \n",
    "\n",
    "In the returned data from the code below, future time periods for the historical simulation will be infilled with `NaN`, because the model has no data for that time period by definition. The same logic applies to the future simulations: any time in the past will be infilled with `NaN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default behavior of concatenating by `time`\n",
    "cd.reset()\n",
    "concat_by_time = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .experiment_id([\"historical\", \"ssp370\"]) # Retrieve historical and future data \n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    "    .variable(\"prec\") # Precipitation \n",
    "    .processes({\n",
    "        \"concat\": \"time\"  # Concatenate along simulation dimension\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "concat_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90a447-6fe7-4331-a3da-f0839d1a419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example behavior of concatenating by `sim`\n",
    "cd.reset()\n",
    "concat_by_sim = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .experiment_id([\"historical\", \"ssp370\"]) # Retrieve historical and future data \n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d01\")\n",
    "    .variable(\"prec\") # Precipitation \n",
    "    .processes({\n",
    "        # Concatenate along simulation dimension. You'll notice that the `sim` dim\n",
    "        # now has `historical` and `ssp370` simulations stacked ontop of each other\n",
    "        \"concat\": \"sim\" \n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "concat_by_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e25f1",
   "metadata": {},
   "source": [
    "### Processor Example 2: Filter Unadjusted Models (only for WRF data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528379db",
   "metadata": {},
   "source": [
    "By default, we filter out unadjusted WRF models. If you're interested in learning more about why, you can check out the section in our guidance where we talk about that <a href=\"https://analytics.cal-adapt.org/guidance/using_in_decision_making/#the-analytics-engine-hosts-a-priori-bias-corrected-as-well-as-non-bias-corrected-wrf-data---which-one-should-a-user-choose?\" style=\"color: blue;\" target=\"_blank\">here.</a> However, if you'd like to see all models, you can pass in `filter_unadjusted_models: False` into the processors. **However, we highly recommend ONLY using the adjusted WRF models for analysis, since the unadjusted models have biases that have not been corrected.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ead1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "all_models = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        'filter_unadjusted_models': 'no'\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "# Here, you'll see that there are 8 WRF models, versus the example above that concatenating by time, which only had 5 models.\n",
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804314ce",
   "metadata": {},
   "source": [
    "### Processor Example 3: Time Slicing\n",
    "\n",
    "Assuming you don't want to do an analysis on the entire timeseries of data available, we provide a TimeSlice processor to subset the climate of interest into a smaller temporal subset. Just this time, we'll time slice some `LOCA2` data to see how those parameters look like. Below is an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383af656",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.reset()\n",
    "time_slice = (2030, 2050)\n",
    "time_slicing = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"LOCA2\")    # Activity ID is LOCA2 \n",
    "    .institution_id(\"UCSD\")  # Different institution for LOCA2\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"tasmax\") # Max daily temp at 2 meters\n",
    "    .processes({\n",
    "        \"time_slice\": time_slice\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "time_slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3eb7f-5729-454a-a7ba-f9c59829bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63d204",
   "metadata": {},
   "source": [
    "### Processor Example 4: Global Warming Levels (GWL)\n",
    "\n",
    "Another approach you can take for your analysis is to use Global Warming Levels instead of time, so that you can compare simulations based on when they reach a certain level of warming rather than what their warming is at a certain point in time. To learn more, you can check out our GWL methodology notebook <a href=\"https://github.com/cal-adapt/cae-notebooks/blob/main/analysis/warming_level_methods.ipynb\" style=\"color: blue;\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrf_wl_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "            # \"warming_level_window\": 12, # Optional: specify the window size (in years) for the warming level calculation\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "wrf_wl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8d3a8",
   "metadata": {},
   "source": [
    "### Processor Example 5: Clipping to Boundaries\n",
    "\n",
    "Now, you are more likely to have a specific area of interest rather than conducting an analysis over the entire WRF/LOCA2 grid. Using `climakitae`, there are many options for clipping to boundaries. They include:\n",
    "#### Clipping to a user specified shape file:\n",
    "- `\"clip\": \"<path to geopandas readable shape file>\"`\n",
    "\n",
    "#### Clipping to user specified lat/lons\n",
    "- `\"clip\": (lat0, lon0)`\n",
    "- `\"clip\": [(lat0, lon0), (lat1, lon1), ..., (latN, lonN)]`\n",
    "\n",
    "#### Clipping to a HADISD station\n",
    "Use `ClimateData().show_station_options()` to see a list of all accepted stations. Please note that this method DOES NOT bias adjust your data using historical station data, it simply pulls the data from the nearest grid cell in the data you're requesting.  \n",
    "- `\"clip\": \"KBFL\"`\n",
    "- `\"clip\": \"Bakersfield Meadows Field (KBFL)\"`\n",
    "- `\"clip\": [\"KBFL\", \"KBLH\", \"KBUR\"]`\n",
    "\n",
    "#### Clipping to `climakitae` supported boundaries\n",
    "The supported boundary types can be seen with `ClimateData().show_boundary_options()`. To see a comprehensive list of the types you can use `ClimateData().show_boundary_options(\"<type>\")`. Please be advised that some of these lists (like census tracts) are immense and may be listed by their numerical code.  \n",
    "\n",
    "- `\"clip\": \"Los Angeles County\"`\n",
    "- `\"clip\": [\"Alameda County\", \"Los Angeles County\"]`\n",
    "- `\"clip\": {\"boundaries\": [\"Alameda County\", \"Los Angeles County\"], \"separated\" = True}`\n",
    "- `\"clip\": [\"Alameda County\", \"City and County of San Francisco - Hetch Hetchy Water and Power\"]`\n",
    "\n",
    "**Note: You may also clip to multiple boundaries at the same time.** In this case, the union is returned by default, enabling a clean and intuitive plotting experience (shown below). If you’d prefer to preserve location as a dimension for comparative analysis, you can use the approach demonstrated in the third bullet of *Clipping to `climakitae` support boundaries* above: pass a dictionary with a `boundaries` key containing your list of boundaries and set `separated`: True. This produces a new dimension named after the first boundary type in the list. For example, applying this approach to the scenario in bullet 4 would create a dimension called `county`, since a county is the first boundary specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at all HADISD station options\n",
    "cd.show_station_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97841200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at other boundaries that `climakitae` supports\n",
    "cd.show_boundary_options()\n",
    "cd.show_boundary_options(\"ca_counties\")\n",
    "cd.show_boundary_options(\"ious_pous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc8464-ace4-42f7-8b07-d762b5195fed",
   "metadata": {},
   "source": [
    "**Now, let's clip our WRF WL data to a specific point (Downtown Los Angeles).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_clipped_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": (34.05, -118.25)  # Clip to specified coordinates\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "wl_clipped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46807187-80b1-4418-be9b-ad6560d38171",
   "metadata": {},
   "source": [
    "**Now, let's clip to multiple points at the same time and take a look at the resulting data object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb58b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lons = [\n",
    "    (34.05, -118.25),  # Los Angeles, CA\n",
    "    (37.77, -122.42),  # San Francisco, CA\n",
    "]\n",
    "wl_couple_points = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": {\n",
    "            \"points\": lat_lons,  # Clip to specified coordinates\n",
    "            # Whether or not you want your clipped points to be in a separate dimension called `points`,\n",
    "            # or if you want gridded data returned with NaN everywhere except selected points.\n",
    "            \"separated\": True\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "wl_couple_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb05da-e9b7-4d18-922c-259474aeb2c3",
   "metadata": {},
   "source": [
    "**We can additionally clip different boundaries together too. Below, we'll clip Alameda and Los Angeles Counties into one xr.DataArray and visualize the result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e37ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_counties = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": [\"Alameda County\", \"Los Angeles County\"]\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "clip_counties.isel(sim=0, warming_level=0, time_delta=0).t2.plot(x='lon', y='lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e649a91",
   "metadata": {},
   "source": [
    "**Now, we can separate the two clipped regions like we did before using the `separated: True` parameter to `clip`, and see that `county` now exists as a dimension on the resulting DataArray object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_counties_separated = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": {\n",
    "            \"boundaries\": [\"Alameda County\", \"Los Angeles County\"],\n",
    "            \"separated\": True\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "clip_counties_separated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cdacb",
   "metadata": {},
   "source": [
    "### Processor Example 6: Unit Conversion\n",
    "\n",
    "We can also pass in a processor to convert the units of our dataset. It's as simple as specifying the conversion you'd like to apply. If it fails, you'll be informed in the logs about available units to convert to and no unit conversion will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6246068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we'll take the temperature data that's natively in Kelvin to be returned in Fahrenheit instead\n",
    "degF_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\") # Temperature at 2 meters\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0], # Warming levels in °C\n",
    "        },\n",
    "        \"clip\": \"Los Angeles County\",\n",
    "        \"convert_units\": \"degF\" # This will convert from Kelvin to Fahrenheit\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "degF_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf697e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll see that the values are within the reasonable ranges of we'd see for Fahrenheit for Los Angeles County\n",
    "degF_data.mean(dim='time_delta').isel(sim=0, warming_level=0).t2.plot(x=\"lon\", y=\"lat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1044a6",
   "metadata": {},
   "source": [
    "### Processor Example 7: Metric Calculation\n",
    "\n",
    "Some basic metric calculations have also been built in as processors, so that you can save yourself a few steps of calculating common metrics on your resulting dataset.\n",
    "\n",
    "The basic options include: `min`, `mean`, `median`, `max`, and `percentiles` and are demonstrated below. \n",
    "\n",
    "1-in-X calculations have also been included in as a processor as a more complex processor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed665d-b290-4a35-a778-a959cb7ed10a",
   "metadata": {},
   "source": [
    "#### Simple Metric Comparison Across Warming Levels\n",
    "\n",
    "Let's start with a simple metric comparison. We'll evaluate the min, mean, and max across three global warming levels, and then plot all those in a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ed48e-0666-43c3-adc3-35369beab38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['min', 'mean', 'max']\n",
    "data = []\n",
    "for metric in metrics:\n",
    "    data.append(\n",
    "        (cd.catalog(\"cadcat\")\n",
    "        .activity_id(\"WRF\")\n",
    "        .institution_id(\"UCLA\")\n",
    "        .table_id(\"day\")\n",
    "        .grid_label(\"d03\")\n",
    "        .variable(\"t2\")\n",
    "        .processes({\n",
    "            \"warming_level\": {\n",
    "                \"warming_levels\": [1.5, 2.0, 3.0],\n",
    "            },\n",
    "            \"clip\": \"Humboldt County\",\n",
    "            \"convert_units\": \"degF\",\n",
    "            \"metric_calc\": {\n",
    "                \"metric\": metric,\n",
    "                # NOTE: We have a `time_delta` dimension here because that's the time variable that's returned from a warming\n",
    "                # level approach of retrieving data. If this was a time-based approach, that dimension would be named `time`.\n",
    "                \"dim\": [\"time_delta\", \"sim\"]\n",
    "                # note: don't average over warming level\n",
    "            }\n",
    "        })\n",
    "        .get())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78c222-caf1-46af-a44b-959a3d4cf0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the 3 warming levels\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12), sharex=True, sharey=True)\n",
    "\n",
    "gwls = [1.5, 2.0, 3.0][::-1]  # Reverse for plotting\n",
    "for i, metric in enumerate(metrics):\n",
    "    for j, gwl in enumerate(gwls):\n",
    "        ax = axes[j, i]\n",
    "        data[i].isel(warming_level=len(gwls) - 1 - j).t2.plot.contourf(\n",
    "            ax=ax,\n",
    "            y=\"lat\",\n",
    "            x=\"lon\",\n",
    "            cbar_kwargs={\n",
    "                'label': f'Temperature (°F)',\n",
    "            }, \n",
    "            levels=100,\n",
    "            cmap='plasma',\n",
    "            vmin=0,\n",
    "            vmax=110\n",
    "        )\n",
    "        ax.set_title(f'{metric.capitalize()} at {gwl}°C Warming Level')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75a6b3-8460-4ab7-b9c7-5562e4b29bbd",
   "metadata": {},
   "source": [
    "#### Advanced Metric Comparison Across Warming Levels\n",
    "\n",
    "Now, let's try a slightly more advanced analysis. Let's defined a base level of warming of 1.2 degC as our reference period, and then calculate the 90th, 95th, and 98th percentile temperatures within this reference period. \n",
    "\n",
    "Then, we'll get the temperature for three global warming levels (1.5, 2.0, 3.0) and count the average number of days per year above the 90th, 95th, and 98th percentile reference period temperature for each warming level for each individual GCM. Then we'll average the number of days across GCMs and plot the results in a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8363e54-c20c-4bb3-8af6-60726ddb09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first find the 90th, 95th, and 98th percentiles over Humboldt County for a 1.2 degC reference warming level period.\n",
    "percentiles = [90, 95, 98]\n",
    "location = \"Humboldt County\"\n",
    "ref_percentiles = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.2],\n",
    "        },\n",
    "        \"clip\": location,\n",
    "        \"convert_units\": \"degF\",\n",
    "        \"metric_calc\": {\n",
    "            \"percentiles\": percentiles,\n",
    "            \"dim\": [\"time_delta\"]\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482fc76-2e5b-423d-b4fe-023616d62934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll get all the raw data from the future WLs and count the number of days each simulation is above the different 1.2 degC WL percentiles.\n",
    "wrf_wl_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.5, 2.0, 3.0],\n",
    "        },\n",
    "        \"clip\": location,\n",
    "        \"convert_units\": \"degF\",\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0d85b-4d4e-4887-8eba-35ae6ed1db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ref_percentiles)\n",
    "display(wrf_wl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d47fcf-4da9-450d-bda0-5f4c108358ca",
   "metadata": {},
   "source": [
    "First, we'll drop `EC-Earth3-Veg` from `wrf_wl_data`, since `EC-Earth3-Veg` is an incomplete, and thus dropped, WL at 1.2 degC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21461c-246b-4068-9ec2-5bb2b0ff5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping `EC-Earth3-Veg` by only keeping the other sims\n",
    "only_valid_wrf = wrf_wl_data.sel(sim=[\n",
    "    'WRF_UCLA_TaiESM1_ssp370_day_d03_r1i1p1f1',\n",
    "    # 'WRF_UCLA_EC-Earth3-Veg_ssp370_day_d03_r1i1p1f1',\n",
    "    'WRF_UCLA_MIROC6_ssp370_day_d03_r1i1p1f1',\n",
    "    'WRF_UCLA_EC-Earth3_ssp370_day_d03_r1i1p1f1',\n",
    "    'WRF_UCLA_MPI-ESM1-2-HR_ssp370_day_d03_r3i1p1f1'\n",
    "])\n",
    "\n",
    "# Creating a DataArray from the reference percentiles\n",
    "ref_percentile_da = ref_percentiles[[\"t2_p90\", \"t2_p95\", \"t2_p98\"]].isel(warming_level=0).to_array(dim=\"percentiles\").assign_coords(percentiles=percentiles)\n",
    "\n",
    "# Comparing the temperature values to the percentiles\n",
    "compared_da = (only_valid_wrf > ref_percentile_da).t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bfc1c2-1ccc-45e4-9e9e-ec674b19cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now, let's plot a comparison of the results\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12), sharex=True, sharey=True)\n",
    "\n",
    "# mask for the spatial coordinates so that we can preserve them after counting\n",
    "spatial_mask = ref_percentile_da.isel(percentiles=0, sim=0).notnull()\n",
    "\n",
    "gwls = [1.5, 2.0, 3.0][::-1]  # Reverse for plotting\n",
    "for i, metric in enumerate(percentiles):\n",
    "    for j, gwl in enumerate(gwls):\n",
    "        ax = axes[j, i]\n",
    "        \n",
    "        days_exceeding = (compared_da.isel(warming_level=len(gwls) - 1 - j).sel(percentiles=metric).mean(dim='sim')).sum(dim='time_delta', skipna=False) / 30\n",
    "\n",
    "        # preserve the masked county\n",
    "        days_exceeding = days_exceeding.where(spatial_mask)\n",
    "\n",
    "        # contour plot\n",
    "        days_exceeding.plot.contourf(\n",
    "            ax=ax,\n",
    "            y=\"lat\",\n",
    "            x=\"lon\",\n",
    "            cbar_kwargs={'label': f'Avg Days Per Year Above Reference'},\n",
    "            levels=100,\n",
    "            cmap='plasma',\n",
    "            vmin=0, vmax=99\n",
    "        )\n",
    "        ax.set_title(f'Avg Days / Year > {metric}th pctl T2 at {gwl}°C GWL')\n",
    "\n",
    "plt.suptitle(\"Average Number of Days Above Reference Percentile Temp for several Global Warming Levels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2e396",
   "metadata": {},
   "source": [
    "#### 1-in-X Metric Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f53f2",
   "metadata": {},
   "source": [
    "Finally, the last metric calculation that we provide out of the box with the `ClimateData` object are 1-in-X calculations. Below demonstrates an example of how you could calculate the **Maximum 1-in-10 and 1-in-50 Daily Air Temperatures for WRF data over Alameda County for a 1.5 degC warming world.**\n",
    "\n",
    "**Parameter options for 1-in-X calculations:**\n",
    "- `return_periods`: A list of return periods you're interested in calculating for your dataset\n",
    "- `distribution`: One of the following distribution types: `[\"gev\", \"gumbel\", \"weibull\", \"pearson3\", \"genpareto\", \"gamma\"]` (see more on scipy.stats documentation <a href=\"https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions\" style=\"color: blue;\" target=\"_blank\">here</a>).\n",
    "- `extremes_type`: `min` or `max`\n",
    "- `event_duration`: (# of time, scale of time), i.e. `(1, 'day')`\n",
    "- `block_size`: Block size in number of years, default is 1\n",
    "- `goodness_of_fit_test`:  # Whether or not you want to see the p-values from the fitted distributions used to calculate the resulting 1-in-X return values, default is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_periods = [10, 100]\n",
    "one_in_x_data = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"day\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [2.0]\n",
    "        },\n",
    "        \"clip\": \"Alameda County\", \n",
    "        \"convert_units\": \"degF\",\n",
    "        \"metric_calc\": {\n",
    "            \"one_in_x\": {\n",
    "                \"return_periods\": return_periods, # Looking at 1-in-10 and 1-in-100\n",
    "                \"distribution\": \"gev\", # Default is `gev`\n",
    "                \"extremes_type\": \"max\",\n",
    "                \"event_duration\": (1, 'day'),\n",
    "                \"block_size\": 1, # Block size in years, default is 1\n",
    "                \"goodness_of_fit_test\": True\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    .get())\n",
    "\n",
    "# Let's plot what the 1-in-X return values look like over Alameda County\n",
    "for x in return_periods:\n",
    "    fig,ax = plt.subplots()\n",
    "    one_in_x_data.mean(dim='sim').sel(one_in_x=x).return_values.plot(\n",
    "        cmap='plasma', \n",
    "        x='lon', \n",
    "        y='lat',\n",
    "        cbar_kwargs={'label': f'1-in-{x} year Daily Max Temperature (°F)'}\n",
    "    )\n",
    "    ax.set_title(f'1-in-{x} Year Daily Max Temp averaged \\nover all WRF sims for Alameda County')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df5827-549f-4c90-977c-79e63557c836",
   "metadata": {},
   "source": [
    "### Processor Example 9: Bias Adjust Model to Station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d818ce",
   "metadata": {},
   "source": [
    "In case you want to station bias correct gridded climate model data to historical observations from weather stations, you can pass in your desired weather station to the `bias_adjust_model_to_station` processor that we provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually bias adjust our climate data to KSAC (the SAC airport weather station).\n",
    "manual_bias_adjustment = (cd\n",
    "    .catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"1hr\")\n",
    "    .grid_label(\"d02\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"bias_adjust_model_to_station\": {\n",
    "            \"stations\": ['KSAC'],\n",
    "            \"historical_slice\": (1980, 2014), # You can specify what historical period to bias correct for.\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")\n",
    "\n",
    "manual_bias_adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581676cf",
   "metadata": {},
   "source": [
    "### Processor Example 10: Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f682b-3972-4235-b09c-1eab5017fdbf",
   "metadata": {},
   "source": [
    "Now that we’ve walked through the processors above, you may want to take the data you’ve been working with and move it elsewhere. The `export` processor makes this straightforward.\n",
    "\n",
    "In the example below, we take a small subset of data, apply a few processors, and then export the result using the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a5bd5-df65-4c4d-9a6b-dd28eb73bc2a",
   "metadata": {},
   "source": [
    "        filename (str, optional): Base output filename without extension.\n",
    "            Default: \"dataexport\"\n",
    "        file_format (str, optional): Output file format. Supported values:\n",
    "            \"NetCDF\", \"Zarr\", \"CSV\". Case-insensitive. Default: \"NetCDF\"\n",
    "        mode (str, optional): Storage location for Zarr files.\n",
    "            \"local\" saves to local filesystem, \"s3\" saves to AWS S3.\n",
    "            Default: \"local\"\n",
    "        separated (bool, optional): When exporting a collection of point datasets,\n",
    "            whether to create separate files for each point. If True, each dataset\n",
    "            gets its own file with either lat/lon or index suffix. If False, all\n",
    "            items are exported with the base filename (unique suffixes added if needed).\n",
    "            Ignored for single gridded datasets. Default: False\n",
    "        location_based_naming (bool, optional): When separated=True and\n",
    "            exporting point-based data, include lat/lon coordinates in filenames\n",
    "            (e.g., filename_34-0N_118-0W.nc). If False, uses index numbers\n",
    "            instead (e.g., filename_0.nc). Silently ignored for gridded datasets.\n",
    "            Default: False\n",
    "        export_method (str, optional): Controls what data to export. Options:\n",
    "            \"data\": Export all provided data (default)\n",
    "            \"raw\": Export only raw/unprocessed data\n",
    "            \"calculate\": Export only calculated/processed data\n",
    "            \"both\": Export both raw and calculated data to separate files\n",
    "            \"skip_existing\": Skip export if file already exists\n",
    "            \"none\": Skip export entirely\n",
    "            Default: \"data\"\n",
    "        raw_filename (str, optional): Custom filename for raw data when using\n",
    "            export_method=\"raw\" or \"both\". If not provided, uses\n",
    "            \"{filename}_raw\". Default: None\n",
    "        calc_filename (str, optional): Custom filename for calculated data when\n",
    "            using export_method=\"calculate\" or \"both\". If not provided, uses\n",
    "            \"{filename}_calc\".\n",
    "            Default: None\n",
    "        filename_template (str, optional): Custom template for generating filenames.\n",
    "            Supports placeholders: {filename}, {lat}, {lon}, {name}.\n",
    "            Lat/lon placeholders only populated for single-point data.\n",
    "            Example: \"{name}_data_{lat}N_{lon}W\".\n",
    "            Default: None\n",
    "        fail_on_error (bool, optional): If True, raise exceptions on export\n",
    "            errors. If False, log warnings and continue.\n",
    "            Default: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157320f-7c85-40a9-9259-f25f4f391133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's export all of Humboldt County's data into one file, since the whole county can just be one file\n",
    "location = \"Humboldt County\"\n",
    "export_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.2],\n",
    "        },\n",
    "        \"clip\": location,\n",
    "        \"convert_units\": \"degF\",\n",
    "        \"export\": {\n",
    "            \"filename\": \"gridded_export_data\", # Filename that you want the data exported to\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9720a-fd39-4830-ad10-78e6fe48e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lons = [\n",
    "    (34.05, -118.25),  # Los Angeles, CA\n",
    "    (37.77, -122.42),  # San Francisco, CA\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e81b62-1904-4995-997d-0e9238ccb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's export this list of `lat_lons` from before into separate files.\n",
    "export_data = (\n",
    "    cd.catalog(\"cadcat\")\n",
    "    .activity_id(\"WRF\")\n",
    "    .institution_id(\"UCLA\")\n",
    "    .table_id(\"mon\")\n",
    "    .grid_label(\"d03\")\n",
    "    .variable(\"t2\")\n",
    "    .processes({\n",
    "        \"warming_level\": {\n",
    "            \"warming_levels\": [1.2],\n",
    "        },\n",
    "        \"clip\": {\n",
    "            \"points\": lat_lons,\n",
    "            \"separated\": True,\n",
    "        },\n",
    "        \"convert_units\": \"degF\",\n",
    "        \"export\": {\n",
    "            \"separated\": True, # (ONLY FOR POINT-BASED CLIPPING) Whether or not you want different points to be separated into different files\n",
    "            \"location_based_naming\": True, # Whether or not you want the lat/lons of different points passed \n",
    "            \"filename\": \"point_export_data\", # Filename that you want the data exported to\n",
    "        }\n",
    "    })\n",
    "    .get()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c04a36",
   "metadata": {},
   "source": [
    "We hope this notebook and `climakitae` help empower you in your future climate data analyses!\n",
    "\n",
    "**If you have any issues running this notebook, or are running into any issues with any of these processors, or have general feedback about the behavior of the `ClimateData` object or any of its processors, please write an Issue on our Github repo here: https://github.com/cal-adapt/climakitae/issues. Thank you so much!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
